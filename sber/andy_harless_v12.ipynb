{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "eb797542-13a5-d3ae-06f7-7148178f3c74",
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "This version adjusts results using average (log) predicted prices from a macro model.\n",
    "\n",
    "By default (that is, if micro_humility_factor=1), it rescales the adjusted log predictions so that the standard deviation of the raw predictions is the same as it was before the adjustment.\n",
    "\n",
    "There is also a provision for applying micro and macro humility factors .  The macro humility factor adjusts the macro predictions by averaging in a \"naive\" macro model.  The micro humility factor adjusts individual (log) predictions toward the (log) mean. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "*TODO*:\n",
    "\n",
    "    Apply BAD ADDRESS FIX - *FAILED*\n",
    "    Попробовать пересчитать с новыми fillna\n",
    "    https://www.kaggle.com/jasonpeng/latest-iteration-in-this-silly-game/code\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-20T05:51:44.094871Z",
     "start_time": "2017-06-20T05:51:44.084105Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "train_path = \"data/train_without_noise.csv\"\n",
    "test_path = \"data/test_cleaned.csv\"\n",
    "macro_path = \"data/macro.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-20T05:51:44.694437Z",
     "start_time": "2017-06-20T05:51:44.688324Z"
    },
    "_cell_guid": "af81a88e-5980-2819-18a7-1b1e4032205f",
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "micro_humility_factor = 1     #    range from 0 (complete humility) to 1 (no humility)\n",
    "macro_humility_factor = 0.96\n",
    "jason_weight = .2\n",
    "bruno_weight = .2\n",
    "reynaldo_weight = 1 - jason_weight - bruno_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-20T05:51:45.316178Z",
     "start_time": "2017-06-20T05:51:45.312523Z"
    },
    "_cell_guid": "a0320923-48e8-7105-9228-bee42fa1fc41",
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Get ready for lots of annoying deprecation warnings\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-20T05:51:45.951807Z",
     "start_time": "2017-06-20T05:51:45.945160Z"
    },
    "_cell_guid": "31a987d3-1475-7b13-8da3-9f904856d915",
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import model_selection, preprocessing\n",
    "import xgboost as xgb\n",
    "import datetime\n",
    "import scipy as sp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Функции для преобразования цены"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-20T05:51:47.653731Z",
     "start_time": "2017-06-20T05:51:47.647485Z"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def price_doc_to_meter(train):\n",
    "    train[\"price_doc\"] = train[\"price_doc\"] / train[\"full_sq\"]\n",
    "    return train\n",
    "\n",
    "def price_meter_to_doc(test):\n",
    "    test[\"price_doc\"] = test[\"price_doc\"] * test[\"full_sq\"]\n",
    "    return test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "3d6f23a0-8a54-edf6-a793-14d6cd965335",
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Fit macro model and compute average prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-20T05:51:51.862655Z",
     "start_time": "2017-06-20T05:51:49.449191Z"
    },
    "_cell_guid": "1c611c87-b384-4b03-862f-917717df8c3e",
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Read data\n",
    "macro = pd.read_csv(macro_path)\n",
    "train = pd.read_csv(train_path)\n",
    "\n",
    "# train = price_doc_to_meter(train)\n",
    "\n",
    "test = pd.read_csv(test_path)\n",
    "\n",
    "# Macro data monthly medians\n",
    "macro[\"timestamp\"] = pd.to_datetime(macro[\"timestamp\"])\n",
    "macro[\"year\"]  = macro[\"timestamp\"].dt.year\n",
    "macro[\"month\"] = macro[\"timestamp\"].dt.month\n",
    "macro[\"yearmonth\"] = 100*macro.year + macro.month\n",
    "macmeds = macro.groupby(\"yearmonth\").median()\n",
    "\n",
    "# Price data monthly medians\n",
    "train[\"timestamp\"] = pd.to_datetime(train[\"timestamp\"])\n",
    "train[\"year\"]  = train[\"timestamp\"].dt.year\n",
    "train[\"month\"] = train[\"timestamp\"].dt.month\n",
    "train[\"yearmonth\"] = 100*train.year + train.month\n",
    "prices = train[[\"yearmonth\",\"price_doc\"]]\n",
    "p = prices.groupby(\"yearmonth\").median()\n",
    "\n",
    "# Join monthly prices to macro data\n",
    "df = macmeds.join(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-20T05:51:51.874913Z",
     "start_time": "2017-06-20T05:51:51.864514Z"
    },
    "_cell_guid": "c7fef4e9-279a-dbc2-f80e-8ea82eec262f",
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Function to process Almon lags\n",
    "\n",
    "import numpy.matlib as ml\n",
    " \n",
    "def almonZmatrix(X, maxlag, maxdeg):\n",
    "    \"\"\"\n",
    "    Creates the Z matrix corresponding to vector X.\n",
    "    \"\"\"\n",
    "    n = len(X)\n",
    "    Z = ml.zeros((len(X)-maxlag, maxdeg+1))\n",
    "    for t in range(maxlag,  n):\n",
    "       #Solve for Z[t][0].\n",
    "       Z[t-maxlag,0] = sum([X[t-lag] for lag in range(maxlag+1)])\n",
    "       for j in range(1, maxdeg+1):\n",
    "             s = 0.0\n",
    "             for i in range(1, maxlag+1):       \n",
    "                s += (i)**j * X[t-i]\n",
    "             Z[t-maxlag,j] = s\n",
    "    return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-20T05:51:52.118217Z",
     "start_time": "2017-06-20T05:51:51.877681Z"
    },
    "_cell_guid": "47b5ffb5-90c5-3107-5922-957e48c2a9fe",
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6587365.7873465288"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Prepare data for macro model\n",
    "y = df.price_doc.div(df.cpi).apply(np.log).loc[201108:201506]\n",
    "lncpi = df.cpi.apply(np.log)\n",
    "tblags = 5    # Number of lags used on PDL for Trade Balance\n",
    "mrlags = 5    # Number of lags used on PDL for Mortgage Rate\n",
    "cplags = 5    # Number of lags used on PDL for CPI\n",
    "ztb = almonZmatrix(df.balance_trade.loc[201103:201506].as_matrix(), tblags, 1)\n",
    "zmr = almonZmatrix(df.mortgage_rate.loc[201103:201506].as_matrix(), mrlags, 1)\n",
    "zcp = almonZmatrix(lncpi.loc[201103:201506].as_matrix(), cplags, 1)\n",
    "columns = ['tb0', 'tb1', 'mr0', 'mr1', 'cp0', 'cp1']\n",
    "z = pd.DataFrame( np.concatenate( (ztb, zmr, zcp), axis=1), y.index.values, columns )\n",
    "X = sm.add_constant( z )\n",
    "\n",
    "# Fit macro model\n",
    "eq = sm.OLS(y, X)\n",
    "fit = eq.fit()\n",
    "\n",
    "# Predict with macro model\n",
    "test_cpi = df.cpi.loc[201507:201605]\n",
    "test_index = test_cpi.index\n",
    "ztb_test = almonZmatrix(df.balance_trade.loc[201502:201605].as_matrix(), tblags, 1)\n",
    "zmr_test = almonZmatrix(df.mortgage_rate.loc[201502:201605].as_matrix(), mrlags, 1)\n",
    "zcp_test = almonZmatrix(lncpi.loc[201502:201605].as_matrix(), cplags, 1)\n",
    "z_test = pd.DataFrame( np.concatenate( (ztb_test, zmr_test, zcp_test), axis=1), \n",
    "                       test_index, columns )\n",
    "X_test = sm.add_constant( z_test )\n",
    "pred_lnrp = fit.predict( X_test )\n",
    "pred_p = np.exp(pred_lnrp) * test_cpi\n",
    "\n",
    "# Merge with test cases and compute mean for macro prediction\n",
    "test[\"timestamp\"] = pd.to_datetime(test[\"timestamp\"])\n",
    "test[\"year\"]  = test[\"timestamp\"].dt.year\n",
    "test[\"month\"] = test[\"timestamp\"].dt.month\n",
    "test[\"yearmonth\"] = 100*test.year + test.month\n",
    "test_ids = test[[\"yearmonth\",\"id\"]]\n",
    "monthprices = pd.DataFrame({\"yearmonth\":pred_p.index.values,\"monthprice\":pred_p.values})\n",
    "macro_mean = np.exp(test_ids.merge(monthprices, on=\"yearmonth\").monthprice.apply(np.log).mean())\n",
    "macro_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-20T05:51:52.141736Z",
     "start_time": "2017-06-20T05:51:52.122093Z"
    },
    "_cell_guid": "c8a7aae9-788d-6bf0-1249-40bca06ddfce",
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7773402.173836139"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naive macro model assumes housing prices will simply follow CPI\n",
    "naive_pred_lnrp = y.mean()\n",
    "naive_pred_p = np.exp(naive_pred_lnrp) * test_cpi\n",
    "monthnaive = pd.DataFrame({\"yearmonth\":pred_p.index.values, \"monthprice\":naive_pred_p.values})\n",
    "macro_naive = np.exp(test_ids.merge(monthnaive, on=\"yearmonth\").monthprice.apply(np.log).mean())\n",
    "macro_naive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-20T05:51:52.151302Z",
     "start_time": "2017-06-20T05:51:52.144346Z"
    },
    "_cell_guid": "4b0e1912-e303-55b6-5c34-5d40ad0bf183",
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6631133.2379768156"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combine naive and substantive macro models\n",
    "macro_mean = macro_naive * (macro_mean/macro_naive) ** macro_humility_factor\n",
    "macro_mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "38ef4aa4-4510-c080-cf88-f398fd3f18fc",
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Fit Jason's model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-20T05:58:52.818641Z",
     "start_time": "2017-06-20T05:57:51.958190Z"
    },
    "_cell_guid": "20e58eb5-0375-6e87-1bae-aefbe1e136e0",
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/evgeny/Library/Python/2.7/lib/python/site-packages/ipykernel_launcher.py:14: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate_ix\n",
      "  \n",
      "/Users/evgeny/Library/Python/2.7/lib/python/site-packages/ipykernel_launcher.py:16: DeprecationWarning: \n",
      ".ix is deprecated. Please use\n",
      ".loc for label based indexing or\n",
      ".iloc for positional indexing\n",
      "\n",
      "See the documentation here:\n",
      "http://pandas.pydata.org/pandas-docs/stable/indexing.html#deprecate_ix\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price_doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30474</td>\n",
       "      <td>5602799.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30475</td>\n",
       "      <td>7746122.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30476</td>\n",
       "      <td>5827246.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30477</td>\n",
       "      <td>5733572.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30478</td>\n",
       "      <td>5332166.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  price_doc\n",
       "0  30474  5602799.0\n",
       "1  30475  7746122.5\n",
       "2  30476  5827246.5\n",
       "3  30477  5733572.5\n",
       "4  30478  5332166.5"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Jason/Gunja\n",
    "\n",
    "#load files\n",
    "train = pd.read_csv(train_path, parse_dates=['timestamp'])\n",
    "\n",
    "# train = price_doc_to_meter(train)\n",
    "\n",
    "test = pd.read_csv(test_path, parse_dates=['timestamp'])\n",
    "macro = pd.read_csv(macro_path, parse_dates=['timestamp'])\n",
    "id_test = test.id\n",
    "\n",
    "#clean data\n",
    "bad_index = train[train.life_sq > train.full_sq].index\n",
    "train.ix[bad_index, \"life_sq\"] = np.NaN\n",
    "equal_index = [601,1896,2791]\n",
    "test.ix[equal_index, \"life_sq\"] = test.ix[equal_index, \"full_sq\"]\n",
    "bad_index = test[test.life_sq > test.full_sq].index\n",
    "test.ix[bad_index, \"life_sq\"] = np.NaN\n",
    "bad_index = train[train.life_sq < 5].index\n",
    "train.ix[bad_index, \"life_sq\"] = np.NaN\n",
    "bad_index = test[test.life_sq < 5].index\n",
    "test.ix[bad_index, \"life_sq\"] = np.NaN\n",
    "bad_index = train[train.full_sq < 5].index\n",
    "train.ix[bad_index, \"full_sq\"] = np.NaN\n",
    "bad_index = test[test.full_sq < 5].index\n",
    "test.ix[bad_index, \"full_sq\"] = np.NaN\n",
    "kitch_is_build_year = [13117]\n",
    "train.ix[kitch_is_build_year, \"build_year\"] = train.ix[kitch_is_build_year, \"kitch_sq\"]\n",
    "bad_index = train[train.kitch_sq >= train.life_sq].index\n",
    "train.ix[bad_index, \"kitch_sq\"] = np.NaN\n",
    "bad_index = test[test.kitch_sq >= test.life_sq].index\n",
    "test.ix[bad_index, \"kitch_sq\"] = np.NaN\n",
    "bad_index = train[(train.kitch_sq == 0).values + (train.kitch_sq == 1).values].index\n",
    "train.ix[bad_index, \"kitch_sq\"] = np.NaN\n",
    "bad_index = test[(test.kitch_sq == 0).values + (test.kitch_sq == 1).values].index\n",
    "test.ix[bad_index, \"kitch_sq\"] = np.NaN\n",
    "bad_index = train[(train.full_sq > 210) & (train.life_sq / train.full_sq < 0.3)].index\n",
    "train.ix[bad_index, \"full_sq\"] = np.NaN\n",
    "bad_index = test[(test.full_sq > 150) & (test.life_sq / test.full_sq < 0.3)].index\n",
    "test.ix[bad_index, \"full_sq\"] = np.NaN\n",
    "bad_index = train[train.life_sq > 300].index\n",
    "train.ix[bad_index, [\"life_sq\", \"full_sq\"]] = np.NaN\n",
    "bad_index = test[test.life_sq > 200].index\n",
    "test.ix[bad_index, [\"life_sq\", \"full_sq\"]] = np.NaN\n",
    "train.product_type.value_counts(normalize= True)\n",
    "test.product_type.value_counts(normalize= True)\n",
    "bad_index = train[train.build_year < 1500].index\n",
    "train.ix[bad_index, \"build_year\"] = np.NaN\n",
    "bad_index = test[test.build_year < 1500].index\n",
    "test.ix[bad_index, \"build_year\"] = np.NaN\n",
    "bad_index = train[train.num_room == 0].index \n",
    "train.ix[bad_index, \"num_room\"] = np.NaN\n",
    "bad_index = test[test.num_room == 0].index \n",
    "test.ix[bad_index, \"num_room\"] = np.NaN\n",
    "bad_index = [10076, 11621, 17764, 19390, 24007, 26713]\n",
    "train.ix[bad_index, \"num_room\"] = np.NaN\n",
    "bad_index = [3174, 7313]\n",
    "test.ix[bad_index, \"num_room\"] = np.NaN\n",
    "bad_index = train[(train.floor == 0).values * (train.max_floor == 0).values].index\n",
    "train.ix[bad_index, [\"max_floor\", \"floor\"]] = np.NaN\n",
    "bad_index = train[train.floor == 0].index\n",
    "train.ix[bad_index, \"floor\"] = np.NaN\n",
    "bad_index = train[train.max_floor == 0].index\n",
    "train.ix[bad_index, \"max_floor\"] = np.NaN\n",
    "bad_index = test[test.max_floor == 0].index\n",
    "test.ix[bad_index, \"max_floor\"] = np.NaN\n",
    "bad_index = train[train.floor > train.max_floor].index\n",
    "train.ix[bad_index, \"max_floor\"] = np.NaN\n",
    "bad_index = test[test.floor > test.max_floor].index\n",
    "test.ix[bad_index, \"max_floor\"] = np.NaN\n",
    "train.floor.describe(percentiles= [0.9999])\n",
    "bad_index = [23584]\n",
    "train.ix[bad_index, \"floor\"] = np.NaN\n",
    "train.material.value_counts()\n",
    "test.material.value_counts()\n",
    "train.state.value_counts()\n",
    "bad_index = train[train.state == 33].index\n",
    "train.ix[bad_index, \"state\"] = np.NaN\n",
    "test.state.value_counts()\n",
    "\n",
    "# brings error down a lot by removing extreme price per sqm\n",
    "train.loc[train.full_sq == 0, 'full_sq'] = 50\n",
    "train = train[train.price_doc/train.full_sq <= 600000]\n",
    "train = train[train.price_doc/train.full_sq >= 10000]\n",
    "\n",
    "# Add month-year\n",
    "month_year = (train.timestamp.dt.month + train.timestamp.dt.year * 100)\n",
    "month_year_cnt_map = month_year.value_counts().to_dict()\n",
    "train['month_year_cnt'] = month_year.map(month_year_cnt_map)\n",
    "\n",
    "month_year = (test.timestamp.dt.month + test.timestamp.dt.year * 100)\n",
    "month_year_cnt_map = month_year.value_counts().to_dict()\n",
    "test['month_year_cnt'] = month_year.map(month_year_cnt_map)\n",
    "\n",
    "# Add week-year count\n",
    "week_year = (train.timestamp.dt.weekofyear + train.timestamp.dt.year * 100)\n",
    "week_year_cnt_map = week_year.value_counts().to_dict()\n",
    "train['week_year_cnt'] = week_year.map(week_year_cnt_map)\n",
    "\n",
    "week_year = (test.timestamp.dt.weekofyear + test.timestamp.dt.year * 100)\n",
    "week_year_cnt_map = week_year.value_counts().to_dict()\n",
    "test['week_year_cnt'] = week_year.map(week_year_cnt_map)\n",
    "\n",
    "# Add month and day-of-week\n",
    "train['month'] = train.timestamp.dt.month\n",
    "train['dow'] = train.timestamp.dt.dayofweek\n",
    "\n",
    "test['month'] = test.timestamp.dt.month\n",
    "test['dow'] = test.timestamp.dt.dayofweek\n",
    "\n",
    "# Other feature engineering\n",
    "train['rel_floor'] = train['floor'] / train['max_floor'].astype(float)\n",
    "train['rel_kitch_sq'] = train['kitch_sq'] / train['full_sq'].astype(float)\n",
    "\n",
    "test['rel_floor'] = test['floor'] / test['max_floor'].astype(float)\n",
    "test['rel_kitch_sq'] = test['kitch_sq'] / test['full_sq'].astype(float)\n",
    "\n",
    "train.apartment_name=train.sub_area + train['metro_km_avto'].astype(str)\n",
    "test.apartment_name=test.sub_area + train['metro_km_avto'].astype(str)\n",
    "\n",
    "train['room_size'] = train['life_sq'] / train['num_room'].astype(float)\n",
    "test['room_size'] = test['life_sq'] / test['num_room'].astype(float)\n",
    "\n",
    "y_train = train[\"price_doc\"]\n",
    "wts = 1 - .47*(y_train == 1e6)\n",
    "x_train = train.drop([\"id\", \"timestamp\", \"price_doc\"], axis=1)\n",
    "x_test = test.drop([\"id\", \"timestamp\"], axis=1)\n",
    "\n",
    "for c in x_train.columns:\n",
    "    if x_train[c].dtype == 'object':\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(x_train[c].values)) \n",
    "        x_train[c] = lbl.transform(list(x_train[c].values))\n",
    "        #x_train.drop(c,axis=1,inplace=True)\n",
    "        \n",
    "for c in x_test.columns:\n",
    "    if x_test[c].dtype == 'object':\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(x_test[c].values)) \n",
    "        x_test[c] = lbl.transform(list(x_test[c].values))\n",
    "        #x_test.drop(c,axis=1,inplace=True)  \n",
    "\n",
    "\n",
    "xgb_params = {\n",
    "    'eta': 0.05,\n",
    "    'max_depth': 5,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'rmse',\n",
    "    'silent': 1\n",
    "}\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train, y_train, weight=wts)\n",
    "dtest = xgb.DMatrix(x_test)\n",
    "\n",
    "#cv_output = xgb.cv(xgb_params, dtrain, num_boost_round=1000, early_stopping_rounds=20,\n",
    "#    verbose_eval=50, show_stdv=False)\n",
    "#cv_output[['train-rmse-mean', 'test-rmse-mean']].plot()\n",
    "\n",
    "#num_boost_rounds = len(cv_output)\n",
    "model = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round=350)\n",
    "\n",
    "#fig, ax = plt.subplots(1, 1, figsize=(8, 13))\n",
    "#xgb.plot_importance(model, max_num_features=50, height=0.5, ax=ax)\n",
    "\n",
    "y_predict = model.predict(dtest)\n",
    "jason_model_output = pd.DataFrame({'id': id_test, 'price_doc': y_predict})\n",
    "jason_model_output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-20T05:58:52.837688Z",
     "start_time": "2017-06-20T05:58:52.821247Z"
    },
    "_cell_guid": "017a2a03-1c23-5648-6b74-273210421cc1",
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6835064.5"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jason_model_output.to_csv('jason_model.csv', index=False)\n",
    "np.exp(jason_model_output.price_doc.apply(np.log).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e6a6e979-dad7-3fb4-41d9-bd4da3dbf3c8",
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Fit Reynaldo's model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-20T05:59:51.007880Z",
     "start_time": "2017-06-20T05:58:52.841816Z"
    },
    "_cell_guid": "ef1a4a17-c328-b2eb-4861-ccee2e5c1b2d",
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price_doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30474</td>\n",
       "      <td>5609074.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30475</td>\n",
       "      <td>7932025.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30476</td>\n",
       "      <td>5506285.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30477</td>\n",
       "      <td>5758820.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30478</td>\n",
       "      <td>5179852.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  price_doc\n",
       "0  30474  5609074.5\n",
       "1  30475  7932025.5\n",
       "2  30476  5506285.5\n",
       "3  30477  5758820.0\n",
       "4  30478  5179852.5"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reynaldo\n",
    "train = pd.read_csv(train_path)\n",
    "\n",
    "# train = price_doc_to_meter(train)\n",
    "\n",
    "test = pd.read_csv(test_path)\n",
    "id_test = test.id\n",
    "\n",
    "y_train = train[\"price_doc\"]\n",
    "x_train = train.drop([\"id\", \"timestamp\", \"price_doc\"], axis=1)\n",
    "x_test = test.drop([\"id\", \"timestamp\"], axis=1)\n",
    "\n",
    "for c in x_train.columns:\n",
    "    if x_train[c].dtype == 'object':\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(x_train[c].values)) \n",
    "        x_train[c] = lbl.transform(list(x_train[c].values))\n",
    "        \n",
    "for c in x_test.columns:\n",
    "    if x_test[c].dtype == 'object':\n",
    "        lbl = preprocessing.LabelEncoder()\n",
    "        lbl.fit(list(x_test[c].values)) \n",
    "        x_test[c] = lbl.transform(list(x_test[c].values))\n",
    "\n",
    "xgb_params = {\n",
    "    'eta': 0.05,\n",
    "    'max_depth': 5,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'rmse',\n",
    "    'silent': 1\n",
    "}\n",
    "\n",
    "dtrain = xgb.DMatrix(x_train, y_train)\n",
    "dtest = xgb.DMatrix(x_test)\n",
    "\n",
    "num_boost_rounds = 384  # This was the CV output, as earlier version shows\n",
    "model = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round= num_boost_rounds)\n",
    "\n",
    "y_predict = model.predict(dtest)\n",
    "reynaldo_model_output = pd.DataFrame({'id': id_test, 'price_doc': y_predict})\n",
    "reynaldo_model_output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-20T05:59:51.033841Z",
     "start_time": "2017-06-20T05:59:51.010323Z"
    },
    "_cell_guid": "55f8e7a7-045a-0568-d46b-3ac3bc043091",
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6814835.5"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reynaldo_model_output.to_csv('reynaldo_model.csv', index=False)\n",
    "np.exp( reynaldo_model_output.price_doc.apply(np.log).mean() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "7cc5b5c7-0626-97e2-4164-3e7fe3321da5",
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Fit Bruno's model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-20T06:00:56.270519Z",
     "start_time": "2017-06-20T05:59:51.036243Z"
    },
    "_cell_guid": "f3792f8a-3c79-b307-c699-6295e0358443",
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36556, 390)\n",
      "(36556, 394)\n",
      "(36556, 394)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price_doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30474</td>\n",
       "      <td>5529990.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30475</td>\n",
       "      <td>8320878.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30476</td>\n",
       "      <td>5806957.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30477</td>\n",
       "      <td>5656753.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30478</td>\n",
       "      <td>5179499.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  price_doc\n",
       "0  30474  5529990.0\n",
       "1  30475  8320878.5\n",
       "2  30476  5806957.0\n",
       "3  30477  5656753.0\n",
       "4  30478  5179499.5"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Bruno with outlier dropped\n",
    "\n",
    "\n",
    "\n",
    "# Any results you write to the current directory are saved as output.\n",
    "df_train = pd.read_csv(train_path, parse_dates=['timestamp'])\n",
    "# df_train = price_doc_to_meter(df_train)\n",
    "df_test = pd.read_csv(test_path, parse_dates=['timestamp'])\n",
    "df_macro = pd.read_csv(macro_path, parse_dates=['timestamp'])\n",
    "\n",
    "df_train.drop(df_train[df_train[\"life_sq\"] > 7000].index, inplace=True)\n",
    "\n",
    "y_train = df_train['price_doc'].values\n",
    "id_test = df_test['id']\n",
    "\n",
    "df_train.drop(['id', 'price_doc'], axis=1, inplace=True)\n",
    "df_test.drop(['id'], axis=1, inplace=True)\n",
    "\n",
    "num_train = len(df_train)\n",
    "df_all = pd.concat([df_train, df_test])\n",
    "# Next line just adds a lot of NA columns (becuase \"join\" only works on indexes)\n",
    "# but somewhow it seems to affect the result\n",
    "df_all = df_all.join(df_macro, on='timestamp', rsuffix='_macro')\n",
    "print(df_all.shape)\n",
    "\n",
    "# Add month-year\n",
    "month_year = (df_all.timestamp.dt.month + df_all.timestamp.dt.year * 100)\n",
    "month_year_cnt_map = month_year.value_counts().to_dict()\n",
    "df_all['month_year_cnt'] = month_year.map(month_year_cnt_map)\n",
    "\n",
    "# Add week-year count\n",
    "week_year = (df_all.timestamp.dt.weekofyear + df_all.timestamp.dt.year * 100)\n",
    "week_year_cnt_map = week_year.value_counts().to_dict()\n",
    "df_all['week_year_cnt'] = week_year.map(week_year_cnt_map)\n",
    "\n",
    "# Add month and day-of-week\n",
    "df_all['month'] = df_all.timestamp.dt.month\n",
    "df_all['dow'] = df_all.timestamp.dt.dayofweek\n",
    "\n",
    "# Other feature engineering\n",
    "df_all['rel_floor'] = df_all['floor'] / df_all['max_floor'].astype(float)\n",
    "df_all['rel_kitch_sq'] = df_all['kitch_sq'] / df_all['full_sq'].astype(float)\n",
    "\n",
    "# Remove timestamp column (may overfit the model in train)\n",
    "df_all.drop(['timestamp', 'timestamp_macro'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "factorize = lambda t: pd.factorize(t[1])[0]\n",
    "\n",
    "df_obj = df_all.select_dtypes(include=['object'])\n",
    "\n",
    "X_all = np.c_[\n",
    "    df_all.select_dtypes(exclude=['object']).values,\n",
    "    np.array(list(map(factorize, df_obj.iteritems()))).T\n",
    "]\n",
    "print(X_all.shape)\n",
    "\n",
    "X_train = X_all[:num_train]\n",
    "X_test = X_all[num_train:]\n",
    "\n",
    "\n",
    "# Deal with categorical values\n",
    "df_numeric = df_all.select_dtypes(exclude=['object'])\n",
    "df_obj = df_all.select_dtypes(include=['object']).copy()\n",
    "\n",
    "for c in df_obj:\n",
    "    df_obj[c] = pd.factorize(df_obj[c])[0]\n",
    "\n",
    "df_values = pd.concat([df_numeric, df_obj], axis=1)\n",
    "\n",
    "\n",
    "# Convert to numpy values\n",
    "X_all = df_values.values\n",
    "print(X_all.shape)\n",
    "\n",
    "X_train = X_all[:num_train]\n",
    "X_test = X_all[num_train:]\n",
    "\n",
    "df_columns = df_values.columns\n",
    "\n",
    "\n",
    "xgb_params = {\n",
    "    'eta': 0.05,\n",
    "    'max_depth': 5,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.7,\n",
    "    'objective': 'reg:linear',\n",
    "    'eval_metric': 'rmse',\n",
    "    'silent': 1\n",
    "}\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, y_train, feature_names=df_columns)\n",
    "dtest = xgb.DMatrix(X_test, feature_names=df_columns)\n",
    "\n",
    "\n",
    "num_boost_round = 489  # From Bruno's original CV, I think\n",
    "model = xgb.train(dict(xgb_params, silent=0), dtrain, num_boost_round=num_boost_round)\n",
    "\n",
    "y_pred = model.predict(dtest)\n",
    "bruno_model_output = pd.DataFrame({'id': id_test, 'price_doc': y_pred})\n",
    "bruno_model_output.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-20T06:00:56.300090Z",
     "start_time": "2017-06-20T06:00:56.273544Z"
    },
    "_cell_guid": "35c8fbfb-4f6d-cd98-5cc0-cf44a97cc14a",
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6705746.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bruno_model_output.to_csv('bruno_model.csv', index=False)\n",
    "np.exp( bruno_model_output.price_doc.apply(np.log).mean() )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4c2eefab-fa97-a1d4-1b9e-574522f3e3c7",
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "source": [
    "## Merge and adjust the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-20T06:00:56.341327Z",
     "start_time": "2017-06-20T06:00:56.305137Z"
    },
    "_cell_guid": "41c97a7b-f063-7501-039b-7d1d681821a5",
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price_doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30474</td>\n",
       "      <td>5591923.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30475</td>\n",
       "      <td>7970427.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30476</td>\n",
       "      <td>5628567.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30477</td>\n",
       "      <td>5733224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30478</td>\n",
       "      <td>5209894.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  price_doc\n",
       "0  30474  5591923.0\n",
       "1  30475  7970427.5\n",
       "2  30476  5628567.0\n",
       "3  30477  5733224.0\n",
       "4  30478  5209894.5"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge\n",
    "results = reynaldo_model_output.merge( \n",
    "             jason_model_output.merge(\n",
    "                 bruno_model_output, on='id', suffixes=['_jason','_bruno'] ), on='id' )\n",
    "results[\"price_doc_reynaldo\"] = results[\"price_doc\"]\n",
    "results[\"price_doc\"] = np.exp( np.log(results.price_doc_reynaldo)*reynaldo_weight +\n",
    "                               np.log(results.price_doc_jason)*jason_weight       +\n",
    "                               np.log(results.price_doc_bruno)*bruno_weight          )\n",
    "\n",
    "results.drop([\"price_doc_reynaldo\", \"price_doc_bruno\", \"price_doc_jason\"],axis=1,inplace=True)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-20T06:00:56.368742Z",
     "start_time": "2017-06-20T06:00:56.344643Z"
    },
    "_cell_guid": "f1747b78-8340-ba92-0f5c-4accacb3d01f",
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "results.to_csv('unadjusted_combo.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-20T06:00:56.386190Z",
     "start_time": "2017-06-20T06:00:56.371429Z"
    },
    "_cell_guid": "750d077d-71e9-0480-9853-5bfcbf5ea212",
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Functions to use in data adjustment\n",
    "\n",
    "def scale_miss(\n",
    "        alpha,\n",
    "        shifted_logs,\n",
    "        oldstd,\n",
    "        new_logmean\n",
    "        ):\n",
    "    newlogs = new_logmean + alpha*(shifted_logs - new_logmean)\n",
    "    newstd = np.std(np.exp(newlogs))\n",
    "    return (newstd-oldstd)**2\n",
    "    \n",
    "\n",
    "def shift_logmean_but_keep_scale(  # Or change the scale, but relative to the old scale\n",
    "        data,\n",
    "        new_logmean,\n",
    "        rescaler\n",
    "        ):\n",
    "    logdata = np.log(data)\n",
    "    oldstd = data.std()\n",
    "    shift = new_logmean - logdata.mean()\n",
    "    shifted_logs = logdata + shift\n",
    "    scale = sp.optimize.leastsq( scale_miss, 1, args=(shifted_logs, oldstd, new_logmean) )\n",
    "    alpha = scale[0][0]\n",
    "    newlogs = new_logmean + rescaler*alpha*(shifted_logs - new_logmean)\n",
    "    return np.exp(newlogs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-06-20T06:00:56.477039Z",
     "start_time": "2017-06-20T06:00:56.388555Z"
    },
    "_cell_guid": "07ca5900-fb83-b2d7-b7bd-71ab69179b7b",
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>price_doc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30474</td>\n",
       "      <td>5438761.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30475</td>\n",
       "      <td>7795607.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30476</td>\n",
       "      <td>5474965.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30477</td>\n",
       "      <td>5578388.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>30478</td>\n",
       "      <td>5061540.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  price_doc\n",
       "0  30474  5438761.0\n",
       "1  30475  7795607.5\n",
       "2  30476  5474965.5\n",
       "3  30477  5578388.5\n",
       "4  30478  5061540.5"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adjust\n",
    "lnm = np.log(macro_mean)\n",
    "y_predict = shift_logmean_but_keep_scale( results.price_doc, lnm, micro_humility_factor )\n",
    "\n",
    "sub = pd.DataFrame({'id': id_test, 'price_doc': y_predict})\n",
    "\n",
    "# sub = price_meter_to_doc(test.merge(sub, on=\"id\"))[[\"id\", \"price_doc\"]]\n",
    "sub.to_csv('andy_sub.csv', index=False)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "run_control": {
     "frozen": false,
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_change_revision": 141,
  "_is_fork": false,
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "102px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
