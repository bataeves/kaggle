{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-13T07:44:25.587559Z",
     "start_time": "2017-08-13T07:44:17.389400Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.venv/local/lib/python2.7/site-packages/IPython/config.py:13: ShimWarning: The `IPython.config` package has been deprecated since IPython 4.0. You should import from traitlets.config instead.\n",
      "  \"You should import from traitlets.config instead.\", ShimWarning)\n",
      "/home/ubuntu/.venv/local/lib/python2.7/site-packages/IPython/utils/traitlets.py:5: UserWarning: IPython.utils.traitlets has moved to a top-level traitlets package.\n",
      "  warn(\"IPython.utils.traitlets has moved to a top-level traitlets package.\")\n"
     ]
    }
   ],
   "source": [
    "# Author : Paul-Antoine Nguyen\n",
    "\n",
    "# This script considers all the products a user has ordered\n",
    "#\n",
    "# We train a model computing the probability of reorder on the \"train\" data\n",
    "#\n",
    "# For the submission, we keep the orders that have a probability of\n",
    "# reorder higher than a threshold\n",
    "\n",
    "# some overhead because of kernel memory limits\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "import gc\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "tqdm.pandas(desc=\"\")\n",
    "\n",
    "%load_ext ipycache\n",
    "%load_ext cython\n",
    "\n",
    "IDIR = 'input/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2017-08-12T10:56:43.982Z"
    }
   },
   "outputs": [],
   "source": [
    "print('loading prior')\n",
    "priors = pd.read_csv(IDIR + 'order_products__prior.csv')\n",
    "print('loading train')\n",
    "\n",
    "op_train = pd.read_csv(\n",
    "    IDIR + 'order_products__train.csv', \n",
    "    index_col=['order_id', 'product_id']\n",
    ")\n",
    "train_index = set(op_train.index)\n",
    "del op_train\n",
    "\n",
    "print('loading orders')\n",
    "orders = pd.read_csv(IDIR + 'orders.csv')\n",
    "print('loading products')\n",
    "products = pd.read_csv(IDIR + 'products.csv')\n",
    "\n",
    "departments = pd.read_csv(IDIR + 'departments.csv', engine='c')\n",
    "aisles = pd.read_csv(IDIR + 'aisles.csv', engine='c')\n",
    "\n",
    "print('priors {}: {}'.format(priors.shape, ', '.join(priors.columns)))\n",
    "print('orders {}: {}'.format(orders.shape, ', '.join(orders.columns)))\n",
    "# print('train {}: {}'.format(op_train.shape, ', '.join(op_train.columns)))\n",
    "print('Total departments: {}'.format(departments.shape[0]))\n",
    "print('Total aisles: {}'.format(aisles.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-07T22:23:14.718658Z",
     "start_time": "2017-08-07T22:23:13.290603Z"
    }
   },
   "outputs": [],
   "source": [
    "orders.order_dow = orders.order_dow.astype(np.int8)\n",
    "orders.order_hour_of_day = orders.order_hour_of_day.astype(np.int8)\n",
    "orders.order_number = orders.order_number.astype(np.int16)\n",
    "orders.order_id = orders.order_id.astype(np.int32)\n",
    "orders.user_id = orders.user_id.astype(np.int32)\n",
    "orders.days_since_prior_order = orders.days_since_prior_order.astype(np.float32)\n",
    "orders.set_index('order_id', inplace=True, drop=False)\n",
    "\n",
    "products.drop(['product_name'], axis=1, inplace=True)\n",
    "products.aisle_id = products.aisle_id.astype(np.int8)\n",
    "products.department_id = products.department_id.astype(np.int8)\n",
    "products.product_id = products.product_id.astype(np.int32)\n",
    "products.set_index('product_id', drop=False, inplace=True)\n",
    "\n",
    "# op_train.reordered = op_train.reordered.astype(np.int8)\n",
    "# op_train.add_to_cart_order = op_train.add_to_cart_order.astype(np.int16)\n",
    "# op_train.set_index(['order_id', 'product_id'], inplace=True, drop=False)\n",
    "\n",
    "priors.order_id = priors.order_id.astype(np.int32)\n",
    "priors.add_to_cart_order = priors.add_to_cart_order.astype(np.int16)\n",
    "priors.reordered = priors.reordered.astype(np.int8)\n",
    "priors.product_id = priors.product_id.astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://www.kaggle.com/c/instacart-market-basket-analysis/discussion/35468\n",
    "\n",
    "Here are some feature ideas that can help new participants get started and may be you will find something you have missed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-07T22:23:31.515282Z",
     "start_time": "2017-08-07T22:23:14.922932Z"
    }
   },
   "outputs": [],
   "source": [
    "priors = priors.join(orders, on='order_id', rsuffix='_')\n",
    "priors = priors.join(products, on='product_id', rsuffix='_')\n",
    "priors.drop(['product_id_', 'order_id_'], inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-07T22:23:33.742171Z",
     "start_time": "2017-08-07T22:23:31.770503Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "552"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Week No\n",
    "o1_gr = orders.sort_values([\"user_id\", \"order_number\"]).groupby(\"user_id\").agg({\"days_since_prior_order\": \"cumsum\"})\n",
    "orders[\"user_weekno\"] = (o1_gr[\"days_since_prior_order\"] / 7).round().fillna(0)\n",
    "orders[\"user_days\"] = o1_gr[\"days_since_prior_order\"].fillna(0)\n",
    "\n",
    "# orders = orders.merge(\n",
    "#     orders.groupby(\"user_id\").agg({\n",
    "#         \"user_weekno\": \"max\",\n",
    "#         \"user_days\": \"max\",\n",
    "#     }).rename(\n",
    "#         columns={\n",
    "#             \"user_weekno\": \"user_weekno_max\",\n",
    "#             \"user_days\": \"user_days_max\"\n",
    "#         }\n",
    "#     ).reset_index(),\n",
    "#     on=\"user_id\",\n",
    "#     how=\"left\"\n",
    "# )\n",
    "\n",
    "# orders[\"user_weekno_rev\"] = abs(orders.user_weekno_max - orders.user_weekno).astype(np.int8)\n",
    "# orders[\"user_days_rev\"] = abs(orders.user_days_max - orders.user_days).astype(np.int16)\n",
    "# orders = orders.drop([\"user_weekno_max\", \"user_days_max\"], axis=1)\n",
    "del o1_gr\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Product\n",
    "* ~~users~~\n",
    "* ~~orders~~\n",
    "* ~~order frequency~~\n",
    "* ~~reorder rate~~\n",
    "* recency\n",
    "* ~~mean/std add_to_cart_order~~\n",
    "* etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-07T22:23:57.442715Z",
     "start_time": "2017-08-07T22:23:33.920357Z"
    }
   },
   "outputs": [],
   "source": [
    "prods = pd.DataFrame()\n",
    "p_grouped = priors.groupby(\"product_id\")\n",
    "\n",
    "prods['orders'] = p_grouped.size().astype(np.float32)\n",
    "prods['order_freq'] = prods['orders'] / len(priors.order_id.unique())\n",
    "prods['users'] = p_grouped.user_id.unique().apply(len)\n",
    "prods['add_to_cart_order_mean'] = p_grouped.add_to_cart_order.mean()\n",
    "prods['add_to_cart_order_std'] = p_grouped.add_to_cart_order.std()\n",
    "\n",
    "prods['reorders'] = p_grouped['reordered'].sum().astype(np.int32)\n",
    "prods['reorders_max'] = p_grouped['reordered'].max().astype(np.int32)\n",
    "prods['reorders_min'] = p_grouped['reordered'].min().astype(np.int32)\n",
    "prods['reorders_mean'] = p_grouped['reordered'].mean().astype(np.float32)\n",
    "prods['reorders_std'] = p_grouped['reordered'].std().astype(np.float32)\n",
    "\n",
    "prods['reorder_rate'] = (prods.reorders / prods.orders).astype(np.float32)\n",
    "\n",
    "products = products.join(prods)\n",
    "del prods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-16T13:37:31.059319Z",
     "start_time": "2017-07-16T13:37:31.048484Z"
    }
   },
   "source": [
    "## User"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Products purchased\n",
    "* Orders made\n",
    "* frequency and recency of orders\n",
    "* Aisle purchased from\n",
    "* Department purchased from\n",
    "* frequency and recency of reorders\n",
    "* tenure\n",
    "* mean order size\n",
    "* etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-07T22:25:42.769765Z",
     "start_time": "2017-08-07T22:23:57.751464Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "91"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user f (206209, 17)\n"
     ]
    }
   ],
   "source": [
    "usr = pd.DataFrame()\n",
    "o_grouped = orders.groupby('user_id')\n",
    "p_grouped = priors.groupby('user_id')\n",
    "usr['average_days_between_orders'] = o_grouped.days_since_prior_order.mean().astype(np.float32)\n",
    "usr['max_days_between_orders'] = o_grouped.days_since_prior_order.max().astype(np.float32)\n",
    "usr['min_days_between_orders'] = o_grouped.days_since_prior_order.min().astype(np.float32)\n",
    "usr['std_days_between_orders'] = o_grouped.days_since_prior_order.std().astype(np.float32)\n",
    "\n",
    "usr[\"period\"] = o_grouped.days_since_prior_order.fillna(0).sum()\n",
    "usr[\"weeks\"] = o_grouped.user_weekno.fillna(0).max()\n",
    "usr['nb_orders'] = o_grouped.size().astype(np.int16)\n",
    "\n",
    "users = pd.DataFrame()\n",
    "users['total_items'] = p_grouped.size().astype(np.int16)\n",
    "users['all_products'] = p_grouped['product_id'].apply(set)\n",
    "users['total_distinct_items'] = (users.all_products.map(len)).astype(np.int16)\n",
    "\n",
    "users['reorders'] = p_grouped[\"reordered\"].sum().astype(np.int32)\n",
    "users['reorders_max'] = p_grouped[\"reordered\"].max().astype(np.int32)\n",
    "users['reorders_min'] = p_grouped[\"reordered\"].min().astype(np.int32)\n",
    "users['reorders_mean'] = p_grouped[\"reordered\"].mean().astype(np.float32)\n",
    "users['reorders_std'] = p_grouped[\"reordered\"].std().astype(np.float32)\n",
    "\n",
    "users = users.join(usr)\n",
    "\n",
    "users['reorder_rate'] = (users.reorders / users.nb_orders).astype(np.float32)\n",
    "users['average_basket'] = (users.total_items / users.nb_orders).astype(np.float32)\n",
    "del usr\n",
    "gc.collect()\n",
    "print('user f', users.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-05T11:27:29.358854Z",
     "start_time": "2017-08-05T11:27:29.350904Z"
    }
   },
   "source": [
    "## Aisle\n",
    "* users\n",
    "* orders\n",
    "* order frequency\n",
    "* reorder rate\n",
    "* recency\n",
    "* mean add_to_cart_order\n",
    "* etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-07T22:25:49.916018Z",
     "start_time": "2017-08-07T22:25:43.209046Z"
    }
   },
   "outputs": [],
   "source": [
    "prods = pd.DataFrame()\n",
    "p_grouped = priors.groupby(\"aisle_id\")\n",
    "\n",
    "prods['orders'] = p_grouped.size().astype(np.float32)\n",
    "prods['order_freq'] = (prods['orders'] / len(priors.order_id.unique())).astype(np.float32)\n",
    "prods['users'] = p_grouped.user_id.unique().apply(len).astype(np.float32)\n",
    "prods['add_to_cart_order_mean'] = p_grouped.add_to_cart_order.mean().astype(np.float32)\n",
    "prods['add_to_cart_order_std'] = p_grouped.add_to_cart_order.std().astype(np.float32)\n",
    "\n",
    "prods['reorders'] = p_grouped['reordered'].sum().astype(np.float32)\n",
    "prods['reorder_rate'] = (prods.reorders / prods.orders).astype(np.float32)\n",
    "\n",
    "aisles.set_index('aisle_id', drop=False, inplace=True)\n",
    "aisles = aisles.join(prods)\n",
    "\n",
    "del prods, p_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Department\n",
    "* users\n",
    "* orders\n",
    "* order frequency\n",
    "* reorder rate\n",
    "* recency\n",
    "* mean add_to_cart_order\n",
    "* etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-07T22:25:55.504924Z",
     "start_time": "2017-08-07T22:25:50.380314Z"
    }
   },
   "outputs": [],
   "source": [
    "prods = pd.DataFrame()\n",
    "p_grouped = priors.groupby(\"department_id\")\n",
    "\n",
    "prods['orders'] = p_grouped.size().astype(np.float32)\n",
    "prods['order_freq'] = (prods['orders'] / len(priors.order_id.unique())).astype(np.float32)\n",
    "prods['users'] = p_grouped.user_id.unique().apply(len).astype(np.float32)\n",
    "prods['add_to_cart_order_mean'] = p_grouped.add_to_cart_order.mean().astype(np.float32)\n",
    "prods['add_to_cart_order_std'] = p_grouped.add_to_cart_order.std().astype(np.float32)\n",
    "\n",
    "prods['reorders'] = p_grouped['reordered'].sum().astype(np.float32)\n",
    "prods['reorder_rate'] = (prods.reorders / prods.orders).astype(np.float32)\n",
    "\n",
    "departments.set_index('department_id', drop=False, inplace=True)\n",
    "departments = departments.join(prods)\n",
    "\n",
    "del prods, p_grouped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User Product Interaction (UP)\n",
    "* purchases\n",
    "* reorders\n",
    "* day since last purchase\n",
    "* order since last purchase\n",
    "* etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-07T22:25:56.061900Z",
     "start_time": "2017-08-07T22:25:55.978539Z"
    }
   },
   "outputs": [],
   "source": [
    "orders_last = orders[[\"order_id\", \"order_number\", \"user_id\"]].rename(\n",
    "    columns={\"order_id\": \"last_order_id\"}\n",
    ")\n",
    "orders_first = orders[[\"order_id\", \"order_number\", \"user_id\"]].rename(\n",
    "    columns={\"order_id\": \"first_order_id\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-07T22:25:56.606431Z",
     "start_time": "2017-08-07T22:25:56.602749Z"
    }
   },
   "outputs": [],
   "source": [
    "def flat_columns(df):\n",
    "    ind = pd.Index([\"%s\" % (e[1]) for e in df.columns.tolist()])\n",
    "    df.columns = ind\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-07T22:26:51.875117Z",
     "start_time": "2017-08-07T22:25:57.149399Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.venv/local/lib/python2.7/site-packages/pandas/core/groupby.py:4036: FutureWarning: using a dict with renaming is deprecated and will be removed in a future version\n",
      "  return super(DataFrameGroupBy, self).aggregate(arg, *args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "179"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user X product f 13293564\n"
     ]
    }
   ],
   "source": [
    "priors['z'] = priors.product_id + priors.user_id * 100000\n",
    "userXproduct = priors.groupby([\"z\", \"user_id\"]).agg({\n",
    "    \"order_id\": {\"nb_orders\": \"count\"},\n",
    "    \"order_number\": {\n",
    "        \"last_order_number\": \"max\", \n",
    "        \"first_order_number\": \"min\"\n",
    "    },\n",
    "    \"add_to_cart_order\": {\n",
    "        \"sum_add_to_cart_order\": \"sum\",\n",
    "        \"min_add_to_cart_order\": \"min\",\n",
    "        \"max_add_to_cart_order\": \"max\",\n",
    "        \"mean_add_to_cart_order\": \"mean\",\n",
    "        \"std_add_to_cart_order\": \"std\"\n",
    "    },\n",
    "    \"reordered\": {\n",
    "        \"sum_reordered\": \"sum\", \n",
    "        \"mean_reordered\": \"mean\", \n",
    "        \"std_reordered\": \"std\"\n",
    "    }\n",
    "})\n",
    "\n",
    "userXproduct = flat_columns(userXproduct).reset_index()\n",
    "userXproduct = userXproduct.merge(\n",
    "    orders_last, \n",
    "    left_on=[\"user_id\", \"last_order_number\"],\n",
    "    right_on=[\"user_id\", \"order_number\"]\n",
    ").drop(\"order_number\", axis=1)\n",
    "\n",
    "userXproduct = userXproduct.merge(\n",
    "    orders_first, \n",
    "    left_on=[\"user_id\", \"first_order_number\"],\n",
    "    right_on=[\"user_id\", \"order_number\"]\n",
    ").drop([\"user_id\", \"order_number\"], axis=1)\n",
    "userXproduct.drop_duplicates(subset=[\"z\"], inplace=True)\n",
    "userXproduct.set_index(\"z\", inplace=True)\n",
    "# d = dict()\n",
    "# for row in tqdm(priors.itertuples(), total=len(priors)):\n",
    "#     z = row.z\n",
    "#     if z not in d:\n",
    "#         d[z] = (\n",
    "#             1,\n",
    "#             (row.order_number, row.order_id),\n",
    "#             row.add_to_cart_order,\n",
    "#             row.reordered\n",
    "#         )\n",
    "#     else:\n",
    "#         d[z] = (\n",
    "#             d[z][0] + 1,\n",
    "#             max(d[z][1], (row.order_number, row.order_id)),\n",
    "#             d[z][2] + row.add_to_cart_order,\n",
    "#             d[z][3] + row.reordered\n",
    "#         )\n",
    "\n",
    "# # priors.drop(['z'], axis=1, inplace=True)\n",
    "\n",
    "# print('to dataframe (less memory)')\n",
    "# d = pd.DataFrame.from_dict(d, orient='index')\n",
    "# d.columns = ['nb_orders', 'last_order_id', 'sum_pos_in_cart', 'reorders']\n",
    "# d.nb_orders = d.nb_orders.astype(np.int16)\n",
    "# d.last_order_id = d.last_order_id.map(lambda x: x[1]).astype(np.int32)\n",
    "# d.sum_pos_in_cart = d.sum_pos_in_cart.astype(np.int16)\n",
    "# d.reorders = d.reorders.astype(np.int16)\n",
    "   \n",
    "# userXproduct = d\n",
    "gc.collect()\n",
    "print('user X product f', len(userXproduct))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User aisle interaction (UA)\n",
    "* purchases\n",
    "* reorders\n",
    "* day since last purchase\n",
    "* order since last purchase\n",
    "* etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-07T22:27:21.847403Z",
     "start_time": "2017-08-07T22:26:52.488908Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user X aisle f 5729249\n"
     ]
    }
   ],
   "source": [
    "priors['z'] = priors.aisle_id + priors.user_id * 100000\n",
    "userXaisle = priors.groupby([\"z\", \"user_id\"]).agg({\n",
    "    \"order_id\": {\"nb_orders\": \"count\"},\n",
    "    \"order_number\": {\n",
    "        \"last_order_number\": \"max\", \n",
    "        \"first_order_number\": \"min\"\n",
    "    },\n",
    "    \"add_to_cart_order\": {\n",
    "        \"sum_add_to_cart_order\": \"sum\",\n",
    "        \"min_add_to_cart_order\": \"min\",\n",
    "        \"max_add_to_cart_order\": \"max\",\n",
    "        \"mean_add_to_cart_order\": \"mean\",\n",
    "        \"std_add_to_cart_order\": \"std\"\n",
    "    },\n",
    "    \"reordered\": {\n",
    "        \"sum_reordered\": \"sum\", \n",
    "        \"mean_reordered\": \"mean\", \n",
    "        \"std_reordered\": \"std\"\n",
    "    }\n",
    "})\n",
    "\n",
    "userXaisle = flat_columns(userXaisle).reset_index()\n",
    "userXaisle = userXaisle.merge(\n",
    "    orders_last, \n",
    "    left_on=[\"user_id\", \"last_order_number\"],\n",
    "    right_on=[\"user_id\", \"order_number\"]\n",
    ").drop(\"order_number\", axis=1)\n",
    "\n",
    "userXaisle = userXaisle.merge(\n",
    "    orders_first, \n",
    "    left_on=[\"user_id\", \"first_order_number\"],\n",
    "    right_on=[\"user_id\", \"order_number\"]\n",
    ").drop([\"user_id\", \"order_number\"], axis=1)\n",
    "userXaisle.drop_duplicates(subset=[\"z\"], inplace=True)\n",
    "userXaisle.set_index(\"z\", inplace=True)\n",
    "gc.collect()\n",
    "print('user X aisle f', len(userXaisle))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User department interaction (UD)\n",
    "* purchases\n",
    "* reorders\n",
    "* day since last purchase\n",
    "* order since last purchase\n",
    "* etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-07T22:27:41.179636Z",
     "start_time": "2017-08-07T22:27:22.530294Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "225"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user X department f 2232789\n"
     ]
    }
   ],
   "source": [
    "priors['z'] = priors.department_id + priors.user_id * 100000\n",
    "userXdepartment = priors.groupby([\"z\", \"user_id\"]).agg({\n",
    "    \"order_id\": {\"nb_orders\": \"count\"},\n",
    "    \"order_number\": {\n",
    "        \"last_order_number\": \"max\", \n",
    "        \"first_order_number\": \"min\"\n",
    "    },\n",
    "    \"add_to_cart_order\": {\n",
    "        \"sum_add_to_cart_order\": \"sum\",\n",
    "        \"min_add_to_cart_order\": \"min\",\n",
    "        \"max_add_to_cart_order\": \"max\",\n",
    "        \"mean_add_to_cart_order\": \"mean\",\n",
    "        \"std_add_to_cart_order\": \"std\"\n",
    "    },\n",
    "    \"reordered\": {\n",
    "        \"sum_reordered\": \"sum\", \n",
    "        \"mean_reordered\": \"mean\", \n",
    "        \"std_reordered\": \"std\"\n",
    "    }\n",
    "})\n",
    "\n",
    "userXdepartment = flat_columns(userXdepartment).reset_index()\n",
    "userXdepartment = userXdepartment.merge(\n",
    "    orders_last, \n",
    "    left_on=[\"user_id\", \"last_order_number\"],\n",
    "    right_on=[\"user_id\", \"order_number\"]\n",
    ").drop(\"order_number\", axis=1)\n",
    "\n",
    "userXdepartment = userXdepartment.merge(\n",
    "    orders_first, \n",
    "    left_on=[\"user_id\", \"first_order_number\"],\n",
    "    right_on=[\"user_id\", \"order_number\"]\n",
    ").drop([\"user_id\", \"order_number\"], axis=1)\n",
    "userXdepartment.drop_duplicates(subset=[\"z\"], inplace=True)\n",
    "userXdepartment.set_index(\"z\", inplace=True)\n",
    "gc.collect()\n",
    "print('user X department f', len(userXdepartment))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## User time interaction (UT)\n",
    "* user preferred day of week\n",
    "* user preferred time of day\n",
    "* similar features for products and aisles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-12T11:02:04.865647Z",
     "start_time": "2017-08-12T11:02:04.197710Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'op_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-05007ade1cea>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m### build list of candidate products to reorder, with features ###\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mselected_orders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels_given\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0morder_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'op_train' is not defined"
     ]
    }
   ],
   "source": [
    "### build list of candidate products to reorder, with features ###\n",
    "train_index = set(op_train.index)\n",
    "\n",
    "def features(selected_orders, labels_given=False):\n",
    "    order_list = []\n",
    "    product_list = []\n",
    "    labels = []\n",
    "    for row in tqdm(selected_orders.itertuples(), total=len(selected_orders)):\n",
    "        order_id = row.order_id\n",
    "        user_id = row.user_id\n",
    "        user_products = list(users.all_products[user_id])\n",
    "        product_list += user_products\n",
    "        order_list += [order_id] * len(user_products)\n",
    "        if labels_given:\n",
    "            labels += [\n",
    "                (order_id, product) in train_index \n",
    "                for product in user_products\n",
    "            ]\n",
    "        \n",
    "    df = pd.DataFrame({'order_id': order_list, 'product_id': product_list})\n",
    "    df.order_id = df.order_id.astype(np.int32)\n",
    "    df.product_id = df.product_id.astype(np.int32)\n",
    "    df['user_id'] = df.order_id.map(orders.user_id).astype(np.int32)\n",
    "    df['aisle_id'] = df.product_id.map(products.aisle_id).astype(np.int8)\n",
    "    df['department_id'] = df.product_id.map(products.department_id).astype(np.int8)\n",
    "\n",
    "    labels = np.array(labels, dtype=np.int8)\n",
    "    del order_list\n",
    "    del product_list\n",
    "    \n",
    "    print('user related features')\n",
    "    df['user_total_orders'] = df.user_id.map(users.nb_orders)\n",
    "    df['user_total_items'] = df.user_id.map(users.total_items)\n",
    "    df['user_total_distinct_items'] = df.user_id.map(users.total_distinct_items)\n",
    "    df['user_average_days_between_orders'] = df.user_id.map(users.average_days_between_orders)\n",
    "    df['user_max_days_between_orders'] = df.user_id.map(users.max_days_between_orders)\n",
    "    df['user_min_days_between_orders'] = df.user_id.map(users.min_days_between_orders)\n",
    "    df['user_std_days_between_orders'] = df.user_id.map(users.std_days_between_orders)\n",
    "    df['user_average_basket'] =  df.user_id.map(users.average_basket)\n",
    "\n",
    "    df['user_reorders'] =  df.user_id.map(users.reorders)\n",
    "    df['user_reorders_max'] =  df.user_id.map(users.reorders_max)\n",
    "    df['user_reorders_min'] =  df.user_id.map(users.reorders_min)\n",
    "    df['user_reorders_mean'] =  df.user_id.map(users.reorders_mean)\n",
    "    df['user_reorders_std'] =  df.user_id.map(users.reorders_std)\n",
    "    df['user_reorder_rate'] =  df.user_id.map(users.reorder_rate)\n",
    "    df['user_period'] =  df.user_id.map(users.period)\n",
    "    \n",
    "    print('order related features')\n",
    "    df['dow'] = df.order_id.map(orders.order_dow)\n",
    "    df['order_hour_of_day'] = df.order_id.map(orders.order_hour_of_day)\n",
    "    df['days_since_prior_order'] = df.order_id.map(orders.days_since_prior_order)\n",
    "    df['days_since_ratio'] = df.days_since_prior_order / df.user_average_days_between_orders\n",
    "    \n",
    "    print('product related features')\n",
    "    df['product_orders'] = df.product_id.map(products.orders).astype(np.float32)\n",
    "    df['product_users'] = df.product_id.map(products.users).astype(np.float32)\n",
    "    df['product_order_freq'] = df.product_id.map(products.order_freq).astype(np.float32)\n",
    "\n",
    "    df['product_reorders'] = df.product_id.map(products.reorders)\n",
    "    df['product_reorders_max'] = df.product_id.map(products.reorders_max)\n",
    "    df['product_reorders_min'] = df.product_id.map(products.reorders_min)\n",
    "    df['product_reorders_mean'] = df.product_id.map(products.reorders_mean)\n",
    "    df['product_reorders_std'] = df.product_id.map(products.reorders_std)\n",
    "    df['product_reorder_rate'] = df.product_id.map(products.reorder_rate)\n",
    "    df['product_add_to_cart_order_mean'] = df.product_id.map(products.add_to_cart_order_mean).astype(np.float32)\n",
    "    df['product_add_to_cart_order_std'] = df.product_id.map(products.add_to_cart_order_std).astype(np.float32)\n",
    "\n",
    "    print('aisle related features')\n",
    "    df['aisle_orders'] = df.aisle_id.map(aisles.orders)\n",
    "    df['aisle_users'] = df.aisle_id.map(aisles.users)\n",
    "    df['aisle_order_freq'] = df.aisle_id.map(aisles.order_freq)\n",
    "    df['aisle_reorders'] = df.aisle_id.map(aisles.reorders)\n",
    "    df['aisle_reorder_rate'] = df.aisle_id.map(aisles.reorder_rate)\n",
    "    df['aisle_add_to_cart_order_mean'] = df.aisle_id.map(aisles.add_to_cart_order_mean)\n",
    "    df['aisle_add_to_cart_order_std'] = df.aisle_id.map(aisles.add_to_cart_order_std)\n",
    "    \n",
    "    print('department related features')\n",
    "    df['department_orders'] = df.department_id.map(departments.orders)\n",
    "    df['department_users'] = df.department_id.map(departments.users)\n",
    "    df['department_order_freq'] = df.department_id.map(departments.order_freq)\n",
    "    df['department_reorders'] = df.department_id.map(departments.reorders)\n",
    "    df['department_reorder_rate'] = df.department_id.map(departments.reorder_rate)\n",
    "    df['department_add_to_cart_order_mean'] = df.department_id.map(departments.add_to_cart_order_mean)\n",
    "    df['department_add_to_cart_order_std'] = df.department_id.map(departments.add_to_cart_order_std)\n",
    "\n",
    "    print('user_X_product related features')\n",
    "    df['z'] = df.product_id + df.user_id * 100000\n",
    "    df['UP_orders'] = df.z.map(userXproduct.nb_orders)\n",
    "    df['UP_orders_ratio'] = (df.UP_orders / df.user_total_orders).astype(np.float32)\n",
    "    df['UP_last_order_id'] = df.z.map(userXproduct.last_order_id)\n",
    "    df['UP_first_order_id'] = df.z.map(userXproduct.first_order_id)\n",
    "    \n",
    "    df['UP_average_pos_in_cart'] = (df.z.map(userXproduct.sum_add_to_cart_order) / df.UP_orders).astype(np.float32)\n",
    "    df['UP_sum_add_to_cart_order'] = df.z.map(userXproduct.sum_add_to_cart_order)\n",
    "    df['UP_min_add_to_cart_order'] = df.z.map(userXproduct.min_add_to_cart_order)\n",
    "    df['UP_mean_add_to_cart_order'] = df.z.map(userXproduct.mean_add_to_cart_order)\n",
    "    df['UP_max_add_to_cart_order'] = df.z.map(userXproduct.max_add_to_cart_order)\n",
    "    df['UP_std_add_to_cart_order'] = df.z.map(userXproduct.std_add_to_cart_order)\n",
    "\n",
    "    df['UP_sum_reordered'] = df.z.map(userXproduct.sum_reordered)\n",
    "    df['UP_mean_reordered'] = df.z.map(userXproduct.mean_reordered)\n",
    "    df['UP_std_reordered'] = df.z.map(userXproduct.std_reordered)\n",
    "    df['UP_reorders_rate'] = (df.UP_sum_reordered / df.UP_orders).astype(np.float32)\n",
    "\n",
    "    df['UP_last_order_number'] = df.UP_last_order_id.map(orders.order_number)\n",
    "    df['UP_first_order_number'] = df.UP_first_order_id.map(orders.order_number)\n",
    "    df['UP_last_order_number_prc'] = (df.UP_last_order_number / df.user_total_orders).astype(np.float32)\n",
    "    df['UP_first_order_number_prc'] = (df.UP_first_order_number / df.user_total_orders).astype(np.float32)\n",
    "\n",
    "    df['UP_orders_since_last'] = df.user_total_orders - df.UP_last_order_number\n",
    "    df['UP_orders_rate_since_first_order'] = df.UP_orders / (df.user_total_orders - df.UP_first_order_number + 1)\n",
    "    \n",
    "    df['UP_weeks_sinse_last'] = df.UP_last_order_id.map(orders.user_weekno) - df.order_id.map(orders.user_weekno)\n",
    "    df['UP_days_sinse_last'] = df.UP_last_order_id.map(orders.user_days) - df.order_id.map(orders.user_days)\n",
    "    \n",
    "    df['UP_delta_hour_vs_last'] = abs(df.order_hour_of_day - \\\n",
    "                  df.UP_last_order_id.map(orders.order_hour_of_day)).map(\n",
    "        lambda x: min(x, 24-x)\n",
    "    ).astype(np.int8)\n",
    "\n",
    "    print('user_X_aisle related features')\n",
    "    df['z'] = df.aisle_id + df.user_id * 100000\n",
    "    df['UA_orders'] = df.z.map(userXaisle.nb_orders)\n",
    "    df['UA_orders_ratio'] = (df.UA_orders / df.user_total_orders).astype(np.float32)\n",
    "    df['UA_last_order_id'] = df.z.map(userXaisle.last_order_id)\n",
    "    df['UA_first_order_id'] = df.z.map(userXaisle.first_order_id)\n",
    "    \n",
    "    df['UA_average_pos_in_cart'] = (df.z.map(userXaisle.sum_add_to_cart_order) / df.UA_orders).astype(np.float32)\n",
    "    df['UA_sum_add_to_cart_order'] = df.z.map(userXaisle.sum_add_to_cart_order)\n",
    "    df['UA_min_add_to_cart_order'] = df.z.map(userXaisle.min_add_to_cart_order)\n",
    "    df['UA_mean_add_to_cart_order'] = df.z.map(userXaisle.mean_add_to_cart_order)\n",
    "    df['UA_max_add_to_cart_order'] = df.z.map(userXaisle.max_add_to_cart_order)\n",
    "    df['UA_std_add_to_cart_order'] = df.z.map(userXaisle.std_add_to_cart_order)\n",
    "\n",
    "    df['UA_sum_reordered'] = df.z.map(userXaisle.sum_reordered)\n",
    "    df['UA_mean_reordered'] = df.z.map(userXaisle.mean_reordered)\n",
    "    df['UA_std_reordered'] = df.z.map(userXaisle.std_reordered)\n",
    "    df['UA_reorders_rate'] = (df.UA_sum_reordered / df.UA_orders).astype(np.float32)\n",
    "\n",
    "    df['UA_last_order_number'] = df.UA_last_order_id.map(orders.order_number)\n",
    "    df['UA_first_order_number'] = df.UA_first_order_id.map(orders.order_number)\n",
    "    df['UA_last_order_number_prc'] = (df.UA_last_order_number / df.user_total_orders).astype(np.float32)\n",
    "    df['UA_first_order_number_prc'] = (df.UA_first_order_number / df.user_total_orders).astype(np.float32)\n",
    "\n",
    "    df['UA_orders_since_last'] = df.user_total_orders - df.UA_last_order_number\n",
    "    df['UA_orders_rate_since_first_order'] = df.UA_orders / (df.user_total_orders - df.UA_first_order_number + 1)\n",
    "    \n",
    "    df['UA_weeks_sinse_last'] = df.UA_last_order_id.map(orders.user_weekno) - df.order_id.map(orders.user_weekno)\n",
    "    df['UA_days_sinse_last'] = df.UA_last_order_id.map(orders.user_days) - df.order_id.map(orders.user_days)\n",
    "    \n",
    "    df['UA_delta_hour_vs_last'] = abs(df.order_hour_of_day - \\\n",
    "                  df.UA_last_order_id.map(orders.order_hour_of_day)).map(\n",
    "        lambda x: min(x, 24-x)\n",
    "    ).astype(np.int8)\n",
    "\n",
    "    print('user_X_department related features')\n",
    "    df['z'] = df.department_id + df.user_id * 100000\n",
    "    df['UD_orders'] = df.z.map(userXdepartment.nb_orders)\n",
    "    df['UD_orders_ratio'] = (df.UD_orders / df.user_total_orders).astype(np.float32)\n",
    "    df['UD_last_order_id'] = df.z.map(userXdepartment.last_order_id)\n",
    "    df['UD_first_order_id'] = df.z.map(userXdepartment.first_order_id)\n",
    "    \n",
    "    df['UD_average_pos_in_cart'] = (df.z.map(userXdepartment.sum_add_to_cart_order) / df.UD_orders).astype(np.float32)\n",
    "    df['UD_sum_add_to_cart_order'] = df.z.map(userXdepartment.sum_add_to_cart_order)\n",
    "    df['UD_min_add_to_cart_order'] = df.z.map(userXdepartment.min_add_to_cart_order)\n",
    "    df['UD_mean_add_to_cart_order'] = df.z.map(userXdepartment.mean_add_to_cart_order)\n",
    "    df['UD_max_add_to_cart_order'] = df.z.map(userXdepartment.max_add_to_cart_order)\n",
    "    df['UD_std_add_to_cart_order'] = df.z.map(userXdepartment.std_add_to_cart_order)\n",
    "\n",
    "    df['UD_sum_reordered'] = df.z.map(userXdepartment.sum_reordered)\n",
    "    df['UD_mean_reordered'] = df.z.map(userXdepartment.mean_reordered)\n",
    "    df['UD_std_reordered'] = df.z.map(userXdepartment.std_reordered)\n",
    "    df['UD_reorders_rate'] = (df.UD_sum_reordered / df.UD_orders).astype(np.float32)\n",
    "\n",
    "    df['UD_last_order_number'] = df.UD_last_order_id.map(orders.order_number)\n",
    "    df['UD_first_order_number'] = df.UD_first_order_id.map(orders.order_number)\n",
    "    df['UD_last_order_number_prc'] = (df.UD_last_order_number / df.user_total_orders).astype(np.float32)\n",
    "    df['UD_first_order_number_prc'] = (df.UD_first_order_number / df.user_total_orders).astype(np.float32)\n",
    "\n",
    "    df['UD_orders_since_last'] = df.user_total_orders - df.UD_last_order_number\n",
    "    df['UD_orders_rate_since_first_order'] = df.UD_orders / (df.user_total_orders - df.UD_first_order_number + 1)\n",
    "    \n",
    "    df['UD_weeks_sinse_last'] = df.UD_last_order_id.map(orders.user_weekno) - df.order_id.map(orders.user_weekno)\n",
    "    df['UD_days_sinse_last'] = df.UD_last_order_id.map(orders.user_days) - df.order_id.map(orders.user_days)\n",
    "    \n",
    "    df['UD_delta_hour_vs_last'] = abs(df.order_hour_of_day - \\\n",
    "                  df.UD_last_order_id.map(orders.order_hour_of_day)).map(\n",
    "        lambda x: min(x, 24-x)\n",
    "    ).astype(np.int8)\n",
    "\n",
    "    df.drop([\n",
    "        'UP_last_order_id', 'UP_first_order_id', \n",
    "        'UA_last_order_id', 'UA_first_order_id', \n",
    "        'UD_last_order_id', 'UD_first_order_id', \n",
    "        'z'], axis=1, inplace=True\n",
    "    )\n",
    "\n",
    "    gc.collect()\n",
    "    return (df, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-07T22:31:31.882167Z",
     "start_time": "2017-08-07T22:27:51.272908Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "split orders : train, test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131209/131209 [00:10<00:00, 12301.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user related features\n",
      "order related features\n",
      "product related features\n",
      "aisle related features\n",
      "department related features\n",
      "user_X_product related features\n",
      "user_X_aisle related features\n",
      "user_X_department related features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 75000/75000 [00:02<00:00, 31517.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user related features\n",
      "order related features\n",
      "product related features\n",
      "aisle related features\n",
      "department related features\n",
      "user_X_product related features\n",
      "user_X_aisle related features\n",
      "user_X_department related features\n"
     ]
    }
   ],
   "source": [
    "### train / test orders ###\n",
    "print('split orders : train, test')\n",
    "test_orders = orders[orders.eval_set == 'test']\n",
    "train_orders = orders[orders.eval_set == 'train']\n",
    "\n",
    "df_train, labels = features(train_orders, labels_given=True)\n",
    "df_test, _ = features(test_orders)\n",
    "\n",
    "del test_orders, train_orders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-06T18:04:14.949304Z",
     "start_time": "2017-08-06T18:04:14.939931Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "# None handling Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-07T20:04:15.688053Z",
     "start_time": "2017-08-07T20:04:15.502013Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.venv/lib/python2.7/site-packages/ipykernel_launcher.py:2: FutureWarning: 'order_id' is both a column name and an index level.\n",
      "Defaulting to column but this will raise an ambiguity error in a future version\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "### build list of candidate products to reorder, with features ###\n",
    "df = op_train.groupby(\"order_id\").agg({\"reordered\": \"sum\"})\n",
    "df[\"reordered\"] = df[\"reordered\"].apply(lambda x: 1 if x == 0 else 0)\n",
    "none_labels = df[\"reordered\"].to_dict()\n",
    "\n",
    "def none_features(selected_orders, labels_given=False):\n",
    "    order_list = []\n",
    "    labels = []\n",
    "    for order_id in tqdm(selected_orders, total=len(selected_orders)):\n",
    "        order_list += [order_id]\n",
    "        if labels_given:\n",
    "            labels += [none_labels[order_id]]\n",
    "        \n",
    "    df = pd.DataFrame({'order_id': order_list})\n",
    "    df.order_id = df.order_id.astype(np.int32)\n",
    "    labels = np.array(labels, dtype=np.int8)\n",
    "    del order_list\n",
    "    \n",
    "    print('user related features')\n",
    "    df['user_id'] = df.order_id.map(orders.user_id).astype(np.int32)\n",
    "    df['user_total_orders'] = df.user_id.map(users.nb_orders)\n",
    "    df['user_total_items'] = df.user_id.map(users.total_items)\n",
    "    df['user_total_distinct_items'] = df.user_id.map(users.total_distinct_items)\n",
    "    df['user_average_days_between_orders'] = df.user_id.map(users.average_days_between_orders)\n",
    "    df['user_average_basket'] =  df.user_id.map(users.average_basket)\n",
    "    df['user_period'] =  df.user_id.map(users.period)\n",
    "    \n",
    "    print('order related features')\n",
    "    df['dow'] = df.order_id.map(orders.order_dow)\n",
    "    df['order_hour_of_day'] = df.order_id.map(orders.order_hour_of_day)\n",
    "    df['days_since_prior_order'] = df.order_id.map(orders.days_since_prior_order)\n",
    "    df['days_since_ratio'] = df.days_since_prior_order / df.user_average_days_between_orders\n",
    "\n",
    "    gc.collect()\n",
    "    return (df, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-07T20:04:28.171126Z",
     "start_time": "2017-08-07T20:04:28.161197Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def none_train(traindf, y):\n",
    "    none_params = {\n",
    "        'task': 'train',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'binary',\n",
    "        'metric': ['auc'],\n",
    "        'num_leaves': 96,\n",
    "        'feature_fraction': 0.9,\n",
    "        'bagging_fraction': 0.95,\n",
    "        'bagging_freq': 5\n",
    "    }\n",
    "    d_train = lgb.Dataset(\n",
    "        feature_select(traindf),\n",
    "        label=y,\n",
    "        categorical_feature=['aisle_id', 'department_id']\n",
    "    )\n",
    "\n",
    "    model = lgb.train(params, d_train, ROUNDS)\n",
    "    return model\n",
    "\n",
    "def none_cv(traindf, y):\n",
    "    d_train = lgb.Dataset(\n",
    "        feature_select(traindf),\n",
    "        label=y,\n",
    "        categorical_feature=['aisle_id', 'department_id']\n",
    "    )\n",
    "\n",
    "    return lgb.cv(params, d_train, ROUNDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-07T20:04:40.715311Z",
     "start_time": "2017-08-07T20:04:40.712473Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def none_predict(model, df):\n",
    "    return model.predict(feature_select(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-16T09:50:39.048027Z",
     "start_time": "2017-07-16T09:48:15.953Z"
    }
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-12T11:00:16.254189Z",
     "start_time": "2017-08-12T10:57:34.310934Z"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "df_train = pd.read_pickle(\"df_train.pkl\")\n",
    "df_test = pd.read_pickle(\"df_test.pkl\")\n",
    "labels = pickle.load(open(\"labels.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-12T12:32:11.685831Z",
     "start_time": "2017-08-12T12:32:11.676950Z"
    }
   },
   "outputs": [],
   "source": [
    "def feature_select(df):\n",
    "    return df.drop(\n",
    "        [\"user_id\", \"product_id\", \"order_id\", \"pred_ext\"],\n",
    "        axis=1, errors=\"ignore\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-12T11:02:31.372745Z",
     "start_time": "2017-08-12T11:02:31.357549Z"
    }
   },
   "outputs": [],
   "source": [
    "params = {\n",
    "    'task': 'train',\n",
    "    'boosting_type': 'gbdt',\n",
    "    'objective': 'binary',\n",
    "    'metric': {'binary_logloss'},\n",
    "    'num_leaves': 96,\n",
    "    'feature_fraction': 0.9,\n",
    "    'bagging_fraction': 0.95,\n",
    "    'bagging_freq': 5\n",
    "}\n",
    "ROUNDS = 98\n",
    "\n",
    "def train(traindf, y):\n",
    "#     none_df, none_labels = none_features(traindf[\"order_id\"].unique(), True)\n",
    "#     none_model = none_train(none_df, none_labels)\n",
    "\n",
    "    d_train = lgb.Dataset(\n",
    "        feature_select(traindf),\n",
    "        label=y,\n",
    "        categorical_feature=['aisle_id', 'department_id']\n",
    "    )\n",
    "\n",
    "    model = lgb.train(params, d_train, ROUNDS)\n",
    "    return model, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-12T11:12:43.810243Z",
     "start_time": "2017-08-12T11:02:33.296521Z"
    }
   },
   "outputs": [],
   "source": [
    "model, none_model = train(df_train, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## F1 Expectation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This kernel implements the O(n²) F1-Score expectation maximization algorithm presented in\n",
    "\"Ye, N., Chai, K., Lee, W., and Chieu, H.  Optimizing F-measures: A Tale of Two Approaches. In ICML, 2012.\"\n",
    "\n",
    "It solves argmax_(0 <= k <= n,[[None]]) E[F1(P,k,[[None]])]\n",
    "with [[None]] being the indicator for predicting label \"None\"\n",
    "given posteriors P = [p_1, p_2, ... , p_n], where p_1 > p_2 > ... > p_n\n",
    "under label independence assumption by means of dynamic programming in O(n²)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-12T11:15:09.583937Z",
     "start_time": "2017-08-12T11:15:08.716510Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_expectations(P, pNone=None):\n",
    "    expectations = []\n",
    "    P = np.sort(P)[::-1]\n",
    "\n",
    "    n = np.array(P).shape[0]\n",
    "    DP_C = np.zeros((n + 2, n + 1))\n",
    "    if pNone is None:\n",
    "        pNone = (1.0 - P).prod()\n",
    "\n",
    "    DP_C[0][0] = 1.0\n",
    "    for j in range(1, n):\n",
    "        DP_C[0][j] = (1.0 - P[j - 1]) * DP_C[0, j - 1]\n",
    "\n",
    "    for i in range(1, n + 1):\n",
    "        DP_C[i, i] = DP_C[i - 1, i - 1] * P[i - 1]\n",
    "        for j in range(i + 1, n + 1):\n",
    "            DP_C[i, j] = P[j - 1] * DP_C[i - 1, j - 1] + (1.0 - P[j - 1]) * DP_C[i, j - 1]\n",
    "\n",
    "    DP_S = np.zeros((2 * n + 1,))\n",
    "    DP_SNone = np.zeros((2 * n + 1,))\n",
    "    for i in range(1, 2 * n + 1):\n",
    "        DP_S[i] = 1. / (1. * i)\n",
    "        DP_SNone[i] = 1. / (1. * i + 1)\n",
    "    for k in range(n + 1)[::-1]:\n",
    "        f1 = 0\n",
    "        f1None = 0\n",
    "        for k1 in range(n + 1):\n",
    "            f1 += 2 * k1 * DP_C[k1][k] * DP_S[k + k1]\n",
    "            f1None += 2 * k1 * DP_C[k1][k] * DP_SNone[k + k1]\n",
    "        for i in range(1, 2 * k - 1):\n",
    "            DP_S[i] = (1 - P[k - 1]) * DP_S[i] + P[k - 1] * DP_S[i + 1]\n",
    "            DP_SNone[i] = (1 - P[k - 1]) * DP_SNone[i] + P[k - 1] * DP_SNone[i + 1]\n",
    "        expectations.append([f1None + 2 * pNone / (2 + k), f1])\n",
    "\n",
    "    return np.array(expectations[::-1]).T\n",
    "\n",
    "def maximize_expectation(P, pNone=None):\n",
    "    expectations = get_expectations(P, pNone)\n",
    "\n",
    "    ix_max = np.unravel_index(expectations.argmax(), expectations.shape)\n",
    "    max_f1 = expectations[ix_max]\n",
    "\n",
    "    predNone = True if ix_max[0] == 0 else False\n",
    "    best_k = ix_max[1]\n",
    "\n",
    "    return best_k, predNone, max_f1\n",
    "\n",
    "def _F1(tp, fp, fn):\n",
    "    return 2 * tp / (2 * tp + fp + fn)\n",
    "\n",
    "def _Fbeta(tp, fp, fn, beta=1.0):\n",
    "    beta_squared = beta ** 2\n",
    "    return (1.0 + beta_squared) * tp / ((1.0 + beta_squared) * tp + fp + beta_squared * fn)\n",
    "\n",
    "\n",
    "def print_best_prediction(P, pNone=None):\n",
    "    print(\"Maximize F1-Expectation\")\n",
    "    print(\"=\" * 23)\n",
    "    P = np.sort(P)[::-1]\n",
    "    n = P.shape[0]\n",
    "    L = ['L{}'.format(i + 1) for i in range(n)]\n",
    "\n",
    "    if pNone is None:\n",
    "        print(\"Estimate p(None|x) as (1-p_1)*(1-p_2)*...*(1-p_n)\")\n",
    "        pNone = (1.0 - P).prod()\n",
    "\n",
    "    PL = ['p({}|x)={}'.format(l, p) for l, p in zip(L, P)]\n",
    "    print(\"Posteriors: {} (n={})\".format(PL, n))\n",
    "    print(\"p(None|x)={}\".format(pNone))\n",
    "\n",
    "    opt = F1Optimizer.maximize_expectation(P, pNone)\n",
    "    best_prediction = ['None'] if opt[1] else []\n",
    "    best_prediction += (L[:opt[0]])\n",
    "    f1_max = opt[2]\n",
    "\n",
    "    print(\"Prediction {} yields best E[F1] of {}\\n\".format(best_prediction, f1_max))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-12T11:15:14.143357Z",
     "start_time": "2017-08-12T11:15:11.816319Z"
    }
   },
   "outputs": [],
   "source": [
    "%%cython\n",
    "import numpy as np\n",
    "def get_expectations_cyt(P, pNone=None):\n",
    "    expectations = []\n",
    "    P = np.sort(P)[::-1]\n",
    "\n",
    "    n = np.array(P).shape[0]\n",
    "    DP_C = np.zeros((n + 2, n + 1))\n",
    "    if pNone is None:\n",
    "        pNone = (1.0 - P).prod()\n",
    "\n",
    "    DP_C[0][0] = 1.0\n",
    "    for j in range(1, n):\n",
    "        DP_C[0][j] = (1.0 - P[j - 1]) * DP_C[0, j - 1]\n",
    "\n",
    "    for i in range(1, n + 1):\n",
    "        DP_C[i, i] = DP_C[i - 1, i - 1] * P[i - 1]\n",
    "        for j in range(i + 1, n + 1):\n",
    "            DP_C[i, j] = P[j - 1] * DP_C[i - 1, j - 1] + (1.0 - P[j - 1]) * DP_C[i, j - 1]\n",
    "\n",
    "    DP_S = np.zeros((2 * n + 1,))\n",
    "    DP_SNone = np.zeros((2 * n + 1,))\n",
    "    for i in range(1, 2 * n + 1):\n",
    "        DP_S[i] = 1. / (1. * i)\n",
    "        DP_SNone[i] = 1. / (1. * i + 1)\n",
    "    for k in range(n + 1)[::-1]:\n",
    "        f1 = 0\n",
    "        f1None = 0\n",
    "        for k1 in range(n + 1):\n",
    "            f1 += 2 * k1 * DP_C[k1][k] * DP_S[k + k1]\n",
    "            f1None += 2 * k1 * DP_C[k1][k] * DP_SNone[k + k1]\n",
    "        for i in range(1, 2 * k - 1):\n",
    "            DP_S[i] = (1 - P[k - 1]) * DP_S[i] + P[k - 1] * DP_S[i + 1]\n",
    "            DP_SNone[i] = (1 - P[k - 1]) * DP_SNone[i] + P[k - 1] * DP_SNone[i + 1]\n",
    "        expectations.append([f1None + 2 * pNone / (2 + k), f1])\n",
    "\n",
    "    return np.array(expectations[::-1]).T\n",
    "\n",
    "def maximize_expectation_cyt(P, pNone=None):\n",
    "    expectations = get_expectations_cyt(P, pNone)\n",
    "\n",
    "    ix_max = np.unravel_index(expectations.argmax(), expectations.shape)\n",
    "    max_f1 = expectations[ix_max]\n",
    "\n",
    "    predNone = True if ix_max[0] == 0 else False\n",
    "    best_k = ix_max[1]\n",
    "\n",
    "    return best_k, predNone, max_f1\n",
    "\n",
    "def print_best_prediction_cyt(P, pNone=None):\n",
    "    print(\"Maximize F1-Expectation\")\n",
    "    print(\"=\" * 23)\n",
    "    P = np.sort(P)[::-1]\n",
    "    n = P.shape[0]\n",
    "    L = ['L{}'.format(i + 1) for i in range(n)]\n",
    "\n",
    "    if pNone is None:\n",
    "        print(\"Estimate p(None|x) as (1-p_1)*(1-p_2)*...*(1-p_n)\")\n",
    "        pNone = (1.0 - P).prod()\n",
    "\n",
    "    PL = ['p({}|x)={}'.format(l, p) for l, p in zip(L, P)]\n",
    "    print(\"Posteriors: {} (n={})\".format(PL, n))\n",
    "    print(\"p(None|x)={}\".format(pNone))\n",
    "\n",
    "    opt = maximize_expectation_cyt(P, pNone)\n",
    "    best_prediction = ['None'] if opt[1] else []\n",
    "    best_prediction += (L[:opt[0]])\n",
    "    f1_max = opt[2]\n",
    "\n",
    "    print(\"Prediction {} yields best E[F1] of {}\\n\".format(best_prediction, f1_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-12T17:30:16.753569Z",
     "start_time": "2017-08-12T17:30:16.301001Z"
    }
   },
   "outputs": [],
   "source": [
    "def final_predict(df_test, none_model=None, TRESHOLD=0.5):\n",
    "    d = dict()\n",
    "\n",
    "    if none_model:\n",
    "        none_df, _ = none_features(df_test[\"order_id\"].unique(), False)\n",
    "        none_df[\"pred\"] = none_predict(none_model, none_df)\n",
    "        none_model_res = none_df.set_index(\"order_id\")[\"pred\"].to_dict()\n",
    "\n",
    "    # Вот тут можно отрезать не по threshold, а с помощью модели определять кол-во покупок\n",
    "    current_order_id = None\n",
    "    current_order_count = 0\n",
    "    current_order_basket_size = 0\n",
    "    for row in tqdm_notebook(df_test.sort_values(\n",
    "        by=[\"order_id\", \"pred\"], \n",
    "        ascending=[False, False]\n",
    "    ).itertuples(), total=len(df_test)):\n",
    "        order_id = row.order_id\n",
    "        if order_id != current_order_id:\n",
    "            current_order_id = order_id\n",
    "            current_order_count = 0\n",
    "            P = df_test[df_test.order_id == order_id].pred.values\n",
    "\n",
    "#             if none_model and none_model_res[order_id] > TRESHOLD:\n",
    "#                 current_order_basket_size = 0\n",
    "#             else:\n",
    "            best_k, predNone, max_f1 = maximize_expectation_cyt(P)\n",
    "            current_order_basket_size = best_k\n",
    "            if predNone:\n",
    "                d[order_id] = 'None'\n",
    "            \n",
    "        if current_order_count >= current_order_basket_size:\n",
    "            continue\n",
    "\n",
    "        current_order_count += 1\n",
    "        try:\n",
    "            d[order_id] += ' ' + str(row.product_id)\n",
    "        except KeyError:\n",
    "            d[order_id] = str(row.product_id)\n",
    "\n",
    "    for order_id in df_test.order_id:\n",
    "        if order_id not in d:\n",
    "            d[order_id] = 'None'\n",
    "\n",
    "    sub = pd.DataFrame.from_dict(d, orient='index')\n",
    "    sub.reset_index(inplace=True)\n",
    "    sub.columns = ['order_id', 'products']\n",
    "    return sub\n",
    "def predict(model, df_test, none_model=None, TRESHOLD=0.5):\n",
    "    ### build candidates list for test ###\n",
    "\n",
    "    df_test['pred'] = model.predict(feature_select(df_test))\n",
    "    if \"pred_ext\" in list(df_test.columns):\n",
    "        df_test['pred'] = (\n",
    "            df_test['pred'] * 0.2 + \n",
    "            df_test['pred_ext'] * 0.8\n",
    "        )\n",
    "        print(\"average pred and pred_ext\")\n",
    "    return final_predict(df_test, none_model=None, TRESHOLD=0.5)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-12T17:25:11.457276Z",
     "start_time": "2017-08-12T17:24:58.750116Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>product_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>aisle_id</th>\n",
       "      <th>department_id</th>\n",
       "      <th>user_total_orders</th>\n",
       "      <th>user_total_items</th>\n",
       "      <th>user_total_distinct_items</th>\n",
       "      <th>user_average_days_between_orders</th>\n",
       "      <th>user_max_days_between_orders</th>\n",
       "      <th>...</th>\n",
       "      <th>UD_last_order_number_prc</th>\n",
       "      <th>UD_first_order_number_prc</th>\n",
       "      <th>UD_orders_since_last</th>\n",
       "      <th>UD_orders_rate_since_first_order</th>\n",
       "      <th>UD_weeks_sinse_last</th>\n",
       "      <th>UD_days_sinse_last</th>\n",
       "      <th>UD_delta_hour_vs_last</th>\n",
       "      <th>pred_ext_x</th>\n",
       "      <th>pred</th>\n",
       "      <th>pred_ext_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2774568</td>\n",
       "      <td>17668</td>\n",
       "      <td>3</td>\n",
       "      <td>91</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>88</td>\n",
       "      <td>33</td>\n",
       "      <td>12.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>1</td>\n",
       "      <td>1.615385</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.351492</td>\n",
       "      <td>0.347998</td>\n",
       "      <td>0.351492</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2774568</td>\n",
       "      <td>39190</td>\n",
       "      <td>3</td>\n",
       "      <td>91</td>\n",
       "      <td>16</td>\n",
       "      <td>13</td>\n",
       "      <td>88</td>\n",
       "      <td>33</td>\n",
       "      <td>12.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>1</td>\n",
       "      <td>1.615385</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.789540</td>\n",
       "      <td>0.782418</td>\n",
       "      <td>0.789540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2774568</td>\n",
       "      <td>44683</td>\n",
       "      <td>3</td>\n",
       "      <td>83</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>88</td>\n",
       "      <td>33</td>\n",
       "      <td>12.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>1</td>\n",
       "      <td>2.923077</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.066456</td>\n",
       "      <td>0.067806</td>\n",
       "      <td>0.066456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2774568</td>\n",
       "      <td>21903</td>\n",
       "      <td>3</td>\n",
       "      <td>123</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>88</td>\n",
       "      <td>33</td>\n",
       "      <td>12.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>1</td>\n",
       "      <td>2.923077</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538955</td>\n",
       "      <td>0.554593</td>\n",
       "      <td>0.538955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2774568</td>\n",
       "      <td>14992</td>\n",
       "      <td>3</td>\n",
       "      <td>83</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>88</td>\n",
       "      <td>33</td>\n",
       "      <td>12.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.923077</td>\n",
       "      <td>0.076923</td>\n",
       "      <td>1</td>\n",
       "      <td>2.923077</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.074164</td>\n",
       "      <td>0.075875</td>\n",
       "      <td>0.074164</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 115 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   order_id  product_id  user_id  aisle_id  department_id  user_total_orders  \\\n",
       "0   2774568       17668        3        91             16                 13   \n",
       "1   2774568       39190        3        91             16                 13   \n",
       "2   2774568       44683        3        83              4                 13   \n",
       "3   2774568       21903        3       123              4                 13   \n",
       "4   2774568       14992        3        83              4                 13   \n",
       "\n",
       "   user_total_items  user_total_distinct_items  \\\n",
       "0                88                         33   \n",
       "1                88                         33   \n",
       "2                88                         33   \n",
       "3                88                         33   \n",
       "4                88                         33   \n",
       "\n",
       "   user_average_days_between_orders  user_max_days_between_orders     ...      \\\n",
       "0                              12.0                          21.0     ...       \n",
       "1                              12.0                          21.0     ...       \n",
       "2                              12.0                          21.0     ...       \n",
       "3                              12.0                          21.0     ...       \n",
       "4                              12.0                          21.0     ...       \n",
       "\n",
       "   UD_last_order_number_prc  UD_first_order_number_prc  UD_orders_since_last  \\\n",
       "0                  0.923077                   0.076923                     1   \n",
       "1                  0.923077                   0.076923                     1   \n",
       "2                  0.923077                   0.076923                     1   \n",
       "3                  0.923077                   0.076923                     1   \n",
       "4                  0.923077                   0.076923                     1   \n",
       "\n",
       "   UD_orders_rate_since_first_order  UD_weeks_sinse_last  UD_days_sinse_last  \\\n",
       "0                          1.615385                 -2.0               -11.0   \n",
       "1                          1.615385                 -2.0               -11.0   \n",
       "2                          2.923077                 -2.0               -11.0   \n",
       "3                          2.923077                 -2.0               -11.0   \n",
       "4                          2.923077                 -2.0               -11.0   \n",
       "\n",
       "   UD_delta_hour_vs_last  pred_ext_x      pred  pred_ext_y  \n",
       "0                      0    0.351492  0.347998    0.351492  \n",
       "1                      0    0.789540  0.782418    0.789540  \n",
       "2                      0    0.066456  0.067806    0.066456  \n",
       "3                      0    0.538955  0.554593    0.538955  \n",
       "4                      0    0.074164  0.075875    0.074164  \n",
       "\n",
       "[5 rows x 115 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Загружаем внешний prediction\n",
    "pred_ext = pd.read_csv(\"prediction_lgbm.csv\").rename(\n",
    "    columns={\"prediction\": \"pred_ext\"}\n",
    ")\n",
    "df_test = df_test.merge(pred_ext, on=[\"order_id\", \"product_id\"])\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-12T18:10:05.477965Z",
     "start_time": "2017-08-12T17:30:19.427848Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74e31e198d9649fbab48162b85054c27"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sub = final_predict(df_test)\n",
    "sub.to_csv('sub2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-12T18:51:24.496754Z",
     "start_time": "2017-08-12T18:10:09.287955Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "90384982a2ca4b0c85103926d94d6251"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sub = final_predict(pd.read_csv(\"prediction_lgbm.csv\").rename(\n",
    "    columns={\"prediction\": \"pred\"}\n",
    "))\n",
    "sub.to_csv('sub.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-12T14:07:39.492053Z",
     "start_time": "2017-08-12T13:15:07.473263Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average pred and pred_ext\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f99bae0123bb48219dd28906f6120f74"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "sub = predict(model, df_test, none_model, TRESHOLD=0.8)\n",
    "sub.to_csv('sub2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "https://www.kaggle.com/happycube/validation-demo-325-cv-3276-lb/notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-16T10:59:51.248918Z",
     "start_time": "2017-07-16T10:48:26.530866Z"
    },
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "lgb.cv(params, d_train, ROUNDS, nfold=5, verbose_eval=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-07T13:29:07.048386Z",
     "start_time": "2017-08-07T13:29:06.326462Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Skipped the cell's code and loaded variables df_train_gt from file '/home/ubuntu/kaggle/instacart/df_train_gt.pkl'.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "54"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%cache df_train_gt.pkl df_train_gt\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "products_raw = pd.read_csv(IDIR + 'products.csv')\n",
    "# combine aisles, departments and products (left joined to products)\n",
    "goods = pd.merge(left=pd.merge(left=products_raw, right=departments, how='left'), right=aisles, how='left')\n",
    "# to retain '-' and make product names more \"standard\"\n",
    "goods.product_name = goods.product_name.str.replace(' ', '_').str.lower() \n",
    "\n",
    "# retype goods to reduce memory usage\n",
    "goods.product_id = goods.product_id.astype(np.int32)\n",
    "goods.aisle_id = goods.aisle_id.astype(np.int16)\n",
    "goods.department_id = goods.department_id.astype(np.int8)\n",
    "\n",
    "# initialize it with train dataset\n",
    "train_details = pd.merge(\n",
    "                left=op_train,\n",
    "                 right=orders, \n",
    "                 how='left', \n",
    "                 on='order_id'\n",
    "        ).apply(partial(pd.to_numeric, errors='ignore', downcast='integer'))\n",
    "\n",
    "# add order hierarchy\n",
    "train_details = pd.merge(\n",
    "                left=train_details,\n",
    "                right=goods[['product_id', \n",
    "                             'aisle_id', \n",
    "                             'department_id']].apply(partial(pd.to_numeric, \n",
    "                                                             errors='ignore', \n",
    "                                                             downcast='integer')),\n",
    "                how='left',\n",
    "                on='product_id'\n",
    ")\n",
    "\n",
    "train_gtl = []\n",
    "\n",
    "for uid, subset in train_details.groupby('user_id'):\n",
    "    subset1 = subset[subset.reordered == 1]\n",
    "    oid = subset.order_id.values[0]\n",
    "\n",
    "    if len(subset1) == 0:\n",
    "        train_gtl.append((oid, 'None'))\n",
    "        continue\n",
    "\n",
    "    ostr = ' '.join([str(int(e)) for e in subset1.product_id.values])\n",
    "    # .strip is needed because join can have a padding space at the end\n",
    "    train_gtl.append((oid, ostr.strip()))\n",
    "\n",
    "del train_details\n",
    "del goods\n",
    "del products_raw\n",
    "\n",
    "gc.collect()\n",
    "\n",
    "df_train_gt = pd.DataFrame(train_gtl)\n",
    "\n",
    "df_train_gt.columns = ['order_id', 'products']\n",
    "df_train_gt.set_index('order_id', inplace=True)\n",
    "df_train_gt.sort_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-07T13:29:13.715015Z",
     "start_time": "2017-08-07T13:29:13.673028Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "def f1_score(cvpred):\n",
    "    joined = df_train_gt.join(cvpred, rsuffix=\"_cv\", how=\"inner\")\n",
    "    lgts = joined.products.replace(\"None\", \"-1\").apply(lambda x: x.split(\" \")).values\n",
    "    lpreds = joined.products_cv.replace(\"None\", \"-1\").apply(lambda x: x.split(\" \")).values\n",
    "    f1 = []\n",
    "    for lgt, lpred in zip(lgts, lpreds):\n",
    "        rr = (np.intersect1d(lgt, lpred))\n",
    "        precision = np.float(len(rr)) / len(lpred)\n",
    "        recall = np.float(len(rr)) / len(lgt)\n",
    "\n",
    "        denom = precision + recall\n",
    "        f1.append(((2 * precision * recall) / denom) if denom > 0 else 0)\n",
    "    return np.mean(f1)\n",
    "\n",
    "def cv(threshold=0.5, n=5):\n",
    "    nsplits = n\n",
    "    if n == 1:\n",
    "        nsplits = 2\n",
    "    gkf = GroupKFold(n_splits=nsplits)\n",
    "\n",
    "    scores = []\n",
    "    for train_idx, test_idx in gkf.split(df_train.index, groups=df_train.user_id):\n",
    "        dftrain = df_train.iloc[train_idx]\n",
    "        dftest = df_train.iloc[test_idx]\n",
    "        y = labels[train_idx]\n",
    "        model, none_model = train(dftrain, y)\n",
    "        pred = predict(model, dftest, none_model, threshold)\n",
    "        f1 = f1_score(pred.set_index(\"order_id\"))\n",
    "        print(f1)\n",
    "        scores.append(f1)\n",
    "        del dftrain\n",
    "        del dftest\n",
    "        gc.collect()\n",
    "        if n == 1:\n",
    "            break\n",
    "\n",
    "    return np.mean(scores), np.std(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-07T14:13:44.403752Z",
     "start_time": "2017-08-07T13:29:20.224987Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65486/65486 [00:00<00:00, 876772.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user related features\n",
      "order related features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.venv/lib/python2.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "100%|██████████| 65723/65723 [00:00<00:00, 208003.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user related features\n",
      "order related features\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c19cc4cb183840329df598ad396bc2f4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.230950656711\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.23095065671059606, 0.0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv(n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-07T09:03:00.594645Z",
     "start_time": "2017-08-07T07:06:32.424463Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65604/65604 [00:00<00:00, 967082.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user related features\n",
      "order related features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.venv/lib/python2.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "100%|██████████| 65605/65605 [00:00<00:00, 1830799.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user related features\n",
      "order related features\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "69004f83e7d04d25a80f5ff34359d64f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.386930142523\n",
      "\t (0.3869301425230352, 0.0)\n",
      "\n",
      "0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65604/65604 [00:00<00:00, 977034.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user related features\n",
      "order related features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65605/65605 [00:00<00:00, 1803772.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user related features\n",
      "order related features\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "86731110131a41bb91da628975223cf2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.38692823718\n",
      "\t (0.3869282371804546, 0.0)\n",
      "\n",
      "0.6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65604/65604 [00:00<00:00, 1002751.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user related features\n",
      "order related features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65605/65605 [00:00<00:00, 1994255.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user related features\n",
      "order related features\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e95b8aa389f4a39ad4fb9621107d3b2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.386927269387\n",
      "\t (0.3869272693873978, 0.0)\n",
      "\n",
      "0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65604/65604 [00:00<00:00, 878798.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user related features\n",
      "order related features\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 65605/65605 [00:00<00:00, 2172933.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user related features\n",
      "order related features\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "720428bd186b4f978d21f549a512384f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-4bcb54de3a36>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mth\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0.8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.6\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\t\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-35-d5a6bf1c9b05>\u001b[0m in \u001b[0;36mcv\u001b[0;34m(threshold, n)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnone_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdftrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdftest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnone_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0mf1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"order_id\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-34-e637be62bb3d>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(model, df_test, none_model, TRESHOLD)\u001b[0m\n\u001b[1;32m     36\u001b[0m                 \u001b[0mcurrent_order_basket_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m                 \u001b[0mbest_k\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF1Optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximize_expectation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mpredNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                     \u001b[0mcurrent_order_basket_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-c449794eaafe>\u001b[0m in \u001b[0;36mmaximize_expectation\u001b[0;34m(P, pNone)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmaximize_expectation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpNone\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mexpectations\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF1Optimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_expectations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mix_max\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munravel_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpectations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpectations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-15-c449794eaafe>\u001b[0m in \u001b[0;36mget_expectations\u001b[0;34m(P, pNone)\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0mf1None\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mk1\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m                 \u001b[0mf1\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mk1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mDP_C\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mDP_S\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mk1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m                 \u001b[0mf1None\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mk1\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mDP_C\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mDP_SNone\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mk1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mk\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "          \r",
      "364524/|/  9%|| 364524/4237331 [03:20<35:27, 1820.44it/s]"
     ]
    }
   ],
   "source": [
    "for th in [0.8, 0.7, 0.6, 0.5, 0.4]:\n",
    "    print(th)\n",
    "    print(\"\\t\", cv(threshold=th, n=1))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "0.372658477911"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "0.9: 0.386930142523\n",
    "\n",
    "0.8: 0.386930142523\n",
    "\n",
    "0.7: 0.38692823718\n",
    "\n",
    "0.6: 0.386927269387\n",
    "\n",
    "подмешанный none score: 0.378085325812\n",
    "\n",
    "без none: 0.386930142523"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-16T16:45:31.846458Z",
     "start_time": "2017-07-16T16:45:31.837241Z"
    },
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-17-fd741fd5103b>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-17-fd741fd5103b>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    (0.37491390084571824, 0.001620734287706205) 0.2\u001b[0m\n\u001b[0m                                                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "0.18\n",
    "0.375669602808\n",
    "0.37518960199\n",
    "0.376068733519\n",
    "0.374880658158\n",
    "0.371575669134\n",
    "(0.37467685312194482, 0.0016027896306283745)\n",
    "\n",
    "0.19\n",
    "0.375981281546\n",
    "0.375613273106\n",
    "0.37623495823\n",
    "0.374958453045\n",
    "0.371884026622\n",
    "(0.3749343985097483, 0.0015845275427144021)\n",
    "\n",
    "0.2\n",
    "0.376141810192\n",
    "0.375593739202\n",
    "0.375961736002\n",
    "0.375124046483\n",
    "0.371748172351\n",
    "(0.37491390084571824, 0.001620734287706205)\n",
    "\n",
    "\n",
    "0.21\n",
    "0.375454836995\n",
    "0.374657579102\n",
    "0.375585106194\n",
    "0.374639123067\n",
    "0.371277685501\n",
    "(0.37432286617177202, 0.0015722458019732746)\n",
    "\n",
    "\n",
    "0.2\n",
    "0.376141810192\n",
    "0.375593739202\n",
    "0.375961736002\n",
    "0.375124046483\n",
    "0.371748172351\n",
    "\n",
    "(0.37491390084571824, 0.001620734287706205)\n",
    "\n",
    "0.374504880043\n",
    "0.372459365153\n",
    "0.374241429517\n",
    "0.373332070018\n",
    "0.370178093483\n",
    "(0.37294316764289259, 0.0015591904647740879) 0.22\n",
    "0.370290530162\n",
    "0.369518178297\n",
    "0.370515696117\n",
    "0.369568282123\n",
    "0.3673846793\n",
    "(0.36945547319979183, 0.0011069090226251931) 0.24\n",
    "0.363691285892\n",
    "0.363725106289\n",
    "0.363492700824\n",
    "0.364412180878\n",
    "0.363024994542\n",
    "(0.36366925368510306, 0.00044761289123321511) 0.26"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-07-23T09:31:39.735518Z",
     "start_time": "2017-07-23T09:31:39.703166Z"
    },
    "heading_collapsed": true
   },
   "source": [
    "# Модель определения кол-ва покупок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-05T11:06:50.032221Z",
     "start_time": "2017-08-05T11:06:47.328520Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>order_id</th>\n",
       "      <th>user_id</th>\n",
       "      <th>eval_set</th>\n",
       "      <th>order_number</th>\n",
       "      <th>order_dow</th>\n",
       "      <th>order_hour_of_day</th>\n",
       "      <th>days_since_prior_order</th>\n",
       "      <th>product_counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>473747</td>\n",
       "      <td>1</td>\n",
       "      <td>prior</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>21.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2254736</td>\n",
       "      <td>1</td>\n",
       "      <td>prior</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>29.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>431534</td>\n",
       "      <td>1</td>\n",
       "      <td>prior</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>28.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>3367565</td>\n",
       "      <td>1</td>\n",
       "      <td>prior</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>19.0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>550135</td>\n",
       "      <td>1</td>\n",
       "      <td>prior</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>20.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>3108588</td>\n",
       "      <td>1</td>\n",
       "      <td>prior</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>14.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2295261</td>\n",
       "      <td>1</td>\n",
       "      <td>prior</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2550362</td>\n",
       "      <td>1</td>\n",
       "      <td>prior</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>30.0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1187899</td>\n",
       "      <td>1</td>\n",
       "      <td>train</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2168274</td>\n",
       "      <td>2</td>\n",
       "      <td>prior</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1501582</td>\n",
       "      <td>2</td>\n",
       "      <td>prior</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1901567</td>\n",
       "      <td>2</td>\n",
       "      <td>prior</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>738281</td>\n",
       "      <td>2</td>\n",
       "      <td>prior</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1673511</td>\n",
       "      <td>2</td>\n",
       "      <td>prior</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1199898</td>\n",
       "      <td>2</td>\n",
       "      <td>prior</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    order_id  user_id eval_set  order_number  order_dow  order_hour_of_day  \\\n",
       "2     473747        1    prior             3          3                 12   \n",
       "3    2254736        1    prior             4          4                  7   \n",
       "4     431534        1    prior             5          4                 15   \n",
       "5    3367565        1    prior             6          2                  7   \n",
       "6     550135        1    prior             7          1                  9   \n",
       "7    3108588        1    prior             8          1                 14   \n",
       "8    2295261        1    prior             9          1                 16   \n",
       "9    2550362        1    prior            10          4                  8   \n",
       "10   1187899        1    train            11          4                  8   \n",
       "11   2168274        2    prior             1          2                 11   \n",
       "12   1501582        2    prior             2          5                 10   \n",
       "13   1901567        2    prior             3          1                 10   \n",
       "14    738281        2    prior             4          2                 10   \n",
       "15   1673511        2    prior             5          3                 11   \n",
       "16   1199898        2    prior             6          2                  9   \n",
       "\n",
       "    days_since_prior_order  product_counts  \n",
       "2                     21.0               9  \n",
       "3                     29.0               8  \n",
       "4                     28.0              13  \n",
       "5                     19.0              26  \n",
       "6                     20.0               3  \n",
       "7                     14.0               2  \n",
       "8                      0.0               1  \n",
       "9                     30.0              15  \n",
       "10                    14.0              15  \n",
       "11                     NaN               5  \n",
       "12                    10.0              15  \n",
       "13                     3.0              13  \n",
       "14                     8.0              11  \n",
       "15                     8.0               5  \n",
       "16                    13.0               3  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prior_orders_count = priors[[\"order_id\", \"product_id\"]].groupby(\"order_id\").count()\n",
    "prior_orders_count = prior_orders_count.rename(columns={\"product_id\": \"product_counts\"})\n",
    "\n",
    "train_orders_count = op_train.drop([\"product_id\", \"order_id\"], axis=1, errors=\"ignore\")\n",
    "train_orders_count = train_orders_count.reset_index()[[\"order_id\", \"product_id\"]].groupby(\"order_id\").count()\n",
    "train_orders_count = train_orders_count.rename(columns={\"product_id\": \"product_counts\"})\n",
    "\n",
    "prior_orders_count = orders.join(prior_orders_count, how='inner')\n",
    "train_orders_count = orders.join(train_orders_count, how='inner')\n",
    "prior_orders_count.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-05T11:07:16.983935Z",
     "start_time": "2017-08-05T11:07:07.223594Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75.973135734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.venv/lib/python2.7/site-packages/ipykernel_launcher.py:42: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "def get_order_count(order, alpha=0.5):\n",
    "    user_id = order[\"user_id\"]\n",
    "    df = prior_orders_count[prior_orders_count[\"user_id\"] == user_id]\n",
    "    feats = [\"order_number\", \"order_dow\", \"order_hour_of_day\", \"days_since_prior_order\"]\n",
    "    X = df[feats].fillna(0).values\n",
    "    y = df[\"product_counts\"].values\n",
    "\n",
    "    # create dataset for lightgbm\n",
    "    lgb_train = lgb.Dataset(X, y)\n",
    "\n",
    "    # specify your configurations as a dict\n",
    "    params = {\n",
    "        'task': 'train',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'objective': 'regression',\n",
    "        'metric': {'rmse'},\n",
    "        'num_leaves': 100,\n",
    "        'learning_rate': 0.01,\n",
    "        'feature_fraction': 0.9,\n",
    "        'bagging_fraction': 0.8,\n",
    "        'bagging_freq': 5,\n",
    "        'verbose': 0,\n",
    "    }\n",
    "\n",
    "    # train\n",
    "    clf = lgb.train(params,\n",
    "                    lgb_train,\n",
    "                    num_boost_round=40)\n",
    "\n",
    "#     clf = Lasso(alpha=0.01)\n",
    "#     clf.fit(X, y)\n",
    "\n",
    "    Xpred = np.array([order[f] or 0 for f in feats]).reshape(1, -1)\n",
    "    Xpred = np.nan_to_num(Xpred, 0)\n",
    "    return clf.predict(Xpred)[0]\n",
    "\n",
    "df = train_orders_count.head(1000)\n",
    "df[\"pred_products_count\"] = df.apply(get_order_count, axis=1)\n",
    "\n",
    "print(mean_squared_error(\n",
    "            df[\"product_counts\"],\n",
    "            df[\"pred_products_count\"]\n",
    "        ))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# None handling model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": [
    "### build list of candidate products to reorder, with features ###\n",
    "train_index = set(op_train.index)\n",
    "\n",
    "def none_features(selected_orders, labels_given=False):\n",
    "    order_list = []\n",
    "    product_list = []\n",
    "    labels = []\n",
    "    for row in tqdm(selected_orders.itertuples(), total=len(selected_orders)):\n",
    "        order_id = row.order_id\n",
    "        user_id = row.user_id\n",
    "        order_list += [order_id]\n",
    "        if labels_given:\n",
    "            labels += [\n",
    "                (order_id, product) in train_index \n",
    "                for product in user_products\n",
    "            ]\n",
    "        \n",
    "    df = pd.DataFrame({'order_id': order_list})\n",
    "    df.order_id = df.order_id.astype(np.int32)\n",
    "    labels = np.array(labels, dtype=np.int8)\n",
    "    del order_list\n",
    "    \n",
    "    print('user related features')\n",
    "    df['user_id'] = df.order_id.map(orders.user_id).astype(np.int32)\n",
    "    df['user_total_orders'] = df.user_id.map(users.nb_orders)\n",
    "    df['user_total_items'] = df.user_id.map(users.total_items)\n",
    "    df['user_total_distinct_items'] = df.user_id.map(users.total_distinct_items)\n",
    "    df['user_average_days_between_orders'] = df.user_id.map(users.average_days_between_orders)\n",
    "    df['user_average_basket'] =  df.user_id.map(users.average_basket)\n",
    "    df['user_period'] =  df.user_id.map(users.period)\n",
    "    \n",
    "    print('order related features')\n",
    "    df['dow'] = df.order_id.map(orders.order_dow)\n",
    "    df['order_hour_of_day'] = df.order_id.map(orders.order_hour_of_day)\n",
    "    df['days_since_prior_order'] = df.order_id.map(orders.days_since_prior_order)\n",
    "    df['days_since_ratio'] = df.days_since_prior_order / df.user_average_days_between_orders\n",
    "\n",
    "    gc.collect()\n",
    "    return (df, labels)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Big Problem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-07T18:38:47.808348Z",
     "start_time": "2017-08-07T18:38:35.582816Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 131209/131209 [00:11<00:00, 11402.83it/s]\n"
     ]
    }
   ],
   "source": [
    "train_index = set(op_train.index)\n",
    "train_orders = orders[orders.eval_set == 'train']\n",
    "selected_orders = train_orders\n",
    "labels_given=True\n",
    "order_list = []\n",
    "product_list = []\n",
    "labels = []\n",
    "for row in tqdm(selected_orders.itertuples(), total=len(selected_orders)):\n",
    "    order_id = row.order_id\n",
    "    user_id = row.user_id\n",
    "    user_products = list(users.all_products[user_id])\n",
    "    product_list += user_products\n",
    "    order_list += [order_id] * len(user_products)\n",
    "    if labels_given:\n",
    "        labels += [\n",
    "            (order_id, product) in train_index \n",
    "            for product in user_products\n",
    "        ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-07T16:12:01.409727Z",
     "start_time": "2017-08-07T16:11:04.388224Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user related features\n",
      "order related features\n",
      "product related features\n",
      "aisle related features\n",
      "department related features\n",
      "user_X_product related features\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot convert non-finite values (NA or inf) to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-aca1d9fe66dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m df['UP_delta_hour_vs_last'] = abs(df.order_hour_of_day -               df.UP_last_order_id.map(orders.order_hour_of_day)).map(\n\u001b[1;32m     76\u001b[0m     \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m24\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m ).astype(np.int8)\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;31m#df['UP_same_dow_as_last_order'] = df.UP_last_order_id.map(orders.order_dow) == \\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.venv/local/lib/python2.7/site-packages/pandas/util/_decorators.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.venv/local/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors, **kwargs)\u001b[0m\n\u001b[1;32m   3408\u001b[0m         \u001b[0;31m# else, only a single dtype is given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3409\u001b[0m         new_data = self._data.astype(dtype=dtype, copy=copy, errors=errors,\n\u001b[0;32m-> 3410\u001b[0;31m                                      **kwargs)\n\u001b[0m\u001b[1;32m   3411\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.venv/local/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, **kwargs)\u001b[0m\n\u001b[1;32m   3222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3224\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'astype'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3226\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.venv/local/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[1;32m   3089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3090\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mgr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3091\u001b[0;31m             \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3092\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3093\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.venv/local/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors, values, **kwargs)\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'raise'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m         return self._astype(dtype, copy=copy, errors=errors, values=values,\n\u001b[0;32m--> 471\u001b[0;31m                             **kwargs)\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     def _astype(self, dtype, copy=False, errors='raise', values=None,\n",
      "\u001b[0;32m/home/ubuntu/.venv/local/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36m_astype\u001b[0;34m(self, dtype, copy, errors, values, klass, mgr, raise_on_error, **kwargs)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0;31m# _astype_nansafe works fine with 1-d only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.venv/local/lib/python2.7/site-packages/pandas/core/dtypes/cast.pyc\u001b[0m in \u001b[0;36mastype_nansafe\u001b[0;34m(arr, dtype, copy)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m             raise ValueError('Cannot convert non-finite values (NA or inf) to '\n\u001b[0m\u001b[1;32m    621\u001b[0m                              'integer')\n\u001b[1;32m    622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot convert non-finite values (NA or inf) to integer"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'order_id': order_list, 'product_id': product_list})\n",
    "df.order_id = df.order_id.astype(np.int32)\n",
    "df.product_id = df.product_id\n",
    "df['user_id'] = df.order_id.map(orders.user_id)\n",
    "df['aisle_id'] = df.product_id.map(products.aisle_id).astype(np.int8)\n",
    "df['department_id'] = df.product_id.map(products.department_id).astype(np.int8)\n",
    "\n",
    "labels = np.array(labels, dtype=np.int8)\n",
    "# del order_list\n",
    "# del product_list\n",
    "\n",
    "print('user related features')\n",
    "df['user_total_orders'] = df.user_id.map(users.nb_orders)\n",
    "df['user_total_items'] = df.user_id.map(users.total_items)\n",
    "df['user_total_distinct_items'] = df.user_id.map(users.total_distinct_items)\n",
    "df['user_average_days_between_orders'] = df.user_id.map(users.average_days_between_orders)\n",
    "df['user_max_days_between_orders'] = df.user_id.map(users.max_days_between_orders)\n",
    "df['user_min_days_between_orders'] = df.user_id.map(users.min_days_between_orders)\n",
    "df['user_std_days_between_orders'] = df.user_id.map(users.std_days_between_orders)\n",
    "df['user_average_basket'] =  df.user_id.map(users.average_basket)\n",
    "\n",
    "df['user_reorders'] =  df.user_id.map(users.reorders)\n",
    "df['user_reorder_rate'] =  df.user_id.map(users.reorder_rate)\n",
    "df['user_period'] =  df.user_id.map(users.period)\n",
    "\n",
    "print('order related features')\n",
    "df['dow'] = df.order_id.map(orders.order_dow)\n",
    "df['order_hour_of_day'] = df.order_id.map(orders.order_hour_of_day)\n",
    "df['days_since_prior_order'] = df.order_id.map(orders.days_since_prior_order)\n",
    "df['days_since_ratio'] = df.days_since_prior_order / df.user_average_days_between_orders\n",
    "\n",
    "print('product related features')\n",
    "df['product_orders'] = df.product_id.map(products.orders).astype(np.int32)\n",
    "df['product_users'] = df.product_id.map(products.users).astype(np.int32)\n",
    "df['product_order_freq'] = df.product_id.map(products.order_freq).astype(np.float32)\n",
    "df['product_reorders'] = df.product_id.map(products.reorders).astype(np.int32)\n",
    "df['product_reorder_rate'] = df.product_id.map(products.reorder_rate)\n",
    "df['product_add_to_cart_order_mean'] = df.product_id.map(products.add_to_cart_order_mean).astype(np.float32)\n",
    "df['product_add_to_cart_order_std'] = df.product_id.map(products.add_to_cart_order_std).astype(np.float32)\n",
    "\n",
    "print('aisle related features')\n",
    "df['aisle_orders'] = df.aisle_id.map(aisles.orders).astype(np.int32)\n",
    "df['aisle_users'] = df.aisle_id.map(aisles.users).astype(np.int32)\n",
    "df['aisle_order_freq'] = df.aisle_id.map(aisles.order_freq).astype(np.float32)\n",
    "df['aisle_reorders'] = df.aisle_id.map(aisles.reorders).astype(np.int32)\n",
    "df['aisle_reorder_rate'] = df.aisle_id.map(aisles.reorder_rate).astype(np.float32)\n",
    "df['aisle_add_to_cart_order_mean'] = df.aisle_id.map(aisles.add_to_cart_order_mean).astype(np.float32)\n",
    "df['aisle_add_to_cart_order_std'] = df.aisle_id.map(aisles.add_to_cart_order_std).astype(np.float32)\n",
    "\n",
    "print('department related features')\n",
    "df['department_orders'] = df.department_id.map(departments.orders).astype(np.int32)\n",
    "df['department_users'] = df.department_id.map(departments.users).astype(np.int32)\n",
    "df['department_order_freq'] = df.department_id.map(departments.order_freq).astype(np.float32)\n",
    "df['department_reorders'] = df.department_id.map(departments.reorders).astype(np.int32)\n",
    "df['department_reorder_rate'] = df.department_id.map(departments.reorder_rate).astype(np.float32)\n",
    "df['department_add_to_cart_order_mean'] = df.department_id.map(departments.add_to_cart_order_mean).astype(np.float32)\n",
    "df['department_add_to_cart_order_std'] = df.department_id.map(departments.add_to_cart_order_std).astype(np.float32)\n",
    "\n",
    "print('user_X_product related features')\n",
    "df['z'] = df.product_id + df.user_id * 100000\n",
    "df['UP_orders'] = df.z.map(userXproduct.nb_orders)\n",
    "df['UP_orders_ratio'] = (df.UP_orders / df.user_total_orders).astype(np.float32)\n",
    "df['UP_last_order_id'] = df.z.map(userXproduct.last_order_id)\n",
    "#     df['UP_first_order_id'] = df.z.map(userXproduct.first_order_id)\n",
    "df['UP_average_pos_in_cart'] = (df.z.map(userXproduct.sum_pos_in_cart) / df.UP_orders).astype(np.float32)\n",
    "df['UP_reorders'] = df.z.map(userXproduct.reorders)\n",
    "df['UP_last_order_number'] = df.UP_last_order_id.map(orders.order_number)\n",
    "#     df['UP_first_order_number'] = df.UP_first_order_id.map(orders.order_number)\n",
    "df['UP_orders_since_last'] = df.user_total_orders - df.UP_last_order_number\n",
    "#     df['UP_orders_rate_since_first_order'] = df.UP_orders / (df.user_total_orders - df.UP_first_order_number + 1)\n",
    "\n",
    "df['UP_weeks_sinse_last'] = df.UP_last_order_id.map(orders.user_weekno_rev)\n",
    "df['UP_days_sinse_last'] = df.UP_last_order_id.map(orders.user_days_rev)\n",
    "\n",
    "df['UP_delta_hour_vs_last'] = abs(df.order_hour_of_day - \\\n",
    "              df.UP_last_order_id.map(orders.order_hour_of_day)).map(\n",
    "    lambda x: min(x, 24-x)\n",
    ").astype(np.int8)\n",
    "\n",
    "#df['UP_same_dow_as_last_order'] = df.UP_last_order_id.map(orders.order_dow) == \\\n",
    "#                                              df.order_id.map(orders.order_dow)\n",
    "\n",
    "df.drop(['UP_last_order_id', 'z'], axis=1, inplace=True)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-07T18:45:21.011374Z",
     "start_time": "2017-08-07T18:44:48.002188Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user related features\n",
      "order related features\n",
      "product related features\n",
      "user_X_product related features\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot convert non-finite values (NA or inf) to integer",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-11906d9f9e5f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'UP_orders_since_last'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_total_orders\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUP_last_order_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morder_number\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'UP_delta_hour_vs_last'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morder_hour_of_day\u001b[0m \u001b[0;34m-\u001b[0m               \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mUP_last_order_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0morder_hour_of_day\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m24\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m#     df['UP_days_past_last_buy'] =\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.venv/local/lib/python2.7/site-packages/pandas/util/_decorators.pyc\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnew_arg_name\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_arg_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0m_deprecate_kwarg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.venv/local/lib/python2.7/site-packages/pandas/core/generic.pyc\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors, **kwargs)\u001b[0m\n\u001b[1;32m   3408\u001b[0m         \u001b[0;31m# else, only a single dtype is given\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3409\u001b[0m         new_data = self._data.astype(dtype=dtype, copy=copy, errors=errors,\n\u001b[0;32m-> 3410\u001b[0;31m                                      **kwargs)\n\u001b[0m\u001b[1;32m   3411\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__finalize__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.venv/local/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, **kwargs)\u001b[0m\n\u001b[1;32m   3222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3224\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'astype'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3226\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.venv/local/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, axes, filter, do_integrity_check, consolidate, **kwargs)\u001b[0m\n\u001b[1;32m   3089\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3090\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mgr'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3091\u001b[0;31m             \u001b[0mapplied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3092\u001b[0m             \u001b[0mresult_blocks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_extend_blocks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapplied\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_blocks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3093\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.venv/local/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors, values, **kwargs)\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'raise'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m         return self._astype(dtype, copy=copy, errors=errors, values=values,\n\u001b[0;32m--> 471\u001b[0;31m                             **kwargs)\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m     def _astype(self, dtype, copy=False, errors='raise', values=None,\n",
      "\u001b[0;32m/home/ubuntu/.venv/local/lib/python2.7/site-packages/pandas/core/internals.pyc\u001b[0m in \u001b[0;36m_astype\u001b[0;34m(self, dtype, copy, errors, values, klass, mgr, raise_on_error, **kwargs)\u001b[0m\n\u001b[1;32m    519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                 \u001b[0;31m# _astype_nansafe works fine with 1-d only\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mastype_nansafe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.venv/local/lib/python2.7/site-packages/pandas/core/dtypes/cast.pyc\u001b[0m in \u001b[0;36mastype_nansafe\u001b[0;34m(arr, dtype, copy)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfinite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m             raise ValueError('Cannot convert non-finite values (NA or inf) to '\n\u001b[0m\u001b[1;32m    621\u001b[0m                              'integer')\n\u001b[1;32m    622\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot convert non-finite values (NA or inf) to integer"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame({'order_id':order_list, 'product_id':product_list})\n",
    "df.order_id = df.order_id.astype(np.int32)\n",
    "df.product_id = df.product_id.astype(np.int32)\n",
    "df['user_id'] = df.order_id.map(orders.user_id)\n",
    "df[\"user_id\"] = df[\"user_id\"].astype(np.int32)\n",
    "\n",
    "print('user related features')\n",
    "\n",
    "df['user_total_orders'] = df.user_id.map(users.nb_orders)\n",
    "df['user_total_items'] = df.user_id.map(users.total_items)\n",
    "df['user_total_distinct_items'] = df.user_id.map(users.total_distinct_items)\n",
    "df['user_average_days_between_orders'] = df.user_id.map(users.average_days_between_orders)\n",
    "df['user_average_basket'] =  df.user_id.map(users.average_basket)\n",
    "df['user_period'] =  df.user_id.map(users.period)\n",
    "\n",
    "print('order related features')\n",
    "# df['dow'] = df.order_id.map(orders.order_dow)\n",
    "df['order_hour_of_day'] = df.order_id.map(orders.order_hour_of_day)\n",
    "df['days_since_prior_order'] = df.order_id.map(orders.days_since_prior_order)\n",
    "df['days_since_ratio'] = df.days_since_prior_order / df.user_average_days_between_orders\n",
    "\n",
    "print('product related features')\n",
    "df['aisle_id'] = df.product_id.map(products.aisle_id).astype(np.int8)\n",
    "df['department_id'] = df.product_id.map(products.department_id).astype(np.int8)\n",
    "df['product_orders'] = df.product_id.map(products.orders).astype(np.float32)\n",
    "df['product_users'] = df.product_id.map(products.users).astype(np.float32)\n",
    "df['product_order_freq'] = df.product_id.map(products.order_freq).astype(np.float32)\n",
    "df['product_reorders'] = df.product_id.map(products.reorders).astype(np.float32)\n",
    "df['product_reorder_rate'] = df.product_id.map(products.reorder_rate)\n",
    "\n",
    "print('user_X_product related features')\n",
    "df['z'] = df.product_id + df.user_id * 100000\n",
    "df['UP_orders'] = df.z.map(userXproduct.nb_orders)\n",
    "df['UP_orders_ratio'] = (df.UP_orders / df.user_total_orders).astype(np.float32)\n",
    "df['UP_last_order_id'] = df.z.map(userXproduct.last_order_id)\n",
    "df['UP_average_pos_in_cart'] = (df.z.map(userXproduct.sum_pos_in_cart) / df.UP_orders).astype(np.float32)\n",
    "\n",
    "df['UP_reorders'] = df.z.map(userXproduct.reorders)\n",
    "\n",
    "df['UP_orders_since_last'] = df.user_total_orders - df.UP_last_order_id.map(orders.order_number)\n",
    "df['UP_delta_hour_vs_last'] = abs(df.order_hour_of_day - \\\n",
    "              df.UP_last_order_id.map(orders.order_hour_of_day)).map(lambda x: min(x, 24-x)).astype(np.int8)\n",
    "\n",
    "#     df['UP_days_past_last_buy'] = \n",
    "#df['UP_same_dow_as_last_order'] = df.UP_last_order_id.map(orders.order_dow) == \\\n",
    "#                                              df.order_id.map(orders.order_dow)\n",
    "\n",
    "df.drop(['UP_last_order_id', 'z'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-08-13T07:44:31.499535Z",
     "start_time": "2017-08-13T07:44:31.374207Z"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "unsupported pickle protocol: 4",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-d937f07e2aa9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_pickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"../../imba/data/dataset.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/ubuntu/.venv/local/lib/python2.7/site-packages/pandas/io/pickle.pyc\u001b[0m in \u001b[0;36mread_pickle\u001b[0;34m(path, compression)\u001b[0m\n\u001b[1;32m     92\u001b[0m                     lambda f: pc.load(f, encoding=encoding, compat=True))\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtry_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mPY3\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.venv/local/lib/python2.7/site-packages/pandas/io/pickle.pyc\u001b[0m in \u001b[0;36mtry_read\u001b[0;34m(path, encoding)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 return read_wrapper(\n\u001b[0;32m---> 92\u001b[0;31m                     lambda f: pc.load(f, encoding=encoding, compat=True))\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtry_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.venv/local/lib/python2.7/site-packages/pandas/io/pickle.pyc\u001b[0m in \u001b[0;36mread_wrapper\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m     66\u001b[0m                             is_text=False)\n\u001b[1;32m     67\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0m_f\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.venv/local/lib/python2.7/site-packages/pandas/io/pickle.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(f)\u001b[0m\n\u001b[1;32m     90\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m                 return read_wrapper(\n\u001b[0;32m---> 92\u001b[0;31m                     lambda f: pc.load(f, encoding=encoding, compat=True))\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtry_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ubuntu/.venv/local/lib/python2.7/site-packages/pandas/compat/pickle_compat.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(fh, encoding, compat, is_verbose)\u001b[0m\n\u001b[1;32m    192\u001b[0m         \u001b[0mup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_verbose\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mis_verbose\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mup\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m         \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36mload\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    862\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    863\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 864\u001b[0;31m                 \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    865\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0m_Stop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mstopinst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python2.7/pickle.pyc\u001b[0m in \u001b[0;36mload_proto\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    890\u001b[0m         \u001b[0mproto\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mord\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mproto\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 892\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"unsupported pickle protocol: %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mproto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m     \u001b[0mdispatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mPROTO\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_proto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: unsupported pickle protocol: 4"
     ]
    }
   ],
   "source": [
    "ds = pd.read_pickle(\"../../imba/data/dataset.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "156px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": true,
   "widenNotebook": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
