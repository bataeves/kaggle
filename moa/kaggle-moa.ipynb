{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#References\" data-toc-modified-id=\"References-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>References</a></span></li><li><span><a href=\"#Load-Data\" data-toc-modified-id=\"Load-Data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Load Data</a></span></li><li><span><a href=\"#Preprocessing\" data-toc-modified-id=\"Preprocessing-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Preprocessing</a></span></li><li><span><a href=\"#Folds\" data-toc-modified-id=\"Folds-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Folds</a></span></li><li><span><a href=\"#Training\" data-toc-modified-id=\"Training-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Training</a></span><ul class=\"toc-item\"><li><span><a href=\"#Preparation\" data-toc-modified-id=\"Preparation-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>Preparation</a></span></li><li><span><a href=\"#Deep-multilabel-model-keras\" data-toc-modified-id=\"Deep-multilabel-model-keras-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>Deep multilabel model keras</a></span></li><li><span><a href=\"#Deep-multilabel-model-torch\" data-toc-modified-id=\"Deep-multilabel-model-torch-5.3\"><span class=\"toc-item-num\">5.3&nbsp;&nbsp;</span>Deep multilabel model torch</a></span></li><li><span><a href=\"#Term-model\" data-toc-modified-id=\"Term-model-5.4\"><span class=\"toc-item-num\">5.4&nbsp;&nbsp;</span>Term model</a></span></li><li><span><a href=\"#Zero-class-prediction-model\" data-toc-modified-id=\"Zero-class-prediction-model-5.5\"><span class=\"toc-item-num\">5.5&nbsp;&nbsp;</span>Zero class prediction model</a></span></li><li><span><a href=\"#Error-class-prediction-model\" data-toc-modified-id=\"Error-class-prediction-model-5.6\"><span class=\"toc-item-num\">5.6&nbsp;&nbsp;</span>Error class prediction model</a></span></li><li><span><a href=\"#Calibration\" data-toc-modified-id=\"Calibration-5.7\"><span class=\"toc-item-num\">5.7&nbsp;&nbsp;</span>Calibration</a></span></li><li><span><a href=\"#Blender-model\" data-toc-modified-id=\"Blender-model-5.8\"><span class=\"toc-item-num\">5.8&nbsp;&nbsp;</span>Blender model</a></span></li><li><span><a href=\"#Manual-tuning\" data-toc-modified-id=\"Manual-tuning-5.9\"><span class=\"toc-item-num\">5.9&nbsp;&nbsp;</span>Manual tuning</a></span></li></ul></li><li><span><a href=\"#Public-models\" data-toc-modified-id=\"Public-models-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Public models</a></span><ul class=\"toc-item\"><li><span><a href=\"#keras-NN-+PCA-with-Label-smoothing-CV[0.01562]-LB-[0.01859]\" data-toc-modified-id=\"keras-NN-+PCA-with-Label-smoothing-CV[0.01562]-LB-[0.01859]-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>keras NN +PCA with Label smoothing CV[0.01562] LB [0.01859]</a></span></li><li><span><a href=\"#Pytorch-RankGauss-PCA-NN-CV-[0.014572]-LB-[0.01839]\" data-toc-modified-id=\"Pytorch-RankGauss-PCA-NN-CV-[0.014572]-LB-[0.01839]-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Pytorch-RankGauss-PCA-NN CV [0.014572] LB [0.01839]</a></span></li><li><span><a href=\"#MODEL1-CV-[0.01562060391771847]-LB-[0.01833]\" data-toc-modified-id=\"MODEL1-CV-[0.01562060391771847]-LB-[0.01833]-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>MODEL1 CV [0.01562060391771847] LB [0.01833]</a></span></li></ul></li><li><span><a href=\"#Auto-Tuning\" data-toc-modified-id=\"Auto-Tuning-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Auto Tuning</a></span><ul class=\"toc-item\"><li><span><a href=\"#Error-class\" data-toc-modified-id=\"Error-class-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>Error class</a></span></li><li><span><a href=\"#Zero-class\" data-toc-modified-id=\"Zero-class-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>Zero class</a></span></li><li><span><a href=\"#Blender\" data-toc-modified-id=\"Blender-7.3\"><span class=\"toc-item-num\">7.3&nbsp;&nbsp;</span>Blender</a></span></li><li><span><a href=\"#Run!\" data-toc-modified-id=\"Run!-7.4\"><span class=\"toc-item-num\">7.4&nbsp;&nbsp;</span>Run!</a></span></li></ul></li><li><span><a href=\"#Final-prediction\" data-toc-modified-id=\"Final-prediction-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Final prediction</a></span></li><li><span><a href=\"#Submission\" data-toc-modified-id=\"Submission-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Submission</a></span></li><li><span><a href=\"#Error-analysis\" data-toc-modified-id=\"Error-analysis-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Error analysis</a></span></li><li><span><a href=\"#Offline-vs-Public\" data-toc-modified-id=\"Offline-vs-Public-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>Offline vs Public</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "https://www.kaggle.com/sinamhd9/mechanisms-of-action-moa-tutorial/data\n",
    "\n",
    "scalers: https://www.kaggle.com/liuhdme/moa-competition\n",
    "\n",
    "keras: https://www.kaggle.com/riadalmadani/keras-nn-pca-with-label-smoothing/comments\n",
    "\n",
    "blending: https://www.kaggle.com/c/lish-moa/notebooks?competitionId=19988&sortBy=scoreDescending\n",
    "\n",
    "Classes info:\n",
    "https://docs.google.com/spreadsheets/d/1NVPfqcJKWd-Oes610N-wHMYOKpO2WiH6PU7wFqZyNX8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что можно поделать:\n",
    "1. (+) Модель предсказывающая все нули или нет\n",
    "2. Модель определения termов из названий классов\n",
    "3. Кластеризация + Y-decode\n",
    "4. G,C - autoencoders\n",
    "5. Imbalance\n",
    "6. Class cleaning, только в train!\n",
    "7. (+) Отдельная модель на классы с ошибками"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T10:49:24.062615Z",
     "start_time": "2020-11-29T10:48:24.167767Z"
    },
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "# Importing useful libraries\n",
    "# pip install jupyter_contrib_nbextensions lightgbm iterative-stratification tensorflow tensorflow-addons mlflow kaggle jupyter hyperopt\n",
    "\n",
    "import pickle\n",
    "from os.path import isfile\n",
    "from functools import partial\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Adding iterative-stratification \n",
    "# Select add data from the right menu and search for iterative-stratification, then add it to your kernel.\n",
    "import sys\n",
    "import os\n",
    "import random\n",
    "sys.path.append('../input/iterative-stratification/iterative-stratification-master')\n",
    "\n",
    "from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n",
    "\n",
    "sys.path.append('../input/rank-gauss')\n",
    "from gauss_rank_scaler import GaussRankScaler\n",
    "\n",
    "from time import time\n",
    "import datetime\n",
    "import gc\n",
    "import collections\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "# ML tools \n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow.keras.backend as K\n",
    "from sklearn.metrics import log_loss\n",
    "from tensorflow_addons.layers import WeightNormalization\n",
    "\n",
    "# Setting random seeds\n",
    "def seed_everything(seed=42):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    tf.random.set_seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "seed_everything(seed=42)\n",
    "\n",
    "# Visualization tools\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set_style('white')\n",
    "sns.set(font_scale=1.2)\n",
    "\n",
    "import requests\n",
    "has_internet = True\n",
    "try:\n",
    "    r = requests.get('http://datadigger.ru', timeout=3)\n",
    "    !pip install -q mlflow\n",
    "    import mlflow\n",
    "    \n",
    "    mlflow.set_tracking_uri('http://datadigger.ru:5000')\n",
    "\n",
    "except Exception:\n",
    "    has_internet = False\n",
    "\n",
    "def dict_flatten(d, parent_key='', sep='_'):\n",
    "    items = []\n",
    "    for k, v in d.items():\n",
    "        new_key = parent_key + sep + k if parent_key else k\n",
    "        if isinstance(v, collections.MutableMapping):\n",
    "            items.extend(dict_flatten(v, new_key, sep=sep).items())\n",
    "        else:\n",
    "            items.append((new_key, v))\n",
    "    return dict(items)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T10:49:30.859173Z",
     "start_time": "2020-11-29T10:49:24.065051Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data size (23814, 876)\n",
      "train drug size (23814, 2)\n",
      "train target nonscored size (23814, 403)\n",
      "train target scored size (23814, 207)\n",
      "train target scored size (23814, 208)\n",
      "test data size (3982, 876)\n",
      "sample submission size (3982, 207)\n",
      "New data shape (21948, 875)\n",
      "Scored без класса: 34.176%\n",
      "NoScored без класса: 79.087%\n",
      "Нет никакого класса: 16.694%\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.read_csv('/kaggle/input/lish-moa/train_features.csv')\n",
    "print('train data size', df_train.shape)\n",
    "\n",
    "df_drug = pd.read_csv('/kaggle/input/lish-moa/train_drug.csv')\n",
    "print('train drug size', df_drug.shape)\n",
    "\n",
    "df_target_ns = pd.read_csv('/kaggle/input/lish-moa/train_targets_nonscored.csv')\n",
    "print('train target nonscored size', df_target_ns.shape)\n",
    "\n",
    "df_target_s = pd.read_csv('/kaggle/input/lish-moa/train_targets_scored.csv')\n",
    "print('train target scored size', df_target_s.shape)\n",
    "\n",
    "df_target_s = df_target_s.merge(df_drug, on=['sig_id'])\n",
    "print('train target scored size', df_target_s.shape)\n",
    "\n",
    "df_test = pd.read_csv('/kaggle/input/lish-moa/test_features.csv')\n",
    "print('test data size', df_test.shape)\n",
    "\n",
    "df_sample = pd.read_csv('/kaggle/input/lish-moa/sample_submission.csv')\n",
    "print('sample submission size', df_sample.shape)\n",
    "\n",
    "def g_c_features(df):\n",
    "    g_features = [cols for cols in df.columns if cols.startswith('g-')]\n",
    "    c_features = [cols for cols in df.columns if cols.startswith('c-')]\n",
    "    return g_features, c_features\n",
    "\n",
    "def preprocess(df):\n",
    "    df['cp_time'] = df['cp_time'].map({24:1, 48:2, 72:3})\n",
    "    df['cp_dose'] = df['cp_dose'].map({'D1':0, 'D2':1})\n",
    "    df['cp_type'] = df['cp_type'].map({'trt_cp': 0, 'ctl_vehicle': 1})\n",
    "    return df\n",
    "\n",
    "X = preprocess(df_train)\n",
    "X_test = preprocess(df_test)\n",
    "\n",
    "ind_te = X_test[X_test['cp_type']==1].index\n",
    "\n",
    "y = df_target_s.drop('sig_id', axis=1)\n",
    "y0 =  df_target_ns.drop('sig_id', axis=1)\n",
    "\n",
    "print('New data shape', X.shape)\n",
    "\n",
    "def perc_empty(df):\n",
    "    df = df.drop(['drug_id'], axis=1, errors='ignore')\n",
    "    return 100 * (1 - len(df[(df.T != 0).any()]) / len(df))\n",
    "\n",
    "print(\"Scored без класса: {}%\".format(round(perc_empty(y), 3)))\n",
    "print(\"NoScored без класса: {}%\".format(round(perc_empty(y0), 3)))\n",
    "print(\"Нет никакого класса: {}%\".format(round(perc_empty(pd.concat([y, y0], axis=1)), 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T10:49:33.506483Z",
     "start_time": "2020-11-29T10:49:30.863097Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import QuantileTransformer, StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "def variance_reduction(X, X_test, **params):\n",
    "    if not params.get('enabled', True):\n",
    "        return X, X_test\n",
    "    thresh = params.get('threshold', 0.8)\n",
    "\n",
    "    columns_to_skip = [\n",
    "        c for c in ['drug_id', 'cp_type', 'cp_time','cp_dose'] \n",
    "        if c in set(X.columns)\n",
    "    ]\n",
    "    cols_num = len(columns_to_skip)\n",
    "    \n",
    "    var_thresh = VarianceThreshold(thresh)\n",
    "    data = X.append(X_test)\n",
    "    try:\n",
    "        data_transformed = var_thresh.fit_transform(data.iloc[:, cols_num:])\n",
    "    except Exception as e:\n",
    "        print(e, str(thresh))\n",
    "        return X, X_test\n",
    "\n",
    "    train_features_transformed = data_transformed[ : X.shape[0]]\n",
    "    test_features_transformed = data_transformed[-X_test.shape[0] : ]\n",
    "\n",
    "    X = pd.DataFrame(\n",
    "        X[columns_to_skip].values.reshape(-1, cols_num),\n",
    "        columns=columns_to_skip\n",
    "    )\n",
    "\n",
    "    X = pd.concat([X, pd.DataFrame(train_features_transformed)], axis=1)\n",
    "\n",
    "    X_test = pd.DataFrame(\n",
    "        X_test[columns_to_skip].values.reshape(-1, cols_num),\n",
    "        columns=columns_to_skip\n",
    "    )\n",
    "\n",
    "    X_test = pd.concat([X_test, pd.DataFrame(test_features_transformed)], axis=1)\n",
    "    return X, X_test\n",
    "\n",
    "def fe_cluster(train, test, **params):\n",
    "    if not params.get('enabled', True):\n",
    "        return train, test\n",
    "    n_clusters_g = params.get('n_clusters_g', 35) \n",
    "    n_clusters_c = params.get('n_clusters_c', 5)\n",
    "    random_state = params.get('seed', 299)\n",
    "    \n",
    "    features_g, features_c = g_c_features(train)\n",
    "    def create_cluster(train, test, features, kind = 'g', n_clusters = n_clusters_g):\n",
    "        train_ = train[features].copy()\n",
    "        test_ = test[features].copy()\n",
    "        data = pd.concat([train_, test_], axis = 0)\n",
    "        kmeans = KMeans(n_clusters = n_clusters, random_state = random_state).fit(data)\n",
    "        train[f'clusters_{kind}'] = kmeans.labels_[:train.shape[0]]\n",
    "        test[f'clusters_{kind}'] = kmeans.labels_[train.shape[0]:]\n",
    "        train = pd.get_dummies(train, columns = [f'clusters_{kind}'])\n",
    "        test = pd.get_dummies(test, columns = [f'clusters_{kind}'])\n",
    "        return train, test\n",
    "    \n",
    "    train, test = create_cluster(train, test, features_g, kind = 'g', n_clusters = n_clusters_g)\n",
    "    train, test = create_cluster(train, test, features_c, kind = 'c', n_clusters = n_clusters_c)\n",
    "    return train, test\n",
    "\n",
    "def quantile_transformer(df, df_test, **params):\n",
    "    random_state = params.get('seed', 42)\n",
    "    g_features, c_features = g_c_features(df)\n",
    "\n",
    "    for col in (g_features + c_features):\n",
    "        transformer = QuantileTransformer(n_quantiles=100, random_state=random_state, output_distribution='normal')\n",
    "        vec_len = len(df[col].values)\n",
    "        raw_vec = df[col].values.reshape(vec_len, 1)\n",
    "        vec_len_test = len(df_test[col].values)\n",
    "        raw_vec_test = df_test[col].values.reshape(vec_len_test, 1)\n",
    "        transformer.fit(raw_vec)\n",
    "        df[col] = transformer.transform(raw_vec).reshape(1, vec_len)[0]\n",
    "        df_test[col] = transformer.transform(raw_vec_test).reshape(1, vec_len_test)[0]\n",
    "    return df, df_test\n",
    "\n",
    "def rank_gauss(df, **params):\n",
    "    g_features, c_features = g_c_features(df)\n",
    "    cols_numeric = g_features + c_features\n",
    "    df[cols_numeric] = GaussRankScaler().fit_transform(df[cols_numeric])\n",
    "    return df\n",
    "\n",
    "def standard_scaler(df, df_test, **params):\n",
    "    g_features, c_features = g_c_features(df)\n",
    "    cols_numeric = g_features + c_features\n",
    "    scaler = StandardScaler()\n",
    "    df[cols_numeric] = scaler.fit_transform(df[cols_numeric])\n",
    "    df_test[cols_numeric] = scaler.transform(df_test[cols_numeric])\n",
    "    return df, df_test\n",
    "\n",
    "def fe_cluster_pca(train, test, n_clusters=5, seed = 42):\n",
    "    pca_g_cols = [c for c in train.columns if c.startswith('pca_g-')]\n",
    "    pca_c_cols = [c for c in train.columns if c.startswith('pca_c-')]\n",
    "    train_gpca = train[pca_g_cols]\n",
    "    test_gpca = test[pca_g_cols]\n",
    "    train_cpca = train[pca_c_cols]\n",
    "    test_cpca = test[pca_c_cols]\n",
    "\n",
    "    train_pca=pd.concat((train_gpca,train_cpca),axis=1)\n",
    "    test_pca=pd.concat((test_gpca,test_cpca),axis=1)\n",
    "\n",
    "    data=pd.concat([train_pca,test_pca],axis=0)\n",
    "    kmeans = KMeans(n_clusters = n_clusters, random_state = seed).fit(data)\n",
    "\n",
    "    train[f'clusters_pca'] = kmeans.labels_[:train.shape[0]]\n",
    "    test[f'clusters_pca'] = kmeans.labels_[train.shape[0]:]\n",
    "\n",
    "    train = pd.get_dummies(train, columns = [f'clusters_pca'])\n",
    "    test = pd.get_dummies(test, columns = [f'clusters_pca'])\n",
    "    return train, test\n",
    "\n",
    "def pca_transformer(X, X_test, **params):\n",
    "    # Please see reference 3 for this part\n",
    "    if not params.get('enabled', True):\n",
    "        return X, X_test\n",
    "    random_state = params.get('seed', 42)\n",
    "    n_comp_cells = params.get('n_comp_cells', 0.95)\n",
    "    n_comp_genes = params.get('n_comp_genes', 0.95)\n",
    "#     print(f'pca {n_comp_cells}, {n_comp_genes}') \n",
    "    g_features, c_features = g_c_features(X)\n",
    "\n",
    "    data = pd.concat([pd.DataFrame(X[g_features]), pd.DataFrame(X_test[g_features])])\n",
    "    data2 = (PCA(n_comp_genes, random_state=random_state).fit_transform(data[g_features]))\n",
    "    train2 = data2[:X.shape[0]]\n",
    "    test2 = data2[-X_test.shape[0]:]\n",
    "\n",
    "    train2 = pd.DataFrame(train2, columns=[f'pca_g-{i}' for i in range(data2.shape[1])])\n",
    "    test2 = pd.DataFrame(test2, columns=[f'pca_g-{i}' for i in range(data2.shape[1])])\n",
    "\n",
    "    X = pd.concat((X, train2), axis=1)\n",
    "    X_test = pd.concat((X_test, test2), axis=1)\n",
    "\n",
    "    data = pd.concat([pd.DataFrame(X[c_features]), pd.DataFrame(X_test[c_features])])\n",
    "    data2 = (PCA(n_comp_cells, random_state=random_state).fit_transform(data[c_features]))\n",
    "    train2 = data2[:X.shape[0]]\n",
    "    test2 = data2[-X_test.shape[0]:]\n",
    "\n",
    "    train2 = pd.DataFrame(train2, columns=[f'pca_c-{i}' for i in range(data2.shape[1])])\n",
    "    test2 = pd.DataFrame(test2, columns=[f'pca_c-{i}' for i in range(data2.shape[1])])\n",
    "\n",
    "    X = pd.concat((X, train2), axis=1)\n",
    "    X_test = pd.concat((X_test, test2), axis=1)\n",
    "\n",
    "    clusters = params.get('n_clusters', 0)\n",
    "    if clusters:\n",
    "        X, X_test = fe_cluster_pca(X, X_test, n_clusters=clusters, seed=random_state)\n",
    "    return X, X_test\n",
    "\n",
    "gsquarecols=['g-574','g-211','g-216','g-0','g-255','g-577','g-153','g-389','g-60','g-370','g-248','g-167','g-203','g-177','g-301','g-332','g-517','g-6','g-744','g-224','g-162','g-3','g-736','g-486','g-283','g-22','g-359','g-361','g-440','g-335','g-106','g-307','g-745','g-146','g-416','g-298','g-666','g-91','g-17','g-549','g-145','g-157','g-768','g-568','g-396']\n",
    "\n",
    "def fe_stats(train, test, **params):\n",
    "\n",
    "    if not params.get('enabled', True):\n",
    "        return train, test\n",
    "\n",
    "    features_g, features_c = g_c_features(train)\n",
    "    for df in train, test:\n",
    "        df['g_sum'] = df[features_g].sum(axis = 1)\n",
    "        df['g_mean'] = df[features_g].mean(axis = 1)\n",
    "        df['g_std'] = df[features_g].std(axis = 1)\n",
    "        df['g_kurt'] = df[features_g].kurtosis(axis = 1)\n",
    "        df['g_skew'] = df[features_g].skew(axis = 1)\n",
    "        df['c_sum'] = df[features_c].sum(axis = 1)\n",
    "        df['c_mean'] = df[features_c].mean(axis = 1)\n",
    "        df['c_std'] = df[features_c].std(axis = 1)\n",
    "        df['c_kurt'] = df[features_c].kurtosis(axis = 1)\n",
    "        df['c_skew'] = df[features_c].skew(axis = 1)\n",
    "        df['gc_sum'] = df[features_g + features_c].sum(axis = 1)\n",
    "        df['gc_mean'] = df[features_g + features_c].mean(axis = 1)\n",
    "        df['gc_std'] = df[features_g + features_c].std(axis = 1)\n",
    "        df['gc_kurt'] = df[features_g + features_c].kurtosis(axis = 1)\n",
    "        df['gc_skew'] = df[features_g + features_c].skew(axis = 1)\n",
    "    \n",
    "        df['c52_c42'] = df['c-52'] * df['c-42']\n",
    "        df['c13_c73'] = df['c-13'] * df['c-73']\n",
    "        df['c26_c13'] = df['c-23'] * df['c-13']\n",
    "        df['c33_c6'] = df['c-33'] * df['c-6']\n",
    "        df['c11_c55'] = df['c-11'] * df['c-55']\n",
    "        df['c38_c63'] = df['c-38'] * df['c-63']\n",
    "        df['c38_c94'] = df['c-38'] * df['c-94']\n",
    "        df['c13_c94'] = df['c-13'] * df['c-94']\n",
    "        df['c4_c52'] = df['c-4'] * df['c-52']\n",
    "        df['c4_c42'] = df['c-4'] * df['c-42']\n",
    "        df['c13_c38'] = df['c-13'] * df['c-38']\n",
    "        df['c55_c2'] = df['c-55'] * df['c-2']\n",
    "        df['c55_c4'] = df['c-55'] * df['c-4']\n",
    "        df['c4_c13'] = df['c-4'] * df['c-13']\n",
    "        df['c82_c42'] = df['c-82'] * df['c-42']\n",
    "        df['c66_c42'] = df['c-66'] * df['c-42']\n",
    "        df['c6_c38'] = df['c-6'] * df['c-38']\n",
    "        df['c2_c13'] = df['c-2'] * df['c-13']\n",
    "        df['c62_c42'] = df['c-62'] * df['c-42']\n",
    "        df['c90_c55'] = df['c-90'] * df['c-55']\n",
    "        for feature in features_c:\n",
    "             df[f'{feature}_squared'] = df[feature] ** 2     \n",
    "\n",
    "        for feature in gsquarecols:\n",
    "            df[f'{feature}_squared'] = df[feature] ** 2\n",
    "    return train, test\n",
    "\n",
    "def preprocess_X(params, X, X_test, y, y0, seed=42):\n",
    "    p = params\n",
    "    p_scaler = p['scaler']\n",
    "    p_pca = p['pca']\n",
    "    p_fe_cluster = p['fe_cluster']\n",
    "    p_fe_stats = p['fe_stats']\n",
    "    p_variance_reduction = p['variance_reduction']\n",
    "#     print(X.shape, 'initial')\n",
    "    if p_scaler == 'quantile':\n",
    "        X, X_test = quantile_transformer(X, X_test, seed=seed)\n",
    "    elif p_scaler == 'gauss':\n",
    "        X = rank_gauss(X)\n",
    "        X_test = rank_gauss(X_test)\n",
    "    elif p_scaler == 'standard':\n",
    "        X, X_test = standard_scaler(X, X_test)\n",
    "    elif p_scaler != 'none':\n",
    "        raise Exception(f'Unknown scaler: {p_scaler}')\n",
    "#     print(X.shape, 'scaler')\n",
    "    X, X_test = pca_transformer(X, X_test, seed=seed, **p_pca)\n",
    "#     print(X.shape, 'pca')\n",
    "    X, X_test = fe_cluster(X, X_test, seed=seed, **p_fe_cluster)\n",
    "#     print(X.shape, 'cluster')\n",
    "    X, X_test = fe_stats(X, X_test, **p_fe_stats)\n",
    "#     print(X.shape, 'fe_stats')\n",
    "    X, X_test = variance_reduction(X, X_test, **p_variance_reduction)\n",
    "#     print(X.shape, 'variance')\n",
    "    if p.get(\"shuffle_cols\", True):\n",
    "        X, X_test = shuffle_cols(X, X_test)\n",
    "\n",
    "    y0 = y0[X['cp_type'] == 0].reset_index(drop = True)\n",
    "    y = y[X['cp_type'] == 0].reset_index(drop = True)\n",
    "    X = X[X['cp_type'] == 0].reset_index(drop = True)\n",
    "\n",
    "    X = X.drop(['sig_id'], axis=1)\n",
    "    X_test = X_test.drop(['sig_id'], axis=1)\n",
    "    return X, X_test, y, y0\n",
    "\n",
    "def shuffle_cols(train, test):\n",
    "    # В зависимости от seed перемешиваем фичи\n",
    "    features_shrink = 1.\n",
    "    inp_size = int(np.ceil(features_shrink * len(train.columns)))\n",
    "    split_cols = np.random.choice(train.columns, inp_size, replace=False)\n",
    "    return train[split_cols], test[split_cols]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T10:49:33.530730Z",
     "start_time": "2020-11-29T10:49:33.509835Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def train_test_split(X_f, y_f, n_split=7, seed=42):\n",
    "    return fold(X_f, y_f, n_split, seed)[0]\n",
    "\n",
    "def fold_simple(X_f, y_f, n_split, seed):\n",
    "    if len(y_f.columns) > 1:\n",
    "        f = MultilabelStratifiedKFold(n_splits = n_split, random_state = seed, shuffle = True)\n",
    "        return list(f.split(X_f, y_f))\n",
    "    else:\n",
    "        f = StratifiedKFold(n_splits = n_split, random_state=seed, shuffle = True)\n",
    "        return list(f.split(X_f, y_f))\n",
    "\n",
    "def fold_drug(X_f, y_f, drug_thresh=18, n_split=7, seed=42):\n",
    "    vc = y_f.drug_id.value_counts()\n",
    "    vc1 = vc.loc[vc <= drug_thresh].index.sort_values()\n",
    "    vc2 = vc.loc[vc > drug_thresh].index.sort_values()\n",
    "    \n",
    "    target_cols = [c for c in y_f.columns if c != 'drug_id']\n",
    "\n",
    "    # Сначала бьём на фолды лекарства\n",
    "    # STRATIFY DRUGS 18X OR LESS\n",
    "    skf1 = MultilabelStratifiedKFold(n_splits=n_split, shuffle=True, random_state=seed)\n",
    "    tmp1 = y_f.groupby('drug_id').mean().loc[vc1]\n",
    "    split_1 = list(skf1.split(tmp1, tmp1[target_cols]))\n",
    "\n",
    "    # STRATIFY DRUGS MORE THAN 18X\n",
    "    skf2 = MultilabelStratifiedKFold(n_splits=n_split, shuffle=True, random_state=seed)\n",
    "    tmp2 = y_f.loc[y_f.drug_id.isin(vc2)].reset_index()\n",
    "    split_2 = list(skf2.split(tmp2[target_cols], tmp2[target_cols]))\n",
    "\n",
    "    folds = []\n",
    "    for i in range(n_split):\n",
    "        ind_tr_drug, ind_val_drug = split_1[i]\n",
    "        tr_drug, val_drug = tmp1.iloc[ind_tr_drug].index, tmp1.iloc[ind_val_drug].index\n",
    "        ind_tr_1, ind_val_1 = y_f.loc[y_f.drug_id.isin(tr_drug)].index, y_f.loc[y_f.drug_id.isin(val_drug)].index\n",
    "        \n",
    "        ind_tr_2, ind_val_2 = split_2[i]\n",
    "        ind_tr_2, ind_val_2 = tmp2.iloc[ind_tr_2]['index'], tmp2.iloc[ind_val_2]['index']\n",
    "\n",
    "        ind_tr = np.concatenate([ind_tr_1, ind_tr_2])\n",
    "        ind_val = np.concatenate([ind_val_1, ind_val_2])\n",
    "        folds.append((ind_tr, ind_val))\n",
    "    return folds\n",
    "\n",
    "fold = fold_simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T10:49:33.627130Z",
     "start_time": "2020-11-29T10:49:33.533770Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cyclooxygenase_inhibitor          435\n",
       "dopamine_receptor_antagonist      424\n",
       "glutamate_receptor_antagonist     367\n",
       "adrenergic_receptor_antagonist    360\n",
       "dna_inhibitor                     402\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "p_min = 1e-10\n",
    "p_max = 1-1e-10\n",
    "\n",
    "def y_to_zero_class(df_y):\n",
    "    return pd.DataFrame(df_y.max(axis=1).map({1: 0, 0: 1}))\n",
    "\n",
    "def log_loss_metric(y_true, y_pred, columns=None):\n",
    "    metrics = []\n",
    "    y_pred = np.clip(y_pred, p_min, p_max)\n",
    "    cols = y_true.columns if columns is None else columns\n",
    "    for _target in cols:\n",
    "        metrics.append(\n",
    "            log_loss(\n",
    "                y_true.loc[:, _target],\n",
    "                y_pred.loc[:, _target].astype(float),\n",
    "                labels = [0, 1]\n",
    "            )\n",
    "        )\n",
    "    return np.mean(metrics)\n",
    "\n",
    "def log_loss_result(y_true, y_pred):\n",
    "    return log_loss_metric(y_true, y_pred, columns=y.columns)\n",
    "\n",
    "def logloss(y_true, y_pred):\n",
    "    y_pred = tf.clip_by_value(y_pred,p_min,p_max)\n",
    "    return -K.mean(y_true*K.log(y_pred) + (1-y_true)*K.log(1-y_pred))\n",
    "\n",
    "checkpoint_path = \"model.h5\"\n",
    "\n",
    "def callbacks(verbose=0):\n",
    "    rlr = ReduceLROnPlateau(\n",
    "        monitor = 'val_logloss', factor = 0.1, patience = 3, verbose = verbose, \n",
    "        min_delta=1e-4, mode = 'min'\n",
    "    )\n",
    "#     ckp = ModelCheckpoint(\n",
    "#         checkpoint_path, monitor = 'val_logloss', verbose = 0, \n",
    "#         save_best_only = True, mode = 'min'\n",
    "#     )\n",
    "    es = EarlyStopping(\n",
    "        monitor = 'val_logloss', min_delta = 1e-5, patience = 10, mode = 'min', \n",
    "        baseline = None, restore_best_weights = True, verbose = verbose\n",
    "    )\n",
    "    return rlr, es#, ckp\n",
    "\n",
    "def y_arr_to_df(y_arr, cols=None):\n",
    "    if cols is None:\n",
    "        cols = y.columns\n",
    "    return pd.DataFrame(y_arr, columns=cols)\n",
    "\n",
    "error_classes = [\n",
    "    'cyclooxygenase_inhibitor',\n",
    "    'dopamine_receptor_antagonist',\n",
    "    'glutamate_receptor_antagonist',\n",
    "    'adrenergic_receptor_antagonist',\n",
    "    'dna_inhibitor'\n",
    "]\n",
    "def y_to_error_classes(y_df):\n",
    "#     y_df_wo = pd.DataFrame(y_df.drop(error_classes, axis=1).max(axis=1))\n",
    "#     y_df_wo.columns = ['other']\n",
    "    y_df_w = y_df[error_classes]\n",
    "#     y_res = pd.concat([y_df_wo, y_df_w], axis=1)\n",
    "    return y_df_w\n",
    "\n",
    "y_to_error_classes(y).sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep multilabel model keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T10:49:33.716481Z",
     "start_time": "2020-11-29T10:49:33.629348Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.utils import class_weight\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "def create_model(\n",
    "    num_cols_x, num_cols_y, hid_layers, \n",
    "    activations, dropout_rate, \n",
    "    lr, label_smoothing, \n",
    "    weight_decay=1e-5,\n",
    "    batch_norm=True, weight_norm=True\n",
    "):\n",
    "    inp1 = tf.keras.layers.Input(shape = (num_cols_x, ))\n",
    "    x1 = inp1\n",
    "    if batch_norm:\n",
    "        x1 = tf.keras.layers.BatchNormalization()(x1)\n",
    "    x1 = tf.keras.layers.Dropout(dropout_rate[0])(x1)\n",
    "\n",
    "    for i, units in enumerate(hid_layers):\n",
    "        activation = activations[i]\n",
    "\n",
    "        if activation == 'leaky_relu':\n",
    "            dense = tf.keras.layers.Dense(units)\n",
    "        else:\n",
    "            dense = tf.keras.layers.Dense(units, activation=activation)\n",
    "\n",
    "        if weight_norm and weight_norm != 'output':\n",
    "            x1 = WeightNormalization(dense)(x1)\n",
    "        else:\n",
    "            x1 = dense(x1)\n",
    "\n",
    "        if activation == 'leaky_relu':\n",
    "            x1 = tf.keras.layers.LeakyReLU(alpha=0.01)(x1)\n",
    "        \n",
    "        x1 = tf.keras.layers.Dropout(dropout_rate[i])(x1)\n",
    "        if batch_norm:\n",
    "            x1 = tf.keras.layers.BatchNormalization()(x1)\n",
    "    \n",
    "    \n",
    "    out_dense = tf.keras.layers.Dense(num_cols_y, activation='sigmoid')\n",
    "    if weight_norm:\n",
    "        x1 = WeightNormalization(out_dense)(x1)\n",
    "    else:\n",
    "        x1 = out_dense(x1)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=inp1, outputs=x1)    \n",
    "    opt = tfa.optimizers.AdamW(learning_rate=lr, weight_decay=weight_decay)\n",
    "#     opt = tfa.optimizers.Lookahead(opt, sync_period=10)\n",
    "    model.compile(\n",
    "        optimizer=opt,\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=label_smoothing), \n",
    "        metrics=logloss\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "EPOCHS = None\n",
    "\n",
    "class DeepMultiLabelModel(object):\n",
    "    def __init__(self, params, model_name, weights_from=None, verbose=0, seed=42):\n",
    "        self.deep_params = params\n",
    "        self.model_name = model_name\n",
    "        self.seed = seed\n",
    "        self.num_epochs = EPOCHS or params['epochs']\n",
    "        self.model = None\n",
    "        self.history = None\n",
    "        self.weights_from = None\n",
    "        self.verbose = verbose\n",
    "        self.cv_models = []\n",
    "        self.classes = []\n",
    "    \n",
    "    @property\n",
    "    def real_model(self):\n",
    "        if self.model is not None:\n",
    "            return self\n",
    "        if self.cv_models:\n",
    "            return self.cv_models[0]\n",
    "        return None\n",
    "\n",
    "    @property\n",
    "    def definition(self):\n",
    "        model = self.real_model\n",
    "        model_info = []\n",
    "        if model:\n",
    "            model.model.summary(print_fn=model_info.append)\n",
    "        return \"\\n\".join(model_info)\n",
    "    \n",
    "    @property\n",
    "    def train_history(self):\n",
    "        model = self.real_model\n",
    "        if model is None:\n",
    "            return None\n",
    "        return model.history\n",
    "    \n",
    "    def fit(self, x_tr, y_tr, x_val, y_val, y0_tr, y0_val):\n",
    "        inp_size = x_tr.shape[1]\n",
    "        y_shape = y_val.shape[1]\n",
    "        hid_layer = self.deep_params['hid_layer']\n",
    "        activation = self.deep_params['activation']\n",
    "        dropout = self.deep_params['dropout']\n",
    "        learning_rate = self.deep_params['learning_rate']\n",
    "        label_smoothing = self.deep_params['label_smoothing']\n",
    "        batch_norm = self.deep_params.get('batch_norm', True)\n",
    "        weight_norm = self.deep_params.get('weight_norm', True)\n",
    "        init_non_scored_weights = self.deep_params.get('init_non_scored_weights', True)\n",
    "        cls_weight = self.deep_params.get('class_weight')\n",
    "        weight_decay = self.deep_params.get('weight_decay', 1e-5)\n",
    "\n",
    "        # Scored модель\n",
    "        model = create_model(\n",
    "            inp_size, y_shape, hid_layer, activation, dropout, \n",
    "            learning_rate, label_smoothing,\n",
    "            weight_decay=weight_decay,\n",
    "            batch_norm=batch_norm, weight_norm=weight_norm\n",
    "        )\n",
    "        \n",
    "        if init_non_scored_weights:\n",
    "            ns_y_tr = y0_tr\n",
    "            ns_y_val = y0_val\n",
    "            if init_non_scored_weights == 'ALL_TARGETS':\n",
    "                ns_y_tr = np.hstack([y_tr, y0_tr])\n",
    "                ns_y_val = np.hstack([y_val, y0_val])\n",
    "\n",
    "            # Non-scored модель\n",
    "            model0 = create_model(\n",
    "                inp_size, ns_y_val.shape[1], hid_layer, activation, dropout, \n",
    "                learning_rate, label_smoothing,\n",
    "                weight_decay=weight_decay,\n",
    "                batch_norm=batch_norm, weight_norm=weight_norm\n",
    "            )\n",
    "            model0.fit(\n",
    "                x_tr, ns_y_tr, validation_data=(x_val, ns_y_val),\n",
    "                epochs = self.num_epochs, batch_size = batch_size,\n",
    "                callbacks = callbacks(self.verbose), verbose = self.verbose\n",
    "            )\n",
    "            # Transfer weights\n",
    "            for i in range(len(model.layers)-1):\n",
    "                model.layers[i].set_weights(model0.layers[i].get_weights())\n",
    "\n",
    "        self.history = model.fit(\n",
    "            x_tr, y_tr, validation_data=(x_val, y_val),\n",
    "            epochs = self.num_epochs, batch_size = batch_size,\n",
    "            callbacks = callbacks(self.verbose), verbose = self.verbose,\n",
    "            class_weight = cls_weight\n",
    "        )\n",
    "        self.model = model\n",
    "\n",
    "    def predict(self, X):\n",
    "        if isinstance(X, pd.DataFrame):\n",
    "            X = X.astype('float64').values\n",
    "        if self.cv_models:\n",
    "            preds = []\n",
    "            for model in self.cv_models:\n",
    "                preds.append(model.predict(X))\n",
    "            return np.mean(preds, axis=0)\n",
    "        else:\n",
    "            return self.model.predict(X)\n",
    "        \n",
    "    def cv(self, X, y, y0, run_name=None, n_split=7, return_pred=False,\n",
    "           metric_fn=log_loss_metric, overfit=True, run_tags=None, max_score=None):\n",
    "        seed = self.seed\n",
    "        self.cv_models = []\n",
    "        splits = fold(X, y, n_split=n_split, seed=self.seed)\n",
    "        \n",
    "        y = y.drop(columns=['drug_id'], errors='ignore')\n",
    "        y0 = y0.drop(columns=['drug_id'], errors='ignore')\n",
    "\n",
    "        ycols = y.columns\n",
    "        self.classes = ycols\n",
    "        yvals = y.astype(float).values\n",
    "        y0vals = y0.astype(float).values\n",
    "        X_vals = X.astype('float64').values\n",
    "\n",
    "        test_pred = pd.DataFrame(index=X.index, columns=ycols)\n",
    "        test_pred.loc[:,:] = 0\n",
    "        model_def = None\n",
    "        \n",
    "        initial_time = time()\n",
    "        for n, (tr, te) in enumerate(splits):\n",
    "            start_time = time()\n",
    "            # Обучающая,Валидационная выборка\n",
    "            x_tr, x_test = X_vals[tr], X_vals[te]\n",
    "            # Y предварительной задачи (non-scored)\n",
    "            y0_tr, y0_test = y0vals[tr], y0vals[te]\n",
    "            # Y основной задачи\n",
    "            y_tr, y_test = yvals[tr], yvals[te]\n",
    "\n",
    "            # Разбиваем обучение еще на train/val\n",
    "            if not overfit:\n",
    "                ind_tr, ind_val = train_test_split(pd.DataFrame(x_tr), pd.DataFrame(y_tr))\n",
    "                x_tr, x_val = x_tr[ind_tr], x_tr[ind_val]\n",
    "                y_tr, y_val = y_tr[ind_tr], y_tr[ind_val]\n",
    "                y0_tr, y0_val = y0_tr[ind_tr], y0_tr[ind_val]\n",
    "            else:\n",
    "                x_val = x_test\n",
    "                y_val = y_test\n",
    "                y0_val = y0_test\n",
    "\n",
    "            model = DeepMultiLabelModel(\n",
    "                self.deep_params, model_name=self.model_name, \n",
    "                verbose=self.verbose, seed=self.seed\n",
    "            )\n",
    "            model.fit(x_tr, y_tr, x_val, y_val, y0_tr, y0_val)\n",
    "            model_def = model.definition\n",
    "\n",
    "            test_pred.loc[te, ycols] = model.predict(x_test)\n",
    "\n",
    "            self.cv_models.append(model)\n",
    "\n",
    "            oof = metric_fn(y.loc[te, ycols], test_pred.loc[te, ycols])\n",
    "            print(f'[{str(datetime.timedelta(seconds = time() - start_time))[2:7]}], Fold {n}: {oof}')\n",
    "            if max_score and oof > max_score:\n",
    "                print(f'break cv execution {oof} > {max_score}')\n",
    "                if not return_pred:\n",
    "                    return None\n",
    "                else:\n",
    "                    return None, None\n",
    "\n",
    "        logloss_valid = metric_fn(y, test_pred)\n",
    "        print(f'Valid logloss: {logloss_valid}')\n",
    "        if has_internet and run_name:\n",
    "            mlflow.set_experiment('Kaggle-MOA-{}'.format(self.model_name))\n",
    "            with mlflow.start_run(run_name=run_name):\n",
    "                mlflow.log_params(dict_flatten({\n",
    "                    'n_split': n_split,\n",
    "                    'p_min': p_min,\n",
    "                    'p_max': p_max,\n",
    "                    'nn': self.deep_params\n",
    "                }))\n",
    "                mlflow.log_metric(key=\"logloss_valid\", value=logloss_valid)\n",
    "                run_tags = run_tags or {}\n",
    "                run_tags.update({\n",
    "                    'model_def': model_def,\n",
    "                    'run': run_name,\n",
    "                    'run_time': time() - initial_time\n",
    "                })\n",
    "                mlflow.set_tags(run_tags)\n",
    "        if not return_pred:\n",
    "            return logloss_valid\n",
    "        else:\n",
    "            return logloss_valid, test_pred\n",
    "    \n",
    "    def errors(self, X, y):\n",
    "        # Количество ошибок, когда должно быть везде 0, а на самом деле - нет\n",
    "        # Количество ошибок, когда должно что-то быть, а на самом деле везде 0\n",
    "        # Для уменьшения этих ошибок можно применять lgb_zero\n",
    "        y = y.drop(columns=['drug_id'], errors='ignore')\n",
    "        ycols = y.columns\n",
    "        seed_everything(self.seed)\n",
    "\n",
    "        _, te = train_test_split(X, y, n_split=5)\n",
    "\n",
    "        x_val = X_p.astype('float64').values[te]\n",
    "\n",
    "        y_true = y.loc[te, ycols].reset_index(drop=True)\n",
    "        y_pred = y_arr_to_df(self.predict(x_val), ycols)\n",
    "\n",
    "        non_zeros = y_true[(y_true.T != 0).any()].index\n",
    "        all_zeros = y_true[~(y_true.T != 0).any()].index\n",
    "\n",
    "        clip_p_min = 1e-5\n",
    "        clip_p_max = 1 - 1e-5\n",
    "\n",
    "        y_pred_clip = np.clip(y_pred, clip_p_min, clip_p_max)\n",
    "\n",
    "        print('Logloss:', log_loss_metric(y_true, y_pred))\n",
    "        print('Logloss all zeros:', log_loss_metric(y_true.loc[all_zeros, :], y_pred.loc[all_zeros, :]))\n",
    "        print('Logloss non zeros:', log_loss_metric(y_true.loc[non_zeros, :], y_pred.loc[non_zeros, :]))\n",
    "        print('Logloss clip:', log_loss_metric(y_true, y_pred_clip))\n",
    "        print('Logloss all zeros clip:', log_loss_metric(y_true.loc[all_zeros, :], y_pred_clip.loc[all_zeros, :]))\n",
    "        print('Logloss non zeros clip:', log_loss_metric(y_true.loc[non_zeros, :], y_pred_clip.loc[non_zeros, :]))\n",
    "\n",
    "        losses = []\n",
    "        for i in range(y_true.shape[1]):\n",
    "            y_true_cl = y_true.iloc[:,i]\n",
    "            y_pred_cl = y_pred.iloc[:,i]\n",
    "            losses.append({\n",
    "                \"index\": i,\n",
    "                \"class\": y_true_cl.name,\n",
    "                'true_0': len(y_true_cl[y_true_cl == 0]),\n",
    "                'true_1': len(y_true_cl[y_true_cl == 1]),\n",
    "                \"loss\": log_loss(y_true_cl.values, y_pred_cl.values, labels=[0, 1]),\n",
    "                'pred_hist_0': y_pred_cl[y_pred_cl <= 0.5].round(1).value_counts().sort_index().reset_index().values,\n",
    "                'pred_hist_1': y_pred_cl[y_pred_cl > 0.5].round(1).value_counts().sort_index().reset_index().values,\n",
    "            })\n",
    "\n",
    "        return pd.DataFrame(losses).set_index(['index', 'class']).sort_values('loss', ascending=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep multilabel model torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T10:49:34.688668Z",
     "start_time": "2020-11-29T10:49:33.719216Z"
    }
   },
   "outputs": [],
   "source": [
    "def split_to_terms(s):\n",
    "    return s.split('_')\n",
    "\n",
    "terms = pd.DataFrame({'terms': y.columns.map(split_to_terms)}).explode('terms')['terms'].value_counts()\n",
    "terms = list(terms[terms > 1].index)\n",
    "terms_map = {t: i for i, t in enumerate(terms)}\n",
    "\n",
    "def y_to_terms(y_df):\n",
    "    term_vals = []\n",
    "    for _, row in y_df.iterrows():\n",
    "        new_classes = [0] * len(terms)\n",
    "        terms_1 = set(pd.DataFrame(row[row > 0].index.map(split_to_terms)).explode(0)[0].values.tolist())\n",
    "        for term in terms_1:\n",
    "            if term not in terms_map:\n",
    "                continue\n",
    "            new_classes[terms_map[term]] = 1\n",
    "        term_vals.append(new_classes)\n",
    "    return pd.DataFrame(term_vals, columns=terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T10:49:34.752217Z",
     "start_time": "2020-11-29T10:49:34.690813Z"
    }
   },
   "outputs": [],
   "source": [
    "# preprocess_params, deep_params, _, _, _ = ({'fe_cluster': {'enabled': True, 'n_clusters_c': 6, 'n_clusters_g': 44}, 'fe_stats': {'enabled': False}, 'pca': {'enabled': False}, 'scaler': 'none', 'shuffle_cols': True, 'variance_reduction': {'enabled': True, 'threshold': 0.9585049261745544}, 'use_zero_pred_model': True}, {'activation': ('selu', 'swish', 'swish'), 'dropout': (0.7, 0.7, 0.3), 'hid_layer': (1152, 1152, 2048), 'init_non_scored_weights': False, 'label_smoothing': 0.0007000000000000001, 'learning_rate': 0.016, 'epochs': 500}, {'threshold': 0}, 29, 1)\n",
    "\n",
    "# term_model = DeepMultiLabelModel(deep_params, 'terms')\n",
    "\n",
    "# y_term = y_to_terms(pd.concat([y, y0], axis=1))\n",
    "# term_model.cv(X_p, y_term, y0, n_split=5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero class prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T10:49:34.829540Z",
     "start_time": "2020-11-29T10:49:34.754423Z"
    }
   },
   "outputs": [],
   "source": [
    "# X_p, X_test_p = preprocess_X(fe_params, X.copy(), X_test.copy())\n",
    "\n",
    "# zero_model = DeepMultiLabelModel(nn_params, 'zero')\n",
    "\n",
    "# y_zero = y_to_zero_class(y)\n",
    "# zero_model.cv(X_p, y_zero, y0, n_split=7, run_name='tune_nn_1')\n",
    "\n",
    "# zero_model.predict(X_test_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error class prediction model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T10:49:34.903234Z",
     "start_time": "2020-11-29T10:49:34.831736Z"
    }
   },
   "outputs": [],
   "source": [
    "# fe_params, nn_params, _, seed, _ = (\n",
    "#     {'fe_cluster': {'enabled': True, 'n_clusters_c': 14, 'n_clusters_g': 39}, 'fe_stats': {'enabled': True}, 'pca': {'enabled': False}, 'scaler': 'quantile', 'shuffle_cols': True, 'variance_reduction': {'enabled': False}}, \n",
    "#     {'activation': ('elu', 'elu', 'elu', 'elu'), 'batch_norm': True, \n",
    "#      'dropout': (0.3, 0.3, 0.4, 0.3), 'epochs': 100, 'hid_layer': (512, 1024, 512, 2048), \n",
    "#      'init_non_scored_weights': False, 'label_smoothing': 0.0001380444271082826, \n",
    "#      'learning_rate': 0.4083831289327425, 'weight_norm': True,\n",
    "# #      'class_weight': {0: 1, 1: 7, 2: 6, 3: 7, 4: 7, 5: 5}\n",
    "#     }, \n",
    "#     {'zero_threshold': 0.9837308739197401}, 13, 2\n",
    "# )\n",
    "# seed_everything(seed)\n",
    "\n",
    "# X_p, X_test_p = preprocess_X(fe_params, X.copy(), X_test.copy())\n",
    "\n",
    "# error_model = DeepMultiLabelModel(nn_params, 'errors', verbose=0)\n",
    "\n",
    "# y_error = y_to_error_classes(y)\n",
    "# error_model.cv(X_p, y_error, y0, n_split=5)\n",
    "# loss_df = error_model.errors(X_p, y_error)\n",
    "# loss_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calibration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T10:49:34.949637Z",
     "start_time": "2020-11-29T10:49:34.905403Z"
    }
   },
   "outputs": [],
   "source": [
    "# https://github.com/cerlymarco/MEDIUM_NoteBook/blob/master/NeuralNet_Calibration/NeuralNet_Calibration.ipynb\n",
    "def fit_TemperatureCalibration(train_X_y, valid_X_y=None, epochs=100):\n",
    "    \n",
    "    ### inspired by: https://github.com/stellargraph/stellargraph/blob/develop/stellargraph/calibration.py ###\n",
    "    T = tf.Variable(tf.ones(shape=(1,)))\n",
    "    history = []\n",
    "    early_stopping = False\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
    "    \n",
    "    def cost(T, x, y):\n",
    "        scaled_logits = tf.multiply(x=x, y=1.0 / T)\n",
    "        cost_value = tf.reduce_mean(\n",
    "            tf.nn.softmax_cross_entropy_with_logits(logits=scaled_logits, labels=y)\n",
    "        )\n",
    "\n",
    "        return cost_value\n",
    "\n",
    "    def grad(T, x, y):\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            cost_value = cost(T, x, y)\n",
    "\n",
    "        return cost_value, tape.gradient(cost_value, T)\n",
    "    \n",
    "    X_train, y_train = train_X_y\n",
    "    if valid_X_y:\n",
    "        X_valid, y_valid = valid_X_y\n",
    "        early_stopping = True\n",
    "    \n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        train_cost, grads = grad(T, X_train, y_train)\n",
    "        optimizer.apply_gradients(zip([grads], [T]))\n",
    "        if early_stopping:\n",
    "            val_cost = cost(T, X_valid, y_valid)\n",
    "            if (len(history) > 0) and (val_cost > history[-1][1]):\n",
    "                break\n",
    "            else: \n",
    "                history.append([train_cost, val_cost, T.numpy()[0]])\n",
    "        else:\n",
    "            history.append([train_cost, T.numpy()[0]])\n",
    "\n",
    "    history = np.asarray(history)\n",
    "    temperature = history[-1, -1]\n",
    "    \n",
    "    return temperature\n",
    "\n",
    "\n",
    "def calibrated_proba(logits, temperature):\n",
    "    scaled_prediction = logits / temperature\n",
    "\n",
    "    return np.exp(scaled_prediction) / np.sum(np.exp(scaled_prediction), axis=-1, keepdims=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T10:49:35.265479Z",
     "start_time": "2020-11-29T10:49:34.952009Z"
    }
   },
   "outputs": [],
   "source": [
    "def calibrate(model, X, y, y0, run_name=None, n_split=7, metric_fn=log_loss_metric, overfit=True):\n",
    "    seed_everything(model.seed)\n",
    "\n",
    "    ind_tr, ind_te = train_test_split(X, y, n_split=n_split)\n",
    "    x_tr, y_tr, y0_tr = X.iloc[ind_tr, :].reset_index(drop=True), y.iloc[ind_tr, :].reset_index(drop=True), y0.iloc[ind_tr, :].reset_index(drop=True)\n",
    "    x_te, y_te, y0_te = X.iloc[ind_te, :].reset_index(drop=True), y.iloc[ind_te, :].reset_index(drop=True), y0.iloc[ind_te, :].reset_index(drop=True)\n",
    "\n",
    "    y_pred_te = model.predict(x_te)\n",
    "    print(metric_fn(y_te, y_arr_to_df(y_pred_te, y_te.columns)))\n",
    "\n",
    "    y_pred_tr = model.predict(x_tr)\n",
    "    \n",
    "    calib_temperature = fit_TemperatureCalibration((y_pred_tr, y_tr), (y_pred_te, y_te))\n",
    "    print(calib_temperature)\n",
    "    print(y_pred_te)\n",
    "    y_pred_te = calibrated_proba(y_pred_te, calib_temperature)\n",
    "    print(y_pred_te)\n",
    "\n",
    "    y_pred_te = y_arr_to_df(y_pred_te, y_te.columns)\n",
    "    return metric_fn(y_te, y_pred_te)\n",
    "\n",
    "# calibrate(error_model, X_p.copy(), y_to_error_classes(y.copy()), y0.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blender model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T10:49:35.544697Z",
     "start_time": "2020-11-29T10:49:35.267771Z"
    }
   },
   "outputs": [],
   "source": [
    "!mkdir -p bundles\n",
    "class ModelBlender(object):\n",
    "    def __init__(self, deep_params, blend_params, seed=42, verbose=0, preprocess_params=None):\n",
    "        self.deep_params = deep_params\n",
    "\n",
    "        self.num_epochs = deep_params['epochs']\n",
    "        self.blend_params = blend_params\n",
    "        self.seed = seed\n",
    "        self.preprocess_params = preprocess_params\n",
    "        \n",
    "        zero_params = blend_params.get('zero_params') or deep_params\n",
    "        errors_params = blend_params.get('errors_params') or deep_params\n",
    "\n",
    "        self.model_main = DeepMultiLabelModel(deep_params, model_name='main', seed=seed, verbose=verbose)\n",
    "        self.model_zero = DeepMultiLabelModel(zero_params or deep_params, model_name='zero', seed=seed, verbose=verbose)\n",
    "        self.model_errors = DeepMultiLabelModel(errors_params or deep_params, model_name='errors', seed=seed, verbose=verbose)\n",
    "        self.calib_temperature = None\n",
    "        self.classes = []\n",
    "        self.metrics = {}\n",
    "\n",
    "    @property\n",
    "    def definition(self):\n",
    "        return self.model_main.definition\n",
    "\n",
    "    def predict(self, X):        \n",
    "        y = self.model_main.predict(X)\n",
    "        # Если выставлено, то принудительно ставим 0 везде, где модель предсказания 0 уверена\n",
    "        zero_pred_threshold = self.blend_params.get('zero_threshold', 0)\n",
    "        if zero_pred_threshold > 0:\n",
    "            zero_preds = self.model_zero.predict(X)[:, 0]\n",
    "            override_ind = zero_preds > zero_pred_threshold\n",
    "            print('Override to zeros: {} rows'.format(len(override_ind[override_ind])))\n",
    "            y[override_ind, :] = 0.\n",
    "\n",
    "        if self.blend_params.get('use_error_class'):\n",
    "            error_class_indices = [self.classes.index(e) for e in error_classes]\n",
    "            y[:, error_class_indices] = self.model_errors.predict(X)\n",
    "        return y\n",
    "    \n",
    "    def cv(self, X, y, y0, run_name=None, n_split=7, \n",
    "           metric_fn=log_loss_metric, overfit=True, \n",
    "           run_tags=None, return_pred=True\n",
    "          ):\n",
    "        seed_everything(self.seed)\n",
    "        \n",
    "        y_te = y.drop(columns=['drug_id'], errors='ignore')\n",
    "        ycols = list(y_te.columns)\n",
    "        self.classes = ycols\n",
    "        \n",
    "        preds = {}\n",
    "        _, y_pred = self.model_main.cv(\n",
    "            X, y, y0, \n",
    "            n_split=n_split, metric_fn=metric_fn, overfit=overfit,\n",
    "            run_tags=run_tags, run_name=run_name, return_pred=True, max_score=0.019\n",
    "        )\n",
    "        if y_pred is None:\n",
    "            if return_pred:\n",
    "                return None, None\n",
    "            return None\n",
    "\n",
    "        self.metrics['initial'] = metric_fn(y_te, y_pred)\n",
    "        preds['initial'] = y_pred\n",
    "\n",
    "        print('INITIAL', self.metrics['initial'])\n",
    "        zero_threshold = self.blend_params.get('zero_threshold', 0)\n",
    "        if zero_threshold > 0:\n",
    "            _, y_pred_zero = self.model_zero.cv(\n",
    "                X, y_to_zero_class(y_te), y_to_zero_class(y0), \n",
    "                n_split=n_split, metric_fn=metric_fn, overfit=overfit,\n",
    "                run_tags=run_tags, run_name=run_name, return_pred=True\n",
    "            )\n",
    "            zero_preds = y_pred_zero.iloc[:, 0]\n",
    "            override_ind = zero_preds > zero_threshold\n",
    "            print('Override to zeros: {} rows'.format(len(override_ind[override_ind])))\n",
    "            y_pred.loc[override_ind, :] = 0.\n",
    "            self.metrics['after_zero'] = metric_fn(y_te, y_pred)\n",
    "            preds['after_zero'] = y_pred\n",
    "            print('AFTER ZERO', self.metrics['after_zero'])\n",
    "        \n",
    "        if self.blend_params.get('use_error_class'):\n",
    "            _, y_pred_errors = self.model_errors.cv(\n",
    "                X, y_to_error_classes(y_te), y0, \n",
    "                n_split=n_split, metric_fn=metric_fn, overfit=overfit,\n",
    "                run_tags=run_tags, run_name=run_name, return_pred=True\n",
    "            )\n",
    "            y_pred.loc[:, error_classes] = y_pred_errors.loc[:, error_classes]\n",
    "            self.metrics['after_error'] = metric_fn(y_te, y_pred)\n",
    "            preds['after_error'] = y_pred\n",
    "            print('AFTER ERROR', self.metrics['after_error'])\n",
    "        \n",
    "        logloss_valid = metric_fn(y_te, y_pred)\n",
    "        self.metrics['final'] = logloss_valid\n",
    "        preds['final'] = y_pred\n",
    "\n",
    "        if has_internet and run_name:\n",
    "            bundle = {\n",
    "                'seed': self.seed,\n",
    "                'n_split': n_split,\n",
    "                'p_min': p_min,\n",
    "                'p_max': p_max,\n",
    "                'preprocess_params': self.preprocess_params,\n",
    "                'deep_params': self.deep_params,\n",
    "                'blend_params': self.blend_params,\n",
    "                'logloss_valid': logloss_valid,\n",
    "                'metrics': self.metrics,\n",
    "                'model_def': self.definition,\n",
    "                'run_name': run_name,\n",
    "                'run_tags': run_tags,\n",
    "                'predictions': preds\n",
    "            }\n",
    "            bundle_path = os.path.join('bundles', f'{int(time())}.pickle')\n",
    "            with open(bundle_path, 'wb') as fbundle:\n",
    "                pickle.dump(bundle, fbundle)\n",
    "            print(f'Write bundle: {bundle_path}')\n",
    "\n",
    "            mlflow.set_experiment('Kaggle-MOA-Blend')\n",
    "            with mlflow.start_run(run_name=run_name):\n",
    "                mlflow.log_params(dict_flatten({\n",
    "                    'seed': self.seed,\n",
    "                    'n_split': n_split,\n",
    "                    'p_min': p_min,\n",
    "                    'p_max': p_max,\n",
    "                    'preprocess_params': self.preprocess_params,\n",
    "                    'deep_params': self.deep_params,\n",
    "                    'blend_params': self.blend_params\n",
    "                }))\n",
    "                mlflow.log_metric(key=\"logloss_valid\", value=logloss_valid)\n",
    "                mlflow.log_metrics(self.metrics)\n",
    "                tags = {\n",
    "                    'model_def': self.definition,\n",
    "                    'run': run_name,\n",
    "                    'bundle_path': bundle_path\n",
    "                }\n",
    "                tags.update(run_tags)\n",
    "                mlflow.set_tags(tags)\n",
    "        if return_pred:\n",
    "            return logloss_valid, y_pred\n",
    "        return logloss_valid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T10:49:35.580440Z",
     "start_time": "2020-11-29T10:49:35.547265Z"
    }
   },
   "outputs": [],
   "source": [
    "evaluate_context = {}\n",
    "\n",
    "def create_and_evaluate_model(\n",
    "    args, models=None, predictions=None, predictions_cv=None,\n",
    "    run_name='', n_split=7, verbose=0, overfit=False\n",
    "):\n",
    "    print(args)\n",
    "    preprocess_params, deep_params, blend_params, seed, y_quantiles = args\n",
    "\n",
    "    try:\n",
    "        X_p, X_test_p, y_p, y0_p = preprocess_X(fe_params, X.copy(), X_test.copy(), y.copy(), y0.copy(), seed=seed)\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        return 0.19\n",
    "\n",
    "    model = ModelBlender(deep_params, blend_params, seed=seed, verbose=verbose, preprocess_params=preprocess_params)\n",
    "    evaluate_context['current_iter'] = {\n",
    "        'model': model\n",
    "    }\n",
    "    logloss_valid, y_pred = model.cv(\n",
    "        X_p, y_p, y0_p, n_split=n_split, overfit=overfit, \n",
    "        run_name=run_name, run_tags={'args': str(args)}, return_pred=True\n",
    "    )\n",
    "    if logloss_valid is None:\n",
    "        return 0.19\n",
    "\n",
    "    if models is not None:\n",
    "        models.append(model)\n",
    "\n",
    "    if predictions is not None:\n",
    "        predictions.append(model.predict(X_test_p))\n",
    "    \n",
    "    if predictions_cv is not None:\n",
    "        predictions_cv.append(y_pred)\n",
    "\n",
    "    evaluate_context['last_iter'] = {\n",
    "        'model': model,\n",
    "        'logloss': logloss_valid\n",
    "    }\n",
    "\n",
    "    print(f'Final valid logloss: {logloss_valid}')\n",
    "    return logloss_valid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T10:13:03.483989Z",
     "start_time": "2020-11-28T10:12:43.711Z"
    }
   },
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "models_final = []\n",
    "\n",
    "p_min = 0.0015\n",
    "p_max = 0.9985\n",
    "batch_size = 128\n",
    "seed = 8\n",
    "fold = fold_simple\n",
    "\n",
    "baseline_num = 5\n",
    "baseline_score = round(0.01562, 6)\n",
    "\n",
    "fe_params = {\n",
    "    'fe_cluster': {'enabled': False, 'n_clusters_c': 6, 'n_clusters_g': 44}, \n",
    "    'fe_stats': {'enabled': False}, \n",
    "    'pca': {'enabled': True, 'n_comp_cells': 50, 'n_comp_genes': 600}, \n",
    "    'scaler': 'quantile', 'shuffle_cols': True, \n",
    "    'variance_reduction': {'enabled': True, 'threshold': 0.8}\n",
    "}\n",
    "nn_params = {\n",
    "    'batch_norm': True, 'weight_norm': True, \n",
    "    'activation': ['elu', 'elu', 'elu', 'elu'], \n",
    "    'dropout': [0.3, 0.3, 0.4, 0.3], \n",
    "    'hid_layer': [512,1024,512,2048], \n",
    "    'init_non_scored_weights': False, \n",
    "    'label_smoothing': 0.0015, \n",
    "    'learning_rate': 0.001, 'epochs': 25\n",
    "}\n",
    "\n",
    "baseline_conf = (\n",
    "    fe_params, \n",
    "    nn_params, \n",
    "    {'zero_threshold': 0, \"use_error_class\": False}, 8, 1\n",
    ")\n",
    "\n",
    "new_conf = deepcopy(baseline_conf)\n",
    "# new_conf[2]['use_error_class'] = True\n",
    "\n",
    "new_score = create_and_evaluate_model(\n",
    "    new_conf, models=models_final, \n",
    "    run_name=f'base_{baseline_num}', n_split=5, verbose=0\n",
    ")\n",
    "\n",
    "print(\n",
    "    round(new_score - baseline_score, 6), \n",
    "    f'{100 * round(new_score/baseline_score, 3) - 100:.2f}%', \n",
    "    round(new_score, 6)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Public models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T19:41:09.762201Z",
     "start_time": "2020-11-28T19:41:09.758661Z"
    }
   },
   "outputs": [],
   "source": [
    "p_min = 1e-5\n",
    "p_max = 1.-1e-5\n",
    "batch_size = 128\n",
    "fold = fold_simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## keras NN +PCA with Label smoothing CV[0.01562] LB [0.01859]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T12:27:11.104488Z",
     "start_time": "2020-11-28T11:58:05.127874Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21948, 1043) should be: (, 1039)\n",
      "[02:13], Fold 0: 0.016077665932851228\n",
      "[02:40], Fold 1: 0.016139014846157457\n",
      "[02:21], Fold 2: 0.016049516507951788\n",
      "[02:16], Fold 3: 0.015945916239989495\n",
      "[02:21], Fold 4: 0.016240827478692616\n",
      "[02:29], Fold 5: 0.015985089542815856\n",
      "[02:30], Fold 6: 0.015586100719255144\n",
      "[02:30], Fold 7: 0.015697994209915803\n",
      "[02:16], Fold 8: 0.015996964666843715\n",
      "[02:08], Fold 9: 0.016317549712339566\n",
      "[02:39], Fold 10: 0.015972715173830587\n",
      "[02:16], Fold 11: 0.01589995101765791\n",
      "Valid logloss: 0.015992442170691762\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.015992442170691762"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://www.kaggle.com/riadalmadani/keras-nn-pca-with-label-smoothing\n",
    "\n",
    "seed = 8\n",
    "\n",
    "fe_params = {\n",
    "    'fe_cluster': {'enabled': False, 'n_clusters_c': 6, 'n_clusters_g': 44}, \n",
    "    'fe_stats': {'enabled': False}, \n",
    "    'pca': {'enabled': True, 'n_comp_cells': 50, 'n_comp_genes': 600}, \n",
    "    'scaler': 'quantile', 'shuffle_cols': True, \n",
    "    'variance_reduction': {'enabled': True, 'threshold': 0.8}\n",
    "}\n",
    "X_p, X_test_p, y_p, y0_p = preprocess_X(fe_params, X.copy(), X_test.copy(), y.copy(), y0.copy(), seed=seed)\n",
    "print(X_p.shape, 'should be: (, 1039)')\n",
    "\n",
    "nn_params = {\n",
    "    'batch_norm': True, 'weight_norm': True, \n",
    "    'activation': ['relu', 'relu', 'relu'], \n",
    "    'dropout': [0.2, 0.5, 0.2], \n",
    "    'hid_layer': [2048,1048,512], \n",
    "    'init_non_scored_weights': False, \n",
    "    'label_smoothing': 0.0015, \n",
    "    'learning_rate': 0.001, 'epochs': 500\n",
    "}\n",
    "nn_params = {\n",
    "    'batch_norm': True, 'weight_norm': True, \n",
    "    'activation': ['elu', 'elu', 'elu', 'elu'], \n",
    "    'dropout': [0.3, 0.3, 0.4, 0.3], \n",
    "    'hid_layer': [512,1024,512,2048], \n",
    "    'init_non_scored_weights': False, \n",
    "    'label_smoothing': 0.0015, \n",
    "    'learning_rate': 0.001, 'epochs': 35\n",
    "}\n",
    "main_model = DeepMultiLabelModel(nn_params, 'main', seed=seed, verbose=0)\n",
    "main_model.cv(X_p, y_p, y0_p, n_split=7, run_name='public_nn_1', overfit=True)\n",
    "# Epoch 5/35 0.0180\n",
    "# Epoch 10/35 0.0160"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pytorch-RankGauss-PCA-NN CV [0.014572] LB [0.01839]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T12:32:37.079291Z",
     "start_time": "2020-11-28T12:27:11.109487Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21948, 1015) should be: (, 1015)\n",
      "[01:54], Fold 0: 0.01641352227166248\n",
      "[01:44], Fold 1: 0.016291257878713786\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-099a1cfc3b24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m }\n\u001b[1;32m     25\u001b[0m \u001b[0mmain_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDeepMultiLabelModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'main'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mmain_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'public_nn_2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverfit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# FOLD: 0, EPOCH: 5, valid_loss: 0.017283157035708426\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-0f99f97cd21a>\u001b[0m in \u001b[0;36mcv\u001b[0;34m(self, X, y, y0, run_name, n_split, return_pred, metric_fn, overfit, run_tags)\u001b[0m\n\u001b[1;32m    193\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m             )\n\u001b[0;32m--> 195\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m             \u001b[0mmodel_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefinition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-0f99f97cd21a>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x_tr, y_tr, x_val, y_val, y0_tr, y0_val)\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         self.history = model.fit(\n\u001b[0m\u001b[1;32m    133\u001b[0m             \u001b[0mx_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# https://www.kaggle.com/vbmokin/moa-pytorch-rankgauss-pca-nn-upgrade-3d-visual\n",
    "seed = 0\n",
    "\n",
    "fe_params = {\n",
    "    'fe_cluster': {'enabled': False, 'n_clusters_c': 6, 'n_clusters_g': 44}, \n",
    "    'fe_stats': {'enabled': False}, \n",
    "    'pca': {'enabled': True, 'n_comp_cells': 60, 'n_comp_genes': 463}, \n",
    "    'scaler': 'quantile', 'shuffle_cols': True, \n",
    "    'variance_reduction': {'enabled': True, 'threshold': 0.9}\n",
    "}\n",
    "\n",
    "X_p, X_test_p, y_p, y0_p = preprocess_X(fe_params, X.copy(), X_test.copy(), y.copy(), y0.copy(), seed=seed)\n",
    "\n",
    "print(X_p.shape, 'should be: (, 1015)')\n",
    "\n",
    "nn_params = {\n",
    "    'batch_norm': True, 'weight_norm': True, \n",
    "    'activation': ['leaky_relu', 'leaky_relu'], \n",
    "    'dropout': [0.25, 0.25], \n",
    "    'hid_layer': [1500, 1500], \n",
    "    'init_non_scored_weights': False, \n",
    "    'label_smoothing': 0,\n",
    "    'learning_rate': 0.001, 'epochs': 25\n",
    "}\n",
    "main_model = DeepMultiLabelModel(nn_params, 'main', verbose=0, seed=seed)\n",
    "main_model.cv(X_p, y_p, y0_p, n_split=7, run_name='public_nn_2', overfit=True)\n",
    "\n",
    "# FOLD: 0, EPOCH: 5, valid_loss: 0.017283157035708426\n",
    "# FOLD: 0, EPOCH: 10, valid_loss: 0.01737722285091877\n",
    "# FOLD: 0, EPOCH: 24, valid_loss: 0.016081880070269106"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## MODEL1 CV [0.01562060391771847] LB [0.01833]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T12:32:37.081718Z",
     "start_time": "2020-11-28T11:58:16.703Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/vikazrajpurohit/3-model-training-and-inference#1.-MODEL1-CV-[0.01562060391771847]-LB-[0.01833]\n",
    "seed = 42\n",
    "\n",
    "# TODO:\n",
    "# Fine tune и полный transfer learning\n",
    "\n",
    "fe_params = {\n",
    "    'fe_cluster': {'enabled': True, 'n_clusters_c': 4, 'n_clusters_g': 22}, \n",
    "    'fe_stats': {'enabled': True}, \n",
    "    'pca': {'enabled': True, 'n_comp_cells': 50, 'n_comp_genes': 600, 'n_clusters': 5},\n",
    "    'scaler': 'quantile', 'shuffle_cols': False, \n",
    "    'variance_reduction': {'enabled': True, 'threshold': 0.85}\n",
    "}\n",
    "\n",
    "y0_s = pd.concat([y, y0], axis=1)\n",
    "\n",
    "X_p, X_test_p = preprocess_X(fe_params, X.copy(), X_test.copy(), seed=seed)\n",
    "print(X_p.shape, 'should be: (, 1240)')\n",
    "\n",
    "nn_params = {\n",
    "    'batch_norm': True, 'weight_norm': 'output',\n",
    "    'activation': ['leaky_relu', 'leaky_relu', 'leaky_relu', 'leaky_relu'], \n",
    "    'dropout': [0.5, 0.35, 0.3, 0.25], \n",
    "    'hid_layer': [1500, 1250, 1000, 750], \n",
    "    'init_non_scored_weights': 'ALL_TARGETS', \n",
    "    'label_smoothing': 0, \n",
    "    'learning_rate': 1e-3, 'epochs': 25\n",
    "}\n",
    "main_model = DeepMultiLabelModel(nn_params, 'main', verbose=0, seed=0)\n",
    "main_model.cv(X_p, y, y0_s, n_split=7, run_name='tune_public_3', overfit=True)\n",
    "\n",
    "# ALL_TARGETS:\n",
    "    # SEED: 0, FOLD: 0, EPOCH: 5, train_loss: 0.013472, valid_loss: 0.009183\n",
    "    # SEED: 0, FOLD: 0, EPOCH: 23, train_loss: 0.012016, valid_loss: 0.008624\n",
    "# SCORED_ONLY:\n",
    "    # SEED: 0, FOLD: 0, EPOCH: 5, train_loss: 0.019837, valid_loss: 0.016361\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Auto Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T10:49:40.396277Z",
     "start_time": "2020-11-29T10:49:35.582552Z"
    }
   },
   "outputs": [],
   "source": [
    "from hyperopt import fmin, tpe, hp, Trials, space_eval\n",
    "from hyperopt.pyll.stochastic import sample as ho_sample\n",
    "\n",
    "model_shapes = [\n",
    "    # https://www.kaggle.com/sinamhd9/mechanisms-of-action-moa-tutorial/data\n",
    "    [[1792, 1024, 2048], [0.65, 0.7, 0.6], ['relu', 'relu', 'relu']],\n",
    "    [[1792, 1024, 2048], [0.65, 0.7, 0.6], ['selu','swish','swish']],\n",
    "    [[1152, 1152, 2048], [0.7,0.7,0.3], ['selu', 'swish', 'swish']],\n",
    "    [[1408, 1152, 1920], [0.7,0.65,0.45], ['selu','swish','swish']],\n",
    "    [[1280,1152,1920], [0.7,0.55,0.3], ['selu','swish','swish']],\n",
    "    [[896, 768, 2048], [0.7,0.7,0.3], ['selu','swish','elu']],\n",
    "    [[1280, 768, 2048], [0.7,0.7,0.3], ['selu','swish','elu']],\n",
    "    [[1152, 2048, 1280], [0.7,0.7,0.6], ['selu','swish','swish']],\n",
    "    [[768,512,2048], [0.65,0.7,0.3], ['selu','swish','selu']],\n",
    "    [[1664,1408,1280], [0.65,0.7,0.6], ['selu','swish','swish']],\n",
    "    [[1408,1280,2048], [0.65, 0.65, 0.3], ['selu','swish','elu']],\n",
    "    \n",
    "    # https://www.kaggle.com/omniking1999/notebook-v3-0\n",
    "    [[2048,1048,512], [0.2, 0.5, 0.2], ['relu', 'relu', 'relu']],\n",
    "    [[512, 1024, 512, 2048], [0.3, 0.3, 0.4, 0.3], ['elu','elu','elu','elu']],\n",
    "    [[1500, 1250, 1000, 750], [0.5, 0.35, 0.3, 0.25], ['leaky_relu', 'leaky_relu', 'leaky_relu', 'leaky_relu']]\n",
    "]\n",
    "\n",
    "seeds = [34, 9, 42, 11, 22, 8, 13, 25, 21, 29]\n",
    "\n",
    "space_preprocess = [{\n",
    "        'scaler': hp.choice('scaler', ['gauss', 'quantile', 'none', 'standard']),\n",
    "        'fe_stats': hp.choice('fe_stats', [{\n",
    "            \"enabled\": hp.choice('fe_stats_enabled', [True, False]),\n",
    "        }]),\n",
    "        'pca': hp.choice('pca', [{\n",
    "            \"enabled\": hp.choice('pca_enabled1', [True]),\n",
    "            \"n_comp_genes\": hp.uniformint('n_comp_genes', 300, 700),\n",
    "            \"n_comp_cells\": hp.uniformint('n_comp_cells', 30, 90),\n",
    "        }, {\n",
    "            \"enabled\": hp.choice('pca_enabled2', [False]),\n",
    "        }]),\n",
    "        'fe_cluster': hp.choice('fe_cluster', [{\n",
    "            \"enabled\": hp.choice('fe_cluster_enabled1', [False]),\n",
    "        },\n",
    "        {\n",
    "            \"enabled\": hp.choice('fe_cluster_enabled2', [True]),\n",
    "            \"n_clusters_g\": hp.uniformint('n_clusters_g', 15, 45),\n",
    "            \"n_clusters_c\": hp.uniformint('n_clusters_c', 5, 15),\n",
    "        }]),\n",
    "        'variance_reduction': hp.choice('variance_reduction', [{\n",
    "            \"enabled\": hp.choice('variance_reduction_enabled1', [True]),\n",
    "            \"threshold\": hp.uniform('threshold', 0.7, 0.9)\n",
    "        }, {\n",
    "            \"enabled\": hp.choice('variance_reduction_enabled2', [False]),\n",
    "        }]),\n",
    "        'shuffle_cols': hp.choice('shuffle_cols', [True, False]),\n",
    "    }]\n",
    "\n",
    "space_deep = [{\n",
    "        \"hid_layer\": hp.choice(f'hid_layer_{i}', [model_shape[0]]),\n",
    "        'activation': hp.choice(f'activation_{i}', [model_shape[2]]),\n",
    "        'dropout': hp.choice(f'dropout_{i}', [model_shape[1]]),\n",
    "        'learning_rate': hp.uniform(f'learning_rate_{i}', 0.001, 0.5),\n",
    "        'label_smoothing': hp.uniform(f'label_smoothing{i}', 0.0001, 0.003),\n",
    "        'init_non_scored_weights': hp.choice(f'init_non_scored_weights_{i}', ['ALL_TARGETS', 'ONLY_NON_SCORED', False]),\n",
    "        'batch_norm': hp.choice(f'batch_norm_{i}', [True, False]),\n",
    "        'weight_norm': hp.choice(f'weight_norm_{i}', [True, False]),\n",
    "        'epochs': hp.choice(f'epochs_{i}', [50, 100, 200])\n",
    "    } for i, model_shape in enumerate(model_shapes)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T10:49:40.421930Z",
     "start_time": "2020-11-29T10:49:40.398274Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'fe_cluster': {'enabled': False},\n",
       "  'fe_stats': {'enabled': False},\n",
       "  'pca': {'enabled': True, 'n_comp_cells': 50, 'n_comp_genes': 421},\n",
       "  'scaler': 'none',\n",
       "  'shuffle_cols': True,\n",
       "  'variance_reduction': {'enabled': False}},\n",
       " {'activation': ('relu', 'relu', 'relu'),\n",
       "  'batch_norm': True,\n",
       "  'dropout': (0.2, 0.5, 0.2),\n",
       "  'epochs': 200,\n",
       "  'hid_layer': (2048, 1048, 512),\n",
       "  'init_non_scored_weights': 'ALL_TARGETS',\n",
       "  'label_smoothing': 0.0013903022345106873,\n",
       "  'learning_rate': 0.19762524081127897,\n",
       "  'weight_norm': False},\n",
       " 25)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_class_space = [\n",
    "    hp.choice('preprocess', space_preprocess),\n",
    "    hp.choice('deep_params', space_deep),\n",
    "    hp.choice('seed', seeds)\n",
    "]\n",
    "\n",
    "def evaluate_error_class(args, run_name=None, n_split=7):\n",
    "    print(args)\n",
    "    fe_params, nn_params, seed = args\n",
    "    seed_everything(seed)\n",
    "\n",
    "    X_p, X_test_p, y_p, y0_p = preprocess_X(fe_params, X.copy(), X_test.copy(), y.copy(), y0.copy(), seed=seed)\n",
    "\n",
    "    error_model = DeepMultiLabelModel(nn_params, 'errors', verbose=0)\n",
    "\n",
    "    y_error = y_to_error_classes(y_p)\n",
    "    return error_model.cv(\n",
    "        X_p, y_error, y0_p, n_split=n_split, run_name=run_name,\n",
    "        run_tags={\"args\": str(args)}\n",
    "    )\n",
    "\n",
    "trials_version = 'error_class'\n",
    "run_name = f'tune_{trials_version}'\n",
    "space = error_class_space\n",
    "score_func = partial(evaluate_error_class, run_name=run_name, n_split=5)\n",
    "\n",
    "ho_sample(space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T10:49:41.056418Z",
     "start_time": "2020-11-29T10:49:40.423781Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'fe_cluster': {'enabled': True, 'n_clusters_c': 7, 'n_clusters_g': 31},\n",
       "  'fe_stats': {'enabled': False},\n",
       "  'pca': {'enabled': False},\n",
       "  'scaler': 'quantile',\n",
       "  'shuffle_cols': False,\n",
       "  'variance_reduction': {'enabled': True, 'threshold': 0.7301264415366084}},\n",
       " {'activation': ('leaky_relu', 'leaky_relu', 'leaky_relu', 'leaky_relu'),\n",
       "  'batch_norm': True,\n",
       "  'dropout': (0.5, 0.35, 0.3, 0.25),\n",
       "  'epochs': 50,\n",
       "  'hid_layer': (1500, 1250, 1000, 750),\n",
       "  'init_non_scored_weights': 'ALL_TARGETS',\n",
       "  'label_smoothing': 0.0015276734192733535,\n",
       "  'learning_rate': 0.2359297392950623,\n",
       "  'weight_norm': False},\n",
       " 29)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_class_space = [\n",
    "    hp.choice('preprocess', space_preprocess),\n",
    "    hp.choice('deep_params', space_deep),\n",
    "    hp.choice('seed', seeds)\n",
    "]\n",
    "\n",
    "def evaluate_zero_class(args, run_name=None, run_tags=None, n_split=7):\n",
    "    print(args)\n",
    "    fe_params, nn_params, seed = args\n",
    "    seed_everything(seed)\n",
    "\n",
    "    X_p, X_test_p, y_p, y0_p = preprocess_X(fe_params, X.copy(), X_test.copy(), y.copy(), y0.copy(), seed=seed)\n",
    "\n",
    "    error_model = DeepMultiLabelModel(nn_params, 'zero', verbose=0)\n",
    "\n",
    "    y_error = y_to_zero_class(y_p)\n",
    "    return error_model.cv(\n",
    "        X_p, y_error, y_to_zero_class(y0_p), n_split=n_split, \n",
    "        run_name=run_name, run_tags={\"args\": str(args)}\n",
    "    )\n",
    "\n",
    "trials_version = 'zero_class'\n",
    "run_name = f'tune_{trials_version}'\n",
    "space = zero_class_space\n",
    "score_func = partial(evaluate_zero_class, run_name=run_name, n_split=5)\n",
    "\n",
    "ho_sample(space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Blender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T10:49:41.274515Z",
     "start_time": "2020-11-29T10:49:41.057658Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'fe_cluster': {'enabled': False},\n",
       "  'fe_stats': {'enabled': True},\n",
       "  'pca': {'enabled': False},\n",
       "  'scaler': 'quantile',\n",
       "  'shuffle_cols': False,\n",
       "  'variance_reduction': {'enabled': True, 'threshold': 0.7975799573564033}},\n",
       " {'activation': ('selu', 'swish', 'swish'),\n",
       "  'batch_norm': True,\n",
       "  'dropout': (0.7, 0.65, 0.45),\n",
       "  'epochs': 200,\n",
       "  'hid_layer': (1408, 1152, 1920),\n",
       "  'init_non_scored_weights': False,\n",
       "  'label_smoothing': 0.000764792127236131,\n",
       "  'learning_rate': 0.3400409407529937,\n",
       "  'weight_norm': True},\n",
       " {'use_error_class': True, 'zero_threshold': 0},\n",
       " 25,\n",
       " 1)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blend_space = [\n",
    "    hp.choice('preprocess', space_preprocess),\n",
    "    hp.choice('deep_params', space_deep),\n",
    "    hp.choice('blend_params', [\n",
    "    {\n",
    "        'zero_threshold': hp.uniform('zero_threshold1', 0.95, 0.999),\n",
    "        'use_error_class': hp.choice('use_error_class1', [True, False]),\n",
    "    },\n",
    "    {\n",
    "        'zero_threshold': hp.choice('zero_threshold2', [0]),\n",
    "        'use_error_class': hp.choice('use_error_class2', [True, False]),\n",
    "    }]),\n",
    "    hp.choice('seed', seeds),\n",
    "    hp.choice('y_quantiles', [1, 2]),\n",
    "]\n",
    "\n",
    "trials_version = 'blender2'\n",
    "run_name = f'tune_{trials_version}'\n",
    "space = blend_space\n",
    "score_func = partial(create_and_evaluate_model, models=None, run_name=run_name, n_split=7)\n",
    "\n",
    "ho_sample(space)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T10:13:53.536985Z",
     "start_time": "2020-11-29T06:18:20.211109Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'fe_cluster': {'enabled': True, 'n_clusters_c': 5, 'n_clusters_g': 19}, 'fe_stats': {'enabled': False}, 'pca': {'enabled': False}, 'scaler': 'none', 'shuffle_cols': True, 'variance_reduction': {'enabled': True, 'threshold': 0.7234634592150213}}, {'activation': ('selu', 'swish', 'selu'), 'batch_norm': False, 'dropout': (0.65, 0.7, 0.3), 'epochs': 100, 'hid_layer': (768, 512, 2048), 'init_non_scored_weights': 'ALL_TARGETS', 'label_smoothing': 0.0006978288035937164, 'learning_rate': 0.3178535920260323, 'weight_norm': True}, {'use_error_class': True, 'zero_threshold': 0.985059066480174}, 22, 1)\n",
      "[02:33], Fold 0: 0.019598324077761204                \n",
      "break cv execution 0.019598324077761204 > 0.019      \n",
      "({'fe_cluster': {'enabled': True, 'n_clusters_c': 15, 'n_clusters_g': 43}, 'fe_stats': {'enabled': True}, 'pca': {'enabled': True, 'n_comp_cells': 74, 'n_comp_genes': 557}, 'scaler': 'quantile', 'shuffle_cols': True, 'variance_reduction': {'enabled': True, 'threshold': 0.7189569644347072}}, {'activation': ('selu', 'swish', 'swish'), 'batch_norm': True, 'dropout': (0.7, 0.7, 0.6), 'epochs': 100, 'hid_layer': (1152, 2048, 1280), 'init_non_scored_weights': 'ONLY_NON_SCORED', 'label_smoothing': 0.0017502808718730962, 'learning_rate': 0.3230563364478111, 'weight_norm': False}, {'use_error_class': False, 'zero_threshold': 0}, 25, 2)\n",
      "[04:43], Fold 0: 0.02259846712657795                              \n",
      "break cv execution 0.02259846712657795 > 0.019                    \n",
      "100%|██████████| 2/2 [08:31<00:00, 255.82s/trial, best loss: 0.19]\n",
      "({'fe_cluster': {'enabled': True, 'n_clusters_c': 14, 'n_clusters_g': 42}, 'fe_stats': {'enabled': True}, 'pca': {'enabled': False}, 'scaler': 'standard', 'shuffle_cols': False, 'variance_reduction': {'enabled': True, 'threshold': 0.7886489739495448}}, {'activation': ('selu', 'swish', 'selu'), 'batch_norm': False, 'dropout': (0.65, 0.7, 0.3), 'epochs': 200, 'hid_layer': (768, 512, 2048), 'init_non_scored_weights': False, 'label_smoothing': 0.0029076049700110323, 'learning_rate': 0.19216429141100252, 'weight_norm': True}, {'use_error_class': False, 'zero_threshold': 0.9942998976729281}, 29, 2)\n",
      "[01:29], Fold 0: 0.018801667985491877                        \n",
      "[01:07], Fold 1: 0.019978372146150804                        \n",
      "break cv execution 0.019978372146150804 > 0.019              \n",
      "({'fe_cluster': {'enabled': False}, 'fe_stats': {'enabled': False}, 'pca': {'enabled': True, 'n_comp_cells': 79, 'n_comp_genes': 411}, 'scaler': 'gauss', 'shuffle_cols': True, 'variance_reduction': {'enabled': False}}, {'activation': ('selu', 'swish', 'elu'), 'batch_norm': False, 'dropout': (0.7, 0.7, 0.3), 'epochs': 50, 'hid_layer': (896, 768, 2048), 'init_non_scored_weights': 'ONLY_NON_SCORED', 'label_smoothing': 0.0014884856868194656, 'learning_rate': 0.003136293809714334, 'weight_norm': False}, {'use_error_class': True, 'zero_threshold': 0.9612490662702131}, 8, 1)\n",
      "[02:21], Fold 0: 0.020006752962845764                             \n",
      "break cv execution 0.020006752962845764 > 0.019                   \n",
      "100%|██████████| 4/4 [06:03<00:00, 90.96s/trial, best loss: 0.19] \n",
      "({'fe_cluster': {'enabled': False}, 'fe_stats': {'enabled': False}, 'pca': {'enabled': True, 'n_comp_cells': 81, 'n_comp_genes': 606}, 'scaler': 'quantile', 'shuffle_cols': True, 'variance_reduction': {'enabled': False}}, {'activation': ('selu', 'swish', 'elu'), 'batch_norm': True, 'dropout': (0.7, 0.7, 0.3), 'epochs': 50, 'hid_layer': (896, 768, 2048), 'init_non_scored_weights': 'ONLY_NON_SCORED', 'label_smoothing': 0.001430271450218026, 'learning_rate': 0.306062767069022, 'weight_norm': True}, {'use_error_class': True, 'zero_threshold': 0}, 11, 1)\n",
      "[03:21], Fold 0: 0.02013300735462696                         \n",
      "break cv execution 0.02013300735462696 > 0.019               \n",
      "({'fe_cluster': {'enabled': False}, 'fe_stats': {'enabled': False}, 'pca': {'enabled': True, 'n_comp_cells': 85, 'n_comp_genes': 418}, 'scaler': 'quantile', 'shuffle_cols': False, 'variance_reduction': {'enabled': True, 'threshold': 0.8831168888228615}}, {'activation': ('relu', 'relu', 'relu'), 'batch_norm': True, 'dropout': (0.2, 0.5, 0.2), 'epochs': 100, 'hid_layer': (2048, 1048, 512), 'init_non_scored_weights': False, 'label_smoothing': 0.002797433536021185, 'learning_rate': 0.2897024957730486, 'weight_norm': True}, {'use_error_class': False, 'zero_threshold': 0.9662682868254961}, 22, 2)\n",
      "[02:20], Fold 0: 0.019845850491750104                             \n",
      "break cv execution 0.019845850491750104 > 0.019                   \n",
      "100%|██████████| 6/6 [06:17<00:00, 62.92s/trial, best loss: 0.19] \n",
      "({'fe_cluster': {'enabled': False}, 'fe_stats': {'enabled': False}, 'pca': {'enabled': False}, 'scaler': 'quantile', 'shuffle_cols': False, 'variance_reduction': {'enabled': False}}, {'activation': ('selu', 'swish', 'swish'), 'batch_norm': True, 'dropout': (0.7, 0.7, 0.3), 'epochs': 200, 'hid_layer': (1152, 1152, 2048), 'init_non_scored_weights': 'ONLY_NON_SCORED', 'label_smoothing': 0.0009771883416804452, 'learning_rate': 0.11761814563726697, 'weight_norm': True}, {'use_error_class': False, 'zero_threshold': 0}, 11, 2)\n",
      "[04:20], Fold 0: 0.018952685312066182                         \n",
      "[04:48], Fold 1: 0.018668267869753546                        \n",
      "[04:50], Fold 2: 0.018318618348182707                        \n",
      "[04:41], Fold 3: 0.019007333159604452                         \n",
      "break cv execution 0.019007333159604452 > 0.019               \n",
      "({'fe_cluster': {'enabled': False}, 'fe_stats': {'enabled': True}, 'pca': {'enabled': True, 'n_comp_cells': 38, 'n_comp_genes': 683}, 'scaler': 'standard', 'shuffle_cols': True, 'variance_reduction': {'enabled': False}}, {'activation': ('relu', 'relu', 'relu'), 'batch_norm': False, 'dropout': (0.65, 0.7, 0.6), 'epochs': 50, 'hid_layer': (1792, 1024, 2048), 'init_non_scored_weights': 'ALL_TARGETS', 'label_smoothing': 0.0013432911732844785, 'learning_rate': 0.32248546838896364, 'weight_norm': True}, {'use_error_class': False, 'zero_threshold': 0.9875404088098492}, 29, 2)\n",
      "[04:01], Fold 0: 0.021293196710370717                              \n",
      "break cv execution 0.021293196710370717 > 0.019                    \n",
      "100%|██████████| 8/8 [23:13<00:00, 174.18s/trial, best loss: 0.19] \n",
      "({'fe_cluster': {'enabled': False}, 'fe_stats': {'enabled': False}, 'pca': {'enabled': True, 'n_comp_cells': 57, 'n_comp_genes': 321}, 'scaler': 'gauss', 'shuffle_cols': True, 'variance_reduction': {'enabled': False}}, {'activation': ('selu', 'swish', 'swish'), 'batch_norm': False, 'dropout': (0.65, 0.7, 0.6), 'epochs': 100, 'hid_layer': (1792, 1024, 2048), 'init_non_scored_weights': 'ALL_TARGETS', 'label_smoothing': 0.001149810150809531, 'learning_rate': 0.024465478000991126, 'weight_norm': True}, {'use_error_class': False, 'zero_threshold': 0.9961802014144556}, 25, 1)\n",
      "[06:06], Fold 0: 0.016852943299564434                          \n",
      "[05:36], Fold 1: 0.017091099638381697                         \n",
      "[05:09], Fold 2: 0.016782110693644582                         \n",
      "[05:06], Fold 3: 0.01686275479761972                           \n",
      "[05:51], Fold 4: 0.01684331184450293                           \n",
      "[05:59], Fold 5: 0.01698954409645141                           \n",
      "[05:28], Fold 6: 0.016790426595935177                          \n",
      "Valid logloss: 0.016887459584461237                            \n",
      "INITIAL                                                        \n",
      "0.016887459584461237                                           \n",
      "[04:10], Fold 0: 0.5930874584451227                            \n",
      "[04:24], Fold 1: 0.5881314133614257                            \n",
      "[04:30], Fold 2: 0.5835006920064596                            \n",
      "[05:23], Fold 3: 0.5967700162426397                            \n",
      "[04:44], Fold 4: 0.5816170011383814                            \n",
      "[07:37], Fold 5: 0.5914943875145051                              \n",
      "[04:11], Fold 6: 0.5882537655982037                              \n",
      "Valid logloss: 0.5889791466928849                                \n",
      "Override to zeros: 2 rows                                        \n",
      "AFTER ZERO                                                       \n",
      "0.016887239420322404                                             \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Write bundle: bundles/1606637843.pickle                          \n",
      "Final valid logloss: 0.016887239420322404                        \n",
      "({'fe_cluster': {'enabled': False}, 'fe_stats': {'enabled': False}, 'pca': {'enabled': True, 'n_comp_cells': 31, 'n_comp_genes': 421}, 'scaler': 'gauss', 'shuffle_cols': True, 'variance_reduction': {'enabled': False}}, {'activation': ('selu', 'swish', 'swish'), 'batch_norm': True, 'dropout': (0.7, 0.55, 0.3), 'epochs': 50, 'hid_layer': (1280, 1152, 1920), 'init_non_scored_weights': 'ALL_TARGETS', 'label_smoothing': 0.0006826099873616829, 'learning_rate': 0.24079210897919928, 'weight_norm': True}, {'use_error_class': False, 'zero_threshold': 0.9899258094559541}, 25, 1)\n",
      "[05:08], Fold 0: 0.018535108846555362                                                   \n",
      "[06:26], Fold 1: 0.01828687115274234                                                    \n",
      "[05:52], Fold 2: 0.018353876791802372                                                   \n",
      "[06:15], Fold 3: 0.017746311248941285                                                   \n",
      "[06:02], Fold 4: 0.018205365084935105                                                   \n",
      "[05:25], Fold 5: 0.018456963124138616                                                   \n",
      "[05:40], Fold 6: 0.01828801905026348                                                    \n",
      "Valid logloss: 0.01826748025628776                                                      \n",
      "INITIAL                                                                                 \n",
      "0.01826748025628776                                                                     \n",
      "[03:08], Fold 0: 0.607867904400378                                                      \n",
      "[04:45], Fold 1: 0.6037182105454866                                                     \n",
      "[05:22], Fold 2: 0.6008193662958352                                                     \n",
      "[04:55], Fold 3: 0.608468636410352                                                      \n",
      "[04:44], Fold 4: 0.5986717415302389                                                     \n",
      "[03:45], Fold 5: 0.6076307098697092                                                     \n",
      "[04:27], Fold 6: 0.602652556813822                                                      \n",
      "Valid logloss: 0.6042612864530068                                                       \n",
      "Override to zeros: 0 rows                                                               \n",
      "AFTER ZERO                                                                              \n",
      "0.01826748025628776                                                                     \n",
      "Write bundle: bundles/1606642203.pickle                                                 \n",
      "Final valid logloss: 0.01826748025628776                                                \n",
      "100%|██████████| 10/10 [2:27:37<00:00, 885.75s/trial, best loss: 0.016887239420322404]  \n",
      "({'fe_cluster': {'enabled': False}, 'fe_stats': {'enabled': True}, 'pca': {'enabled': False}, 'scaler': 'gauss', 'shuffle_cols': True, 'variance_reduction': {'enabled': False}}, {'activation': ('relu', 'relu', 'relu'), 'batch_norm': False, 'dropout': (0.2, 0.5, 0.2), 'epochs': 50, 'hid_layer': (2048, 1048, 512), 'init_non_scored_weights': 'ALL_TARGETS', 'label_smoothing': 0.0005449701979443096, 'learning_rate': 0.38731573072277886, 'weight_norm': True}, {'use_error_class': True, 'zero_threshold': 0}, 22, 2)\n",
      "[04:03], Fold 0: 0.018394071682155035                           \n",
      "[03:30], Fold 1: 0.018446944276122933                          \n",
      "[02:51], Fold 2: 0.02039250896813757                           \n",
      "break cv execution 0.02039250896813757 > 0.019                 \n",
      "({'fe_cluster': {'enabled': True, 'n_clusters_c': 9, 'n_clusters_g': 28}, 'fe_stats': {'enabled': False}, 'pca': {'enabled': False}, 'scaler': 'standard', 'shuffle_cols': False, 'variance_reduction': {'enabled': True, 'threshold': 0.7846653313846519}}, {'activation': ('selu', 'swish', 'swish'), 'batch_norm': True, 'dropout': (0.7, 0.65, 0.45), 'epochs': 50, 'hid_layer': (1408, 1152, 1920), 'init_non_scored_weights': 'ONLY_NON_SCORED', 'label_smoothing': 0.0016807318260523595, 'learning_rate': 0.046106016883367955, 'weight_norm': False}, {'use_error_class': False, 'zero_threshold': 0.9804717830749904}, 11, 1)\n",
      "[02:53], Fold 0: 0.019287119355979924                                               \n",
      "break cv execution 0.019287119355979924 > 0.019                                     \n",
      "100%|██████████| 12/12 [14:17<00:00, 71.44s/trial, best loss: 0.016887239420322404] \n",
      "({'fe_cluster': {'enabled': False}, 'fe_stats': {'enabled': False}, 'pca': {'enabled': True, 'n_comp_cells': 69, 'n_comp_genes': 471}, 'scaler': 'quantile', 'shuffle_cols': False, 'variance_reduction': {'enabled': False}}, {'activation': ('leaky_relu', 'leaky_relu', 'leaky_relu', 'leaky_relu'), 'batch_norm': True, 'dropout': (0.5, 0.35, 0.3, 0.25), 'epochs': 50, 'hid_layer': (1500, 1250, 1000, 750), 'init_non_scored_weights': False, 'label_smoothing': 0.0010338141630714668, 'learning_rate': 0.3055857523417075, 'weight_norm': False}, {'use_error_class': False, 'zero_threshold': 0}, 8, 1)\n",
      "[01:17], Fold 0: 0.021931011411861864                           \n",
      "break cv execution 0.021931011411861864 > 0.019                \n",
      "({'fe_cluster': {'enabled': False}, 'fe_stats': {'enabled': True}, 'pca': {'enabled': False}, 'scaler': 'none', 'shuffle_cols': True, 'variance_reduction': {'enabled': True, 'threshold': 0.7902405987719168}}, {'activation': ('elu', 'elu', 'elu', 'elu'), 'batch_norm': False, 'dropout': (0.3, 0.3, 0.4, 0.3), 'epochs': 200, 'hid_layer': (512, 1024, 512, 2048), 'init_non_scored_weights': 'ONLY_NON_SCORED', 'label_smoothing': 0.00222280987061734, 'learning_rate': 0.29328658723726375, 'weight_norm': True}, {'use_error_class': False, 'zero_threshold': 0.9933179191444811}, 22, 1)\n",
      "[03:27], Fold 0: 0.017716091352380267                                              \n",
      "[02:05], Fold 1: 0.021189240543897106                                              \n",
      "break cv execution 0.021189240543897106 > 0.019                                    \n",
      "100%|██████████| 14/14 [07:18<00:00, 31.35s/trial, best loss: 0.016887239420322404] \n",
      "({'fe_cluster': {'enabled': True, 'n_clusters_c': 12, 'n_clusters_g': 37}, 'fe_stats': {'enabled': False}, 'pca': {'enabled': True, 'n_comp_cells': 43, 'n_comp_genes': 386}, 'scaler': 'quantile', 'shuffle_cols': True, 'variance_reduction': {'enabled': True, 'threshold': 0.7466461437260404}}, {'activation': ('selu', 'swish', 'selu'), 'batch_norm': True, 'dropout': (0.65, 0.7, 0.3), 'epochs': 100, 'hid_layer': (768, 512, 2048), 'init_non_scored_weights': 'ALL_TARGETS', 'label_smoothing': 0.00011528622044801593, 'learning_rate': 0.4024352085187225, 'weight_norm': True}, {'use_error_class': True, 'zero_threshold': 0.994309358996566}, 13, 2)\n",
      "[03:25], Fold 0: 0.019438625235842402                           \n",
      "break cv execution 0.019438625235842402 > 0.019                \n",
      "({'fe_cluster': {'enabled': True, 'n_clusters_c': 7, 'n_clusters_g': 30}, 'fe_stats': {'enabled': True}, 'pca': {'enabled': False}, 'scaler': 'quantile', 'shuffle_cols': True, 'variance_reduction': {'enabled': True, 'threshold': 0.7208486832946158}}, {'activation': ('selu', 'swish', 'swish'), 'batch_norm': False, 'dropout': (0.7, 0.7, 0.3), 'epochs': 100, 'hid_layer': (1152, 1152, 2048), 'init_non_scored_weights': 'ONLY_NON_SCORED', 'label_smoothing': 0.0012136009992569725, 'learning_rate': 0.19324451603421447, 'weight_norm': False}, {'use_error_class': True, 'zero_threshold': 0.9937309881226047}, 11, 1)\n",
      "[01:42], Fold 0: 0.02230729221391826                                                \n",
      "break cv execution 0.02230729221391826 > 0.019                                      \n",
      "100%|██████████| 16/16 [06:48<00:00, 25.52s/trial, best loss: 0.016887239420322404] \n",
      "({'fe_cluster': {'enabled': False}, 'fe_stats': {'enabled': True}, 'pca': {'enabled': False}, 'scaler': 'standard', 'shuffle_cols': False, 'variance_reduction': {'enabled': False}}, {'activation': ('selu', 'swish', 'selu'), 'batch_norm': True, 'dropout': (0.65, 0.7, 0.3), 'epochs': 100, 'hid_layer': (768, 512, 2048), 'init_non_scored_weights': False, 'label_smoothing': 0.0017134994426947654, 'learning_rate': 0.25195960770816545, 'weight_norm': True}, {'use_error_class': True, 'zero_threshold': 0.9717527968194115}, 13, 1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[02:07], Fold 0: 0.019021791628142225                           \n",
      "break cv execution 0.019021791628142225 > 0.019                \n",
      "({'fe_cluster': {'enabled': True, 'n_clusters_c': 7, 'n_clusters_g': 19}, 'fe_stats': {'enabled': True}, 'pca': {'enabled': False}, 'scaler': 'none', 'shuffle_cols': True, 'variance_reduction': {'enabled': True, 'threshold': 0.8928614016614166}}, {'activation': ('selu', 'swish', 'elu'), 'batch_norm': True, 'dropout': (0.7, 0.7, 0.3), 'epochs': 100, 'hid_layer': (1280, 768, 2048), 'init_non_scored_weights': 'ALL_TARGETS', 'label_smoothing': 0.0023829260181337446, 'learning_rate': 0.2888229788487776, 'weight_norm': False}, {'use_error_class': True, 'zero_threshold': 0}, 22, 1)\n",
      "[03:43], Fold 0: 0.02094429656680182                                                \n",
      "break cv execution 0.02094429656680182 > 0.019                                      \n",
      "100%|██████████| 18/18 [06:36<00:00, 22.03s/trial, best loss: 0.016887239420322404] \n",
      "({'fe_cluster': {'enabled': False}, 'fe_stats': {'enabled': True}, 'pca': {'enabled': True, 'n_comp_cells': 79, 'n_comp_genes': 303}, 'scaler': 'standard', 'shuffle_cols': True, 'variance_reduction': {'enabled': True, 'threshold': 0.8167074920480217}}, {'activation': ('selu', 'swish', 'elu'), 'batch_norm': True, 'dropout': (0.65, 0.65, 0.3), 'epochs': 100, 'hid_layer': (1408, 1280, 2048), 'init_non_scored_weights': 'ALL_TARGETS', 'label_smoothing': 0.002488279246408773, 'learning_rate': 0.4702211998327671, 'weight_norm': False}, {'use_error_class': False, 'zero_threshold': 0}, 9, 2)\n",
      "[05:39], Fold 0: 0.02113153829110445                            \n",
      "break cv execution 0.02113153829110445 > 0.019                 \n",
      "({'fe_cluster': {'enabled': True, 'n_clusters_c': 10, 'n_clusters_g': 25}, 'fe_stats': {'enabled': False}, 'pca': {'enabled': True, 'n_comp_cells': 66, 'n_comp_genes': 486}, 'scaler': 'none', 'shuffle_cols': False, 'variance_reduction': {'enabled': True, 'threshold': 0.7179478232756692}}, {'activation': ('relu', 'relu', 'relu'), 'batch_norm': True, 'dropout': (0.65, 0.7, 0.6), 'epochs': 200, 'hid_layer': (1792, 1024, 2048), 'init_non_scored_weights': False, 'label_smoothing': 0.0023562602622936566, 'learning_rate': 0.37942761787560425, 'weight_norm': True}, {'use_error_class': True, 'zero_threshold': 0}, 9, 1)\n",
      " 95%|█████████▌| 19/20 [08:46<00:27, 27.71s/trial, best loss: 0.016887239420322404] \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-59-601e58269b0f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m3\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0msug\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtpe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrand\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     best = fmin(\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mfn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscore_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mspace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    505\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mallow_trials_fmin\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"fmin\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m         return trials.fmin(\n\u001b[0m\u001b[1;32m    508\u001b[0m             \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m             \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(self, fn, space, algo, max_evals, timeout, loss_threshold, max_queue_len, rstate, verbose, pass_expr_memo_ctrl, catch_eval_exceptions, return_argmin, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    680\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfmin\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mfmin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    681\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 682\u001b[0;31m         return fmin(\n\u001b[0m\u001b[1;32m    683\u001b[0m             \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    684\u001b[0m             \u001b[0mspace\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[0;34m(fn, space, algo, max_evals, timeout, loss_threshold, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar, early_stop_fn, trials_save_file)\u001b[0m\n\u001b[1;32m    551\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m     \u001b[0;31m# next line is where the fmin is actually executed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 553\u001b[0;31m     \u001b[0mrval\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    554\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    354\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    355\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 356\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    357\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    358\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, N, block_until_done)\u001b[0m\n\u001b[1;32m    290\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    291\u001b[0m                     \u001b[0;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 292\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/hyperopt/fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[0;34m(self, N)\u001b[0m\n\u001b[1;32m    168\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                     \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0merror\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"job exception: %s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/hyperopt/base.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[1;32m    905\u001b[0m                 \u001b[0mprint_node_on_error\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrec_eval_print_node_on_error\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    906\u001b[0m             )\n\u001b[0;32m--> 907\u001b[0;31m             \u001b[0mrval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    908\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    909\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-56-bf72174ef874>\u001b[0m in \u001b[0;36mcreate_and_evaluate_model\u001b[0;34m(args, models, predictions, predictions_cv, run_name, n_split, verbose, overfit)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;34m'model'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     }\n\u001b[0;32m---> 20\u001b[0;31m     logloss_valid, y_pred = model.cv(\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mX_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverfit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverfit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mrun_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_tags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'args'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-54-5ade6663b98a>\u001b[0m in \u001b[0;36mcv\u001b[0;34m(self, X, y, y0, run_name, n_split, metric_fn, overfit, run_tags, return_pred)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         _, y_pred = self.model_main.cv(\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mn_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverfit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverfit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-61849bf06e96>\u001b[0m in \u001b[0;36mcv\u001b[0;34m(self, X, y, y0, run_name, n_split, return_pred, metric_fn, overfit, run_tags, max_score)\u001b[0m\n\u001b[1;32m    200\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m             )\n\u001b[0;32m--> 202\u001b[0;31m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    203\u001b[0m             \u001b[0mmodel_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdefinition\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-61849bf06e96>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x_tr, y_tr, x_val, y_val, y0_tr, y0_val)\u001b[0m\n\u001b[1;32m    137\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m         self.history = model.fit(\n\u001b[0m\u001b[1;32m    140\u001b[0m             \u001b[0mx_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1841\u001b[0m       \u001b[0;31m`\u001b[0m\u001b[0margs\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1842\u001b[0m     \"\"\"\n\u001b[0;32m-> 1843\u001b[0;31m     return self._call_flat(\n\u001b[0m\u001b[1;32m   1844\u001b[0m         [t for t in nest.flatten((args, kwargs), expand_composites=True)\n\u001b[1;32m   1845\u001b[0m          if isinstance(t, (ops.Tensor,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1921\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1923\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1924\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    543\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 545\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    546\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    547\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "!mkdir -p trials/\n",
    "start_secs = time()\n",
    "trials = Trials()\n",
    "\n",
    "fold = fold_simple\n",
    "\n",
    "trials_file = \"trials/trial_{}.hp\".format(trials_version)\n",
    "if isfile(trials_file):\n",
    "    print(f'load trials from: {trials_file}')\n",
    "    trials = pickle.load(open(trials_file, 'rb'))\n",
    "\n",
    "EPOCHS = None\n",
    "\n",
    "for i in range(60):\n",
    "    sug = tpe.suggest\n",
    "    if i % 3 == 0:\n",
    "        sug = tpe.rand.suggest\n",
    "    best = fmin(\n",
    "        fn=score_func,\n",
    "        space=space,\n",
    "        algo=sug,\n",
    "        max_evals=2 * (i + 1),\n",
    "        trials=trials\n",
    "    )\n",
    "    pickle.dump(trials, open(trials_file, \"wb\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-29T16:04:56.099785Z",
     "start_time": "2020-11-29T10:51:11.909264Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "({'fe_cluster': {'enabled': True, 'n_clusters_c': 6, 'n_clusters_g': 44}, 'fe_stats': {'enabled': False}, 'pca': {'enabled': False}, 'scaler': 'none', 'shuffle_cols': True, 'variance_reduction': {'enabled': True, 'threshold': 0.9585049261745544}}, {'activation': ('selu', 'swish', 'swish'), 'batch_norm': True, 'dropout': (0.7, 0.7, 0.3), 'epochs': 100, 'hid_layer': (1152, 1152, 2048), 'init_non_scored_weights': False, 'label_smoothing': 0.0007000000000000001, 'learning_rate': 0.016, 'weight_norm': True}, {'use_error_class': True, 'zero_threshold': 0.985}, 29, 1)\n",
      "[03:02], Fold 0: 0.017156364731024245\n",
      "[03:01], Fold 1: 0.01690529647182921\n",
      "[02:06], Fold 2: 0.017976294061998757\n",
      "[02:02], Fold 3: 0.017259450924824143\n",
      "[02:19], Fold 4: 0.017050093288569778\n",
      "[02:38], Fold 5: 0.01736301611411142\n",
      "[02:20], Fold 6: 0.017188876007641945\n",
      "[02:27], Fold 7: 0.01732044575096952\n",
      "[02:32], Fold 8: 0.01693205854714178\n",
      "[02:28], Fold 9: 0.017197494636883384\n",
      "[02:03], Fold 10: 0.01734772804945053\n",
      "[03:31], Fold 11: 0.017880000248278554\n",
      "Valid logloss: 0.017298093236060273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-1-8edd84b35083>:69: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3, and in 3.9 it will stop working\n",
      "  if isinstance(v, collections.MutableMapping):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INITIAL 0.017298093236060273\n",
      "[03:36], Fold 0: 0.5858689257637631\n",
      "[03:04], Fold 1: 0.596415229415433\n",
      "[03:28], Fold 2: 0.5904712531169877\n",
      "[01:55], Fold 3: 0.6015619047796655\n",
      "[04:07], Fold 4: 0.6016306112616076\n",
      "[05:44], Fold 5: 0.5962678746149392\n",
      "[06:50], Fold 6: 0.5959050026281513\n",
      "[04:04], Fold 7: 0.5956050030259119\n",
      "[03:06], Fold 8: 0.5982529126078138\n",
      "[03:39], Fold 9: 0.5994905106730942\n",
      "[03:45], Fold 10: 0.6004667270832489\n",
      "[02:37], Fold 11: 0.6023087972648831\n",
      "Valid logloss: 0.597020396019625\n",
      "Override to zeros: 4 rows\n",
      "AFTER ZERO 0.017297185940903678\n",
      "[02:35], Fold 0: 0.08620420853162923\n",
      "[02:30], Fold 1: 0.08598465382694451\n",
      "[02:28], Fold 2: 0.08593395483934677\n",
      "[02:13], Fold 3: 0.08653601618860893\n",
      "[02:10], Fold 4: 0.08619149554311747\n",
      "[02:05], Fold 5: 0.08592272884022198\n",
      "[02:34], Fold 6: 0.08532033772418517\n",
      "[02:26], Fold 7: 0.08416058650591282\n",
      "[01:52], Fold 8: 0.08553443817563693\n",
      "[01:54], Fold 9: 0.08491729805550523\n",
      "[02:36], Fold 10: 0.08556222020183772\n",
      "[02:50], Fold 11: 0.08571743759512321\n",
      "Valid logloss: 0.08566544800233915\n",
      "AFTER ERROR 0.017281792909302252\n",
      "Write bundle: bundles/1606653418.pickle\n",
      "Override to zeros: 0 rows\n",
      "Final valid logloss: 0.017281792909302252\n",
      "({'fe_cluster': {'enabled': False, 'n_clusters_c': 6, 'n_clusters_g': 44}, 'fe_stats': {'enabled': False}, 'pca': {'enabled': True, 'n_comp_cells': 50, 'n_comp_genes': 600}, 'scaler': 'quantile', 'shuffle_cols': True, 'variance_reduction': {'enabled': True, 'threshold': 0.8}}, {'batch_norm': True, 'weight_norm': True, 'activation': ['elu', 'elu', 'elu', 'elu'], 'dropout': [0.3, 0.3, 0.4, 0.3], 'hid_layer': [512, 1024, 512, 2048], 'init_non_scored_weights': False, 'label_smoothing': 0.0015, 'learning_rate': 0.001, 'epochs': 25}, {'use_error_class': True, 'zero_threshold': 0.985}, 8, 1)\n",
      "[00:58], Fold 0: 0.01968664282239592\n",
      "break cv execution 0.01968664282239592 > 0.019\n",
      "({'fe_cluster': {'enabled': False, 'n_clusters_c': 6, 'n_clusters_g': 44}, 'fe_stats': {'enabled': False}, 'pca': {'enabled': True, 'n_comp_cells': 50, 'n_comp_genes': 600}, 'scaler': 'quantile', 'shuffle_cols': True, 'variance_reduction': {'enabled': True, 'threshold': 0.8}}, {'batch_norm': True, 'weight_norm': True, 'activation': ['elu', 'elu', 'elu', 'elu'], 'dropout': [0.3, 0.3, 0.4, 0.3], 'hid_layer': [512, 1024, 512, 2048], 'init_non_scored_weights': False, 'label_smoothing': 0.0015, 'learning_rate': 0.001, 'epochs': 35}, {'use_error_class': True, 'zero_threshold': 0.985}, 8, 1)\n",
      "[00:57], Fold 0: 0.01985372818836319\n",
      "break cv execution 0.01985372818836319 > 0.019\n",
      "({'fe_cluster': {'enabled': False}, 'fe_stats': {'enabled': False}, 'pca': {'enabled': False}, 'scaler': 'gauss', 'shuffle_cols': False, 'variance_reduction': {'enabled': False}}, {'activation': ('selu', 'swish', 'swish'), 'batch_norm': False, 'dropout': (0.65, 0.7, 0.6), 'epochs': 200, 'hid_layer': (1664, 1408, 1280), 'init_non_scored_weights': True, 'label_smoothing': 0.0001087446974391731, 'learning_rate': 0.04150188777502751, 'weight_norm': True}, {'use_error_class': True, 'zero_threshold': 0.985}, 34, 1)\n",
      "[04:39], Fold 0: 0.016794535383076056\n",
      "[04:34], Fold 1: 0.016994674144813312\n",
      "[04:09], Fold 2: 0.017036062017312118\n",
      "[04:42], Fold 3: 0.017293050551553935\n",
      "[04:20], Fold 4: 0.017458227170664455\n",
      "[04:16], Fold 5: 0.01701989656003281\n",
      "[04:19], Fold 6: 0.01706095760200505\n",
      "[04:16], Fold 7: 0.017275340082509066\n",
      "[04:07], Fold 8: 0.017307547372014776\n",
      "[04:11], Fold 9: 0.01726137407291598\n",
      "[04:11], Fold 10: 0.017241920002033364\n",
      "[03:43], Fold 11: 0.017559510066680557\n",
      "Valid logloss: 0.017191924585467623\n",
      "INITIAL 0.017191924585467623\n",
      "[06:18], Fold 0: 0.5906991765757732\n",
      "[06:57], Fold 1: 0.5877547331215116\n",
      "[05:04], Fold 2: 0.5892471007913173\n",
      "[05:10], Fold 3: 0.589757462990048\n",
      "[07:36], Fold 4: 0.5814038996342142\n",
      "[03:36], Fold 5: 0.597270372004403\n",
      "[05:48], Fold 6: 0.6019768845849489\n",
      "[07:18], Fold 7: 0.589758964741663\n",
      "[05:04], Fold 8: 0.5869851353512783\n",
      "[04:27], Fold 9: 0.5917293136189207\n",
      "[07:20], Fold 10: 0.5875965539271006\n",
      "[06:58], Fold 11: 0.5849161839047291\n",
      "Valid logloss: 0.589924648437159\n",
      "Override to zeros: 10 rows\n",
      "AFTER ZERO 0.017190590682768826\n",
      "[04:00], Fold 0: 0.08547033284386421\n",
      "[04:12], Fold 1: 0.08468711658290125\n",
      "[04:13], Fold 2: 0.08494271076424838\n",
      "[03:38], Fold 3: 0.08527546012737007\n",
      "[04:00], Fold 4: 0.0853821285315523\n",
      "[05:33], Fold 5: 0.0850056534921961\n",
      "[03:53], Fold 6: 0.08697054712025384\n",
      "[04:19], Fold 7: 0.08622390738275257\n",
      "[04:13], Fold 8: 0.08663767211128046\n",
      "[03:32], Fold 9: 0.08479261747081557\n",
      "[04:41], Fold 10: 0.08689639623694488\n",
      "[04:13], Fold 11: 0.08559366276398973\n",
      "Valid logloss: 0.0856565171190141\n",
      "AFTER ERROR 0.017183086456343737\n",
      "Write bundle: bundles/1606664066.pickle\n",
      "Override to zeros: 0 rows\n",
      "Final valid logloss: 0.017183086456343737\n",
      "({'fe_cluster': {'enabled': False, 'n_clusters_c': 6, 'n_clusters_g': 44}, 'fe_stats': {'enabled': False}, 'pca': {'enabled': True, 'n_comp_cells': 60, 'n_comp_genes': 463}, 'scaler': 'quantile', 'shuffle_cols': True, 'variance_reduction': {'enabled': True, 'threshold': 0.9}}, {'batch_norm': True, 'weight_norm': True, 'activation': ['leaky_relu', 'leaky_relu'], 'dropout': [0.25, 0.25], 'hid_layer': [1500, 1500], 'init_non_scored_weights': False, 'label_smoothing': 0, 'learning_rate': 0.001, 'epochs': 25}, {'use_error_class': True, 'zero_threshold': 0.985}, 0, 1)\n",
      "[01:09], Fold 0: 0.01781096974937013\n",
      "[01:04], Fold 1: 0.018286709686727704\n",
      "[01:28], Fold 2: 0.016840381986625946\n",
      "[01:46], Fold 3: 0.016729876735945934\n",
      "[01:21], Fold 4: 0.016996685561860236\n",
      "[01:04], Fold 5: 0.018354670733782268\n",
      "[01:27], Fold 6: 0.016448579090116548\n",
      "[01:24], Fold 7: 0.01691017749175335\n",
      "[01:07], Fold 8: 0.017609128487529373\n",
      "[17:22], Fold 9: 0.016747534065207677\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 156. MiB for an array with shape (20119, 1015) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-025377ac3004>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    122\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mconf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfinal_conf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0mconf2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeepcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m     new_score = create_and_evaluate_model(\n\u001b[0m\u001b[1;32m    125\u001b[0m         \u001b[0mconf2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mmodels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodels_final\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-14-bf72174ef874>\u001b[0m in \u001b[0;36mcreate_and_evaluate_model\u001b[0;34m(args, models, predictions, predictions_cv, run_name, n_split, verbose, overfit)\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0;34m'model'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m     }\n\u001b[0;32m---> 20\u001b[0;31m     logloss_valid, y_pred = model.cv(\n\u001b[0m\u001b[1;32m     21\u001b[0m         \u001b[0mX_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverfit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverfit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0mrun_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrun_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_tags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'args'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-13-5ade6663b98a>\u001b[0m in \u001b[0;36mcv\u001b[0;34m(self, X, y, y0, run_name, n_split, metric_fn, overfit, run_tags, return_pred)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         _, y_pred = self.model_main.cv(\n\u001b[0m\u001b[1;32m     52\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m             \u001b[0mn_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_split\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetric_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetric_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverfit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moverfit\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-61849bf06e96>\u001b[0m in \u001b[0;36mcv\u001b[0;34m(self, X, y, y0, run_name, n_split, return_pred, metric_fn, overfit, run_tags, max_score)\u001b[0m\n\u001b[1;32m    179\u001b[0m             \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m             \u001b[0;31m# Обучающая,Валидационная выборка\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m             \u001b[0mx_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_vals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_vals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mte\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m             \u001b[0;31m# Y предварительной задачи (non-scored)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m             \u001b[0my0_tr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my0vals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my0vals\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mte\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: Unable to allocate 156. MiB for an array with shape (20119, 1015) and data type float64"
     ]
    }
   ],
   "source": [
    "# Сюда записываем все доступные предсказания для блендинга\n",
    "from copy import deepcopy\n",
    "\n",
    "fold = fold_simple\n",
    "\n",
    "models_final = []\n",
    "predictions_final = []\n",
    "baseline_num = 2\n",
    "EPOCHS = None\n",
    "SPLITS = 12\n",
    "\n",
    "final_conf = [\n",
    "    # http://datadigger.ru:5000/#/experiments/3/runs/4525174c3e574ac68426e02ab0f0ee3f\n",
    "#     ({'fe_cluster': {'enabled': True, 'n_clusters_c': 14, 'n_clusters_g': 39}, 'fe_stats': {'enabled': True}, 'pca': {'enabled': False}, 'scaler': 'quantile', 'shuffle_cols': True, 'variance_reduction': {'enabled': False}}, {'activation': ('elu', 'elu', 'elu', 'elu'), 'batch_norm': True, 'dropout': (0.3, 0.3, 0.4, 0.3), 'epochs': 100, 'hid_layer': (512, 1024, 512, 2048), 'init_non_scored_weights': False, 'label_smoothing': 0.0001380444271082826, 'learning_rate': 0.4083831289327425, 'weight_norm': True}, {'use_error_class': True, 'zero_threshold': 0.985}, 13, 2),\n",
    "    # http://datadigger.ru:5000/#/experiments/3/runs/0b83844bc5bd44b2a9665fe6bd9feee4\n",
    "#     ({'fe_cluster': {'enabled': True, 'n_clusters_c': 11, 'n_clusters_g': 41}, 'fe_stats': {'enabled': False}, 'pca': {'enabled': False}, 'scaler': 'quantile', 'shuffle_cols': True, 'variance_reduction': {'enabled': False}}, {'activation': ('elu', 'elu', 'elu', 'elu'), 'batch_norm': True, 'dropout': (0.3, 0.3, 0.4, 0.3), 'epochs': 100, 'hid_layer': (512, 1024, 512, 2048), 'init_non_scored_weights': False, 'label_smoothing': 0.00010848528437984486, 'learning_rate': 0.40431872111746137, 'weight_norm': True}, {'use_error_class': True, 'zero_threshold': 0.985}, 13, 1),\n",
    "    # http://datadigger.ru:5000/#/experiments/0/runs/82cc5898a2b54ce5832d93f6a1afd445\n",
    "    ({'fe_cluster': {'enabled': True, 'n_clusters_c': 6, 'n_clusters_g': 44}, 'fe_stats': {'enabled': False}, 'pca': {'enabled': False}, 'scaler': 'none', 'shuffle_cols': True, 'variance_reduction': {'enabled': True, 'threshold': 0.9585049261745544}}, {'activation': ('selu', 'swish', 'swish'), 'batch_norm': True, 'dropout': (0.7, 0.7, 0.3), 'epochs': 100, 'hid_layer': (1152, 1152, 2048), 'init_non_scored_weights': False, 'label_smoothing': 0.0007000000000000001, 'learning_rate': 0.016, 'weight_norm': True}, {'use_error_class': True, 'zero_threshold': 0.985}, 29, 1),\n",
    "    \n",
    "    (\n",
    "    {\n",
    "        'fe_cluster': {'enabled': False, 'n_clusters_c': 6, 'n_clusters_g': 44}, \n",
    "        'fe_stats': {'enabled': False}, \n",
    "        'pca': {'enabled': True, 'n_comp_cells': 50, 'n_comp_genes': 600}, \n",
    "        'scaler': 'quantile', 'shuffle_cols': True, \n",
    "        'variance_reduction': {'enabled': True, 'threshold': 0.8}\n",
    "    },\n",
    "    {\n",
    "        'batch_norm': True, 'weight_norm': True, \n",
    "        'activation': ['elu', 'elu', 'elu', 'elu'], \n",
    "        'dropout': [0.3, 0.3, 0.4, 0.3], \n",
    "        'hid_layer': [512,1024,512,2048], \n",
    "        'init_non_scored_weights': False, \n",
    "        'label_smoothing': 0.0015, \n",
    "        'learning_rate': 0.001, 'epochs': 25\n",
    "    }, \n",
    "        {\n",
    "            'use_error_class': True, 'zero_threshold': 0.985\n",
    "        },\n",
    "        8, 1\n",
    "    ),\n",
    "    # public 1\n",
    "    (\n",
    "        {\n",
    "            'fe_cluster': {'enabled': False, 'n_clusters_c': 6, 'n_clusters_g': 44}, \n",
    "            'fe_stats': {'enabled': False}, \n",
    "            'pca': {'enabled': True, 'n_comp_cells': 50, 'n_comp_genes': 600}, \n",
    "            'scaler': 'quantile', 'shuffle_cols': True, \n",
    "            'variance_reduction': {'enabled': True, 'threshold': 0.8}\n",
    "        },\n",
    "        {\n",
    "            'batch_norm': True, 'weight_norm': True, \n",
    "            'activation': ['elu', 'elu', 'elu', 'elu'], \n",
    "            'dropout': [0.3, 0.3, 0.4, 0.3], \n",
    "            'hid_layer': [512,1024,512,2048], \n",
    "            'init_non_scored_weights': False, \n",
    "            'label_smoothing': 0.0015, \n",
    "            'learning_rate': 0.001, 'epochs': 35\n",
    "        },\n",
    "        {\n",
    "            'use_error_class': True, 'zero_threshold': 0.985\n",
    "        },\n",
    "        8, 1\n",
    "    ),\n",
    "    # best mlflow\n",
    "    (\n",
    "        {'fe_cluster': {'enabled': False}, 'fe_stats': {'enabled': False}, 'pca': {'enabled': False}, 'scaler': 'gauss', 'shuffle_cols': False, 'variance_reduction': {'enabled': False}}, \n",
    "        {'activation': ('selu', 'swish', 'swish'), 'batch_norm': False, 'dropout': (0.65, 0.7, 0.6), 'epochs': 200,\n",
    "         'hid_layer': (1664, 1408, 1280), 'init_non_scored_weights': True, 'label_smoothing': 0.0001087446974391731, 'learning_rate': 0.04150188777502751, 'weight_norm': True}, \n",
    "        {\n",
    "            'use_error_class': True, 'zero_threshold': 0.985\n",
    "        }, \n",
    "        34, 1\n",
    "    ),\n",
    "    # public 2\n",
    "    ({\n",
    "        'fe_cluster': {'enabled': False, 'n_clusters_c': 6, 'n_clusters_g': 44}, \n",
    "        'fe_stats': {'enabled': False}, \n",
    "        'pca': {'enabled': True, 'n_comp_cells': 60, 'n_comp_genes': 463}, \n",
    "        'scaler': 'quantile', 'shuffle_cols': True, \n",
    "        'variance_reduction': {'enabled': True, 'threshold': 0.9}\n",
    "    },\n",
    "    {\n",
    "        'batch_norm': True, 'weight_norm': True, \n",
    "        'activation': ['leaky_relu', 'leaky_relu'], \n",
    "        'dropout': [0.25, 0.25], \n",
    "        'hid_layer': [1500, 1500], \n",
    "        'init_non_scored_weights': False, \n",
    "        'label_smoothing': 0,\n",
    "        'learning_rate': 0.001, 'epochs': 25\n",
    "    },\n",
    "    {\n",
    "        'use_error_class': True, 'zero_threshold': 0.985\n",
    "    },\n",
    "    0, 1\n",
    "    ),\n",
    "    # public 3\n",
    "    ({\n",
    "        'fe_cluster': {'enabled': True, 'n_clusters_c': 4, 'n_clusters_g': 22}, \n",
    "        'fe_stats': {'enabled': True}, \n",
    "        'pca': {'enabled': True, 'n_comp_cells': 50, 'n_comp_genes': 600, 'n_clusters': 5},\n",
    "        'scaler': 'quantile', 'shuffle_cols': False, \n",
    "        'variance_reduction': {'enabled': True, 'threshold': 0.85}\n",
    "    },\n",
    "    {\n",
    "        'batch_norm': True, 'weight_norm': 'output',\n",
    "        'activation': ['leaky_relu', 'leaky_relu', 'leaky_relu', 'leaky_relu'], \n",
    "        'dropout': [0.5, 0.35, 0.3, 0.25], \n",
    "        'hid_layer': [1500, 1250, 1000, 750], \n",
    "        'init_non_scored_weights': True, \n",
    "        'label_smoothing': 0, \n",
    "        'learning_rate': 1e-3, 'epochs': 25\n",
    "    },\n",
    "    {\n",
    "        'use_error_class': True, 'zero_threshold': 0.985\n",
    "    },\n",
    "    42, 1\n",
    "    ),\n",
    "]\n",
    "\n",
    "cv_preds = []\n",
    "for conf in final_conf:\n",
    "    conf2 = deepcopy(conf)\n",
    "    new_score = create_and_evaluate_model(\n",
    "        conf2,\n",
    "        models=models_final, \n",
    "        predictions=predictions_final,\n",
    "        predictions_cv=cv_preds,\n",
    "        n_split=SPLITS,\n",
    "        run_name=f'base_{baseline_num}'\n",
    "    )\n",
    "\n",
    "print('\\nFinal results:')\n",
    "# http://datadigger.ru:5000/#/experiments/3/runs/69b1f266675941378e47d747fd5c11fc\n",
    "print('Should be lower than', 0.01709)\n",
    "\n",
    "yres = y.drop(columns=['drug_id'], errors='ignore')\n",
    "ycols = yres.columns\n",
    "cv_res = []\n",
    "for i, cv_pred in enumerate(cv_preds):\n",
    "    print(f'Logloss {i}:', log_loss_metric(yres, cv_pred))\n",
    "    cv_res.append(cv_pred.values)\n",
    "\n",
    "final_pred = y_arr_to_df(np.mean(cv_res, axis=0), ycols)\n",
    "print(f'CV:', log_loss_metric(yres, final_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T11:07:56.368963Z",
     "start_time": "2020-11-28T11:07:55.503743Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sig_id</th>\n",
       "      <th>5-alpha_reductase_inhibitor</th>\n",
       "      <th>11-beta-hsd1_inhibitor</th>\n",
       "      <th>acat_inhibitor</th>\n",
       "      <th>acetylcholine_receptor_agonist</th>\n",
       "      <th>acetylcholine_receptor_antagonist</th>\n",
       "      <th>acetylcholinesterase_inhibitor</th>\n",
       "      <th>adenosine_receptor_agonist</th>\n",
       "      <th>adenosine_receptor_antagonist</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <th>...</th>\n",
       "      <th>tropomyosin_receptor_kinase_inhibitor</th>\n",
       "      <th>trpv_agonist</th>\n",
       "      <th>trpv_antagonist</th>\n",
       "      <th>tubulin_inhibitor</th>\n",
       "      <th>tyrosine_kinase_inhibitor</th>\n",
       "      <th>ubiquitin_specific_protease_inhibitor</th>\n",
       "      <th>vegfr_inhibitor</th>\n",
       "      <th>vitamin_b</th>\n",
       "      <th>vitamin_d_receptor_agonist</th>\n",
       "      <th>wnt_inhibitor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>id_0004d9e33</td>\n",
       "      <td>0.001771</td>\n",
       "      <td>0.002319</td>\n",
       "      <td>0.002188</td>\n",
       "      <td>0.017447</td>\n",
       "      <td>0.024561</td>\n",
       "      <td>0.005326</td>\n",
       "      <td>0.003826</td>\n",
       "      <td>0.006806</td>\n",
       "      <td>0.001434</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001677</td>\n",
       "      <td>0.002125</td>\n",
       "      <td>0.003346</td>\n",
       "      <td>0.003798</td>\n",
       "      <td>0.001245</td>\n",
       "      <td>0.001672</td>\n",
       "      <td>0.001777</td>\n",
       "      <td>0.002286</td>\n",
       "      <td>0.003964</td>\n",
       "      <td>0.002201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>id_001897cda</td>\n",
       "      <td>0.001473</td>\n",
       "      <td>0.002284</td>\n",
       "      <td>0.002613</td>\n",
       "      <td>0.001415</td>\n",
       "      <td>0.001816</td>\n",
       "      <td>0.002413</td>\n",
       "      <td>0.005879</td>\n",
       "      <td>0.010842</td>\n",
       "      <td>0.011807</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001859</td>\n",
       "      <td>0.002963</td>\n",
       "      <td>0.003191</td>\n",
       "      <td>0.000569</td>\n",
       "      <td>0.016581</td>\n",
       "      <td>0.002042</td>\n",
       "      <td>0.021862</td>\n",
       "      <td>0.002280</td>\n",
       "      <td>0.005950</td>\n",
       "      <td>0.002531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>id_002429b5b</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>id_00276f245</td>\n",
       "      <td>0.001649</td>\n",
       "      <td>0.001800</td>\n",
       "      <td>0.003486</td>\n",
       "      <td>0.009947</td>\n",
       "      <td>0.011811</td>\n",
       "      <td>0.003728</td>\n",
       "      <td>0.003397</td>\n",
       "      <td>0.004078</td>\n",
       "      <td>0.001542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002103</td>\n",
       "      <td>0.003909</td>\n",
       "      <td>0.004567</td>\n",
       "      <td>0.034676</td>\n",
       "      <td>0.007587</td>\n",
       "      <td>0.001856</td>\n",
       "      <td>0.004222</td>\n",
       "      <td>0.003509</td>\n",
       "      <td>0.004034</td>\n",
       "      <td>0.002741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>id_0027f1083</td>\n",
       "      <td>0.002193</td>\n",
       "      <td>0.002339</td>\n",
       "      <td>0.002184</td>\n",
       "      <td>0.020698</td>\n",
       "      <td>0.030759</td>\n",
       "      <td>0.004905</td>\n",
       "      <td>0.005872</td>\n",
       "      <td>0.003194</td>\n",
       "      <td>0.001600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001631</td>\n",
       "      <td>0.001717</td>\n",
       "      <td>0.003638</td>\n",
       "      <td>0.004887</td>\n",
       "      <td>0.001805</td>\n",
       "      <td>0.001543</td>\n",
       "      <td>0.001965</td>\n",
       "      <td>0.002267</td>\n",
       "      <td>0.001484</td>\n",
       "      <td>0.002084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 207 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         sig_id  5-alpha_reductase_inhibitor  11-beta-hsd1_inhibitor  \\\n",
       "0  id_0004d9e33                     0.001771                0.002319   \n",
       "1  id_001897cda                     0.001473                0.002284   \n",
       "2  id_002429b5b                     0.000000                0.000000   \n",
       "3  id_00276f245                     0.001649                0.001800   \n",
       "4  id_0027f1083                     0.002193                0.002339   \n",
       "\n",
       "   acat_inhibitor  acetylcholine_receptor_agonist  \\\n",
       "0        0.002188                        0.017447   \n",
       "1        0.002613                        0.001415   \n",
       "2        0.000000                        0.000000   \n",
       "3        0.003486                        0.009947   \n",
       "4        0.002184                        0.020698   \n",
       "\n",
       "   acetylcholine_receptor_antagonist  acetylcholinesterase_inhibitor  \\\n",
       "0                           0.024561                        0.005326   \n",
       "1                           0.001816                        0.002413   \n",
       "2                           0.000000                        0.000000   \n",
       "3                           0.011811                        0.003728   \n",
       "4                           0.030759                        0.004905   \n",
       "\n",
       "   adenosine_receptor_agonist  adenosine_receptor_antagonist  \\\n",
       "0                    0.003826                       0.006806   \n",
       "1                    0.005879                       0.010842   \n",
       "2                    0.000000                       0.000000   \n",
       "3                    0.003397                       0.004078   \n",
       "4                    0.005872                       0.003194   \n",
       "\n",
       "   adenylyl_cyclase_activator  ...  tropomyosin_receptor_kinase_inhibitor  \\\n",
       "0                    0.001434  ...                               0.001677   \n",
       "1                    0.011807  ...                               0.001859   \n",
       "2                    0.000000  ...                               0.000000   \n",
       "3                    0.001542  ...                               0.002103   \n",
       "4                    0.001600  ...                               0.001631   \n",
       "\n",
       "   trpv_agonist  trpv_antagonist  tubulin_inhibitor  \\\n",
       "0      0.002125         0.003346           0.003798   \n",
       "1      0.002963         0.003191           0.000569   \n",
       "2      0.000000         0.000000           0.000000   \n",
       "3      0.003909         0.004567           0.034676   \n",
       "4      0.001717         0.003638           0.004887   \n",
       "\n",
       "   tyrosine_kinase_inhibitor  ubiquitin_specific_protease_inhibitor  \\\n",
       "0                   0.001245                               0.001672   \n",
       "1                   0.016581                               0.002042   \n",
       "2                   0.000000                               0.000000   \n",
       "3                   0.007587                               0.001856   \n",
       "4                   0.001805                               0.001543   \n",
       "\n",
       "   vegfr_inhibitor  vitamin_b  vitamin_d_receptor_agonist  wnt_inhibitor  \n",
       "0         0.001777   0.002286                    0.003964       0.002201  \n",
       "1         0.021862   0.002280                    0.005950       0.002531  \n",
       "2         0.000000   0.000000                    0.000000       0.000000  \n",
       "3         0.004222   0.003509                    0.004034       0.002741  \n",
       "4         0.001965   0.002267                    0.001484       0.002084  \n",
       "\n",
       "[5 rows x 207 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Формируем предсказания на основе множества предсказаний\n",
    "# Сюда записываем submission предсказания\n",
    "df_sample.loc[:, ycols] = 0\n",
    "df_sample.loc[:, ycols] = np.mean(predictions_final, axis=0)\n",
    "# У ctl_vehicle все классы - 0, поэтому просто зануляем\n",
    "# Правильно ли?\n",
    "df_sample.loc[ind_te, ycols] = 0\n",
    "display(df_sample.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-28T11:09:02.152135Z",
     "start_time": "2020-11-28T11:09:00.703708Z"
    }
   },
   "outputs": [],
   "source": [
    "df_sample.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Error analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T14:10:07.041454Z",
     "start_time": "2020-11-26T14:09:40.222102Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-fd35875c472b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mte\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mX_p\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreprocess_X\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpreprocess_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mx_val\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX_p\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'float64'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mte\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-5c8316e2f767>\u001b[0m in \u001b[0;36mpreprocess_X\u001b[0;34m(params, X, X_test, seed)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca_transformer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mp_pca\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfe_cluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mp_fe_cluster\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfe_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mp_fe_stats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m     \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariance_reduction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mp_variance_reduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-5c8316e2f767>\u001b[0m in \u001b[0;36mfe_cluster\u001b[0;34m(train, test, **params)\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_cluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_g\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'g'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_clusters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_clusters_g\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_cluster\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeatures_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_clusters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_clusters_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-5c8316e2f767>\u001b[0m in \u001b[0;36mcreate_cluster\u001b[0;34m(train, test, features, kind, n_clusters)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mtest_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mkmeans\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKMeans\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mn_clusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'clusters_{kind}'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mtest\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34mf'clusters_{kind}'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1049\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mseeds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1050\u001b[0m             \u001b[0;31m# run a k-means once\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1051\u001b[0;31m             labels, inertia, centers, n_iter_ = kmeans_single(\n\u001b[0m\u001b[1;32m   1052\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m                 \u001b[0minit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py\u001b[0m in \u001b[0;36m_kmeans_single_elkan\u001b[0;34m(X, sample_weight, n_clusters, max_iter, init, verbose, x_squared_norms, random_state, tol, n_threads)\u001b[0m\n\u001b[1;32m    441\u001b[0m         \u001b[0;31m# compute new pairwise distances between centers and closest other\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0;31m# center of each center for next iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0mcenter_half_distances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meuclidean_distances\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcenters_new\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m         distance_next_center = np.partition(\n\u001b[1;32m    445\u001b[0m             np.asarray(center_half_distances), kth=1, axis=0)[1]\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/metrics/pairwise.py\u001b[0m in \u001b[0;36meuclidean_distances\u001b[0;34m(X, Y, Y_norm_squared, squared, X_norm_squared)\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m         \u001b[0;31m# if dtype is already float64, no need to chunk and upcast\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 309\u001b[0;31m         \u001b[0mdistances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    310\u001b[0m         \u001b[0mdistances\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    311\u001b[0m         \u001b[0mdistances\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mYY\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     71\u001b[0m                           FutureWarning)\n\u001b[1;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/sklearn/utils/extmath.py\u001b[0m in \u001b[0;36msafe_sparse_dot\u001b[0;34m(a, b, dense_output)\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m \u001b[0;34m@\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     if (sparse.issparse(a) and sparse.issparse(b)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Количество ошибок, когда должно быть везде 0, а на самом деле - нет\n",
    "# Количество ошибок, когда должно что-то быть, а на самом деле везде 0\n",
    "# Для уменьшения этих ошибок можно применять lgb_zero\n",
    "\n",
    "res = y.copy()\n",
    "res.loc[:, y.columns] = 0\n",
    "\n",
    "# model = models_final[-1]\n",
    "# preprocess_params, _, _, seed, _ = baseline_conf[-1]\n",
    "\n",
    "model = error_model\n",
    "preprocess_params = fe_params\n",
    "\n",
    "seed_everything(seed)\n",
    "\n",
    "_, te = train_test_split(X, y, n_split=5)\n",
    "X_p, _, _, _ = preprocess_X(fe_params, X.copy(), X_test.copy(), y.copy(), y0.copy(), seed=seed)\n",
    "\n",
    "x_val = X_p.astype('float64').values[te]\n",
    "\n",
    "res.loc[te, y.columns] = model.predict(x_val)\n",
    "\n",
    "y_pred = res.loc[te, y.columns]\n",
    "y_true = y.loc[te, y.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-26T13:01:55.445366Z",
     "start_time": "2020-11-26T13:01:51.744193Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logloss: 0.013384161126035564\n",
      "Logloss all zeros: 0.0026687569508067285\n",
      "Logloss non zeros: 0.02042709727321972\n",
      "Logloss clip: 0.013384161126035564\n",
      "Logloss all zeros clip: 0.0026687569508067285\n",
      "Logloss non zeros clip: 0.02042709727321972\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>true_0</th>\n",
       "      <th>true_1</th>\n",
       "      <th>loss</th>\n",
       "      <th>pred_hist_0</th>\n",
       "      <th>pred_hist_1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <th>cyclooxygenase_inhibitor</th>\n",
       "      <td>4676</td>\n",
       "      <td>87</td>\n",
       "      <td>0.082078</td>\n",
       "      <td>[[0.0, 4684.0], [0.1, 79.0]]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <th>serotonin_receptor_antagonist</th>\n",
       "      <td>4682</td>\n",
       "      <td>81</td>\n",
       "      <td>0.073743</td>\n",
       "      <td>[[0.0, 4517.0], [0.1, 238.0], [0.2, 8.0]]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <th>glutamate_receptor_antagonist</th>\n",
       "      <td>4689</td>\n",
       "      <td>74</td>\n",
       "      <td>0.073350</td>\n",
       "      <td>[[0.0, 4763.0]]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <th>dopamine_receptor_antagonist</th>\n",
       "      <td>4678</td>\n",
       "      <td>85</td>\n",
       "      <td>0.072481</td>\n",
       "      <td>[[0.0, 4489.0], [0.1, 236.0], [0.2, 28.0], [0....</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <th>adrenergic_receptor_antagonist</th>\n",
       "      <td>4691</td>\n",
       "      <td>72</td>\n",
       "      <td>0.071955</td>\n",
       "      <td>[[0.0, 4763.0]]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <th>chk_inhibitor</th>\n",
       "      <td>4758</td>\n",
       "      <td>5</td>\n",
       "      <td>0.000934</td>\n",
       "      <td>[[0.0, 4757.0], [0.1, 1.0], [0.3, 1.0], [0.4, ...</td>\n",
       "      <td>[[0.6, 1.0], [0.8, 2.0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <th>bacterial_membrane_integrity_inhibitor</th>\n",
       "      <td>4762</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000759</td>\n",
       "      <td>[[0.0, 4761.0], [0.1, 2.0]]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <th>adenylyl_cyclase_activator</th>\n",
       "      <td>4761</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000618</td>\n",
       "      <td>[[0.0, 4760.0], [0.2, 1.0], [0.4, 1.0], [0.5, ...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <th>proteasome_inhibitor</th>\n",
       "      <td>4617</td>\n",
       "      <td>146</td>\n",
       "      <td>0.000356</td>\n",
       "      <td>[[0.0, 4614.0], [0.1, 3.0]]</td>\n",
       "      <td>[[0.9, 2.0], [1.0, 144.0]]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <th>atp-sensitive_potassium_channel_antagonist</th>\n",
       "      <td>4763</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>[[0.0, 4763.0]]</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>206 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  true_0  true_1      loss  \\\n",
       "index class                                                                  \n",
       "71    cyclooxygenase_inhibitor                      4676      87  0.082078   \n",
       "177   serotonin_receptor_antagonist                 4682      81  0.073743   \n",
       "99    glutamate_receptor_antagonist                 4689      74  0.073350   \n",
       "79    dopamine_receptor_antagonist                  4678      85  0.072481   \n",
       "10    adrenergic_receptor_antagonist                4691      72  0.071955   \n",
       "...                                                  ...     ...       ...   \n",
       "65    chk_inhibitor                                 4758       5  0.000934   \n",
       "46    bacterial_membrane_integrity_inhibitor        4762       1  0.000759   \n",
       "8     adenylyl_cyclase_activator                    4761       2  0.000618   \n",
       "163   proteasome_inhibitor                          4617     146  0.000356   \n",
       "34    atp-sensitive_potassium_channel_antagonist    4763       0  0.000113   \n",
       "\n",
       "                                                                                        pred_hist_0  \\\n",
       "index class                                                                                           \n",
       "71    cyclooxygenase_inhibitor                                         [[0.0, 4684.0], [0.1, 79.0]]   \n",
       "177   serotonin_receptor_antagonist                       [[0.0, 4517.0], [0.1, 238.0], [0.2, 8.0]]   \n",
       "99    glutamate_receptor_antagonist                                                 [[0.0, 4763.0]]   \n",
       "79    dopamine_receptor_antagonist                [[0.0, 4489.0], [0.1, 236.0], [0.2, 28.0], [0....   \n",
       "10    adrenergic_receptor_antagonist                                                [[0.0, 4763.0]]   \n",
       "...                                                                                             ...   \n",
       "65    chk_inhibitor                               [[0.0, 4757.0], [0.1, 1.0], [0.3, 1.0], [0.4, ...   \n",
       "46    bacterial_membrane_integrity_inhibitor                            [[0.0, 4761.0], [0.1, 2.0]]   \n",
       "8     adenylyl_cyclase_activator                  [[0.0, 4760.0], [0.2, 1.0], [0.4, 1.0], [0.5, ...   \n",
       "163   proteasome_inhibitor                                              [[0.0, 4614.0], [0.1, 3.0]]   \n",
       "34    atp-sensitive_potassium_channel_antagonist                                    [[0.0, 4763.0]]   \n",
       "\n",
       "                                                                 pred_hist_1  \n",
       "index class                                                                   \n",
       "71    cyclooxygenase_inhibitor                                            []  \n",
       "177   serotonin_receptor_antagonist                                       []  \n",
       "99    glutamate_receptor_antagonist                                       []  \n",
       "79    dopamine_receptor_antagonist                                        []  \n",
       "10    adrenergic_receptor_antagonist                                      []  \n",
       "...                                                                      ...  \n",
       "65    chk_inhibitor                                 [[0.6, 1.0], [0.8, 2.0]]  \n",
       "46    bacterial_membrane_integrity_inhibitor                              []  \n",
       "8     adenylyl_cyclase_activator                                          []  \n",
       "163   proteasome_inhibitor                        [[0.9, 2.0], [1.0, 144.0]]  \n",
       "34    atp-sensitive_potassium_channel_antagonist                          []  \n",
       "\n",
       "[206 rows x 5 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "non_zeros = y_true[(y_true.T != 0).any()].index\n",
    "all_zeros = y_true[~(y_true.T != 0).any()].index\n",
    "\n",
    "clip_p_min = 1e-5\n",
    "clip_p_max = 1 - 1e-5\n",
    "\n",
    "y_pred_clip = np.clip(y_pred, clip_p_min, clip_p_max)\n",
    "\n",
    "print('Logloss:', log_loss_metric(y_true, y_pred))\n",
    "print('Logloss all zeros:', log_loss_metric(y_true.loc[all_zeros, :], y_pred.loc[all_zeros, :]))\n",
    "print('Logloss non zeros:', log_loss_metric(y_true.loc[non_zeros, :], y_pred.loc[non_zeros, :]))\n",
    "print('Logloss clip:', log_loss_metric(y_true, y_pred_clip))\n",
    "print('Logloss all zeros clip:', log_loss_metric(y_true.loc[all_zeros, :], y_pred_clip.loc[all_zeros, :]))\n",
    "print('Logloss non zeros clip:', log_loss_metric(y_true.loc[non_zeros, :], y_pred_clip.loc[non_zeros, :]))\n",
    "\n",
    "losses = []\n",
    "for i in range(y_true.shape[1]):\n",
    "    y_true_cl = y_true.iloc[:,i]\n",
    "    y_pred_cl = y_pred.iloc[:,i]\n",
    "    losses.append({\n",
    "        \"index\": i,\n",
    "        \"class\": y_true_cl.name,\n",
    "        'true_0': len(y_true_cl[y_true_cl == 0]),\n",
    "        'true_1': len(y_true_cl[y_true_cl == 1]),\n",
    "        \"loss\": log_loss(y_true_cl.values, y_pred_cl.values, labels=[0, 1]),\n",
    "        'pred_hist_0': y_pred_cl[y_pred_cl <= 0.5].round(1).value_counts().sort_index().reset_index().values,\n",
    "        'pred_hist_1': y_pred_cl[y_pred_cl > 0.5].round(1).value_counts().sort_index().reset_index().values,\n",
    "    })\n",
    "\n",
    "loss_df = pd.DataFrame(losses).set_index(['index', 'class']).sort_values('loss', ascending=False)\n",
    "display(loss_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Offline vs Public"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "* 0.0167448 -> 0.01904 [exp](http://datadigger.ru:5000/#/experiments/0/runs/876b40e127874edc932aadb531b489e5) vers 15\n",
    "* 0.0166455 -> 0.01901 [exp](http://datadigger.ru:5000/#/experiments/0/runs/cdaa8f76e1054cb3b5c0994af2ceadd6) vers 14\n",
    "* 0.0167984 -> 0.01895\n",
    "* 0.0168703 -> 0.01902 [exp](http://datadigger.ru:5000/#/experiments/0/runs/c949c2c4614f4f2095ffd7ba93e093e5)\n",
    "* 0.0170201 -> 0.01911\n",
    "* 0.0184141 -> 0.01950\n",
    "* 0.018... -> 0.01966 (p_min=1e-15, p_max=1 - 1e-15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "hidden": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "282px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
